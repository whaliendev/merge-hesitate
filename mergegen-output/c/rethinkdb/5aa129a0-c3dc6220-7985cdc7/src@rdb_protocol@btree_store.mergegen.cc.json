[
    {
        "a_contents": "std::map<std::string, std::pair<sindex_config_t, sindex_status_t> > store_t::sindex_list(\n        UNUSED signal_t *interruptor)\n        THROWS_ONLY(interrupted_exc_t) {\n    scoped_ptr_t<real_superblock_t> superblock;\n    scoped_ptr_t<txn_t> txn;\n    get_btree_superblock_and_txn_for_reading(general_cache_conn.get(),\n        CACHE_SNAPSHOTTED_NO, &superblock, &txn);\n    buf_lock_t sindex_block(superblock->expose_buf(),\n                            superblock->get_sindex_block_id(),\n                            access_t::read);\n    superblock->release();\n\n    std::map<sindex_name_t, secondary_index_t> secondary_indexes;\n    get_secondary_indexes(&sindex_block, &secondary_indexes);\n    sindex_block.reset_buf_lock();\n\n    std::map<std::string, std::pair<sindex_config_t, sindex_status_t> > results;\n    for (const auto &pair : secondary_indexes) {\n        guarantee(pair.first.being_deleted == pair.second.being_deleted);\n        if (pair.second.being_deleted) {\n            continue;\n        }\n        std::pair<sindex_config_t, sindex_status_t> *res = &results[pair.first.name];\n        sindex_disk_info_t disk_info;\n        try {\n            deserialize_sindex_info(pair.second.opaque_definition, &disk_info);\n        } catch (const archive_exc_t &) {\n            crash(\"corrupted sindex definition\");\n        }\n\n        res->first.func = disk_info.mapping;\n        res->first.func_version = disk_info.mapping_version_info.original_reql_version;\n        res->first.multi = disk_info.multi;\n        res->first.geo = disk_info.geo;\n\n        res->second.outdated =\n            disk_info.mapping_version_info.latest_compatible_reql_version !=\n                reql_version_t::LATEST;\n        if (pair.second.is_ready()) {\n            res->second.ready = true;\n            res->second.blocks_processed = res->second.blocks_total = 0;\n        } else {\n            res->second.ready = false;\n            progress_completion_fraction_t frac = get_sindex_progress(pair.second.id);\n            if (frac.estimate_of_total_nodes == -1) {\n                res->second.blocks_processed = res->second.blocks_total = 0;\n            } else {\n                res->second.blocks_processed = frac.estimate_of_released_nodes;\n                res->second.blocks_total = frac.estimate_of_total_nodes;\n            }\n        }\n    }\n\n    return results;\n}\n\nvoid store_t::sindex_create(\n        const std::string &name,\n        const sindex_config_t &config,\n        UNUSED signal_t *interruptor)\n        THROWS_ONLY(interrupted_exc_t) {\n    scoped_ptr_t<real_superblock_t> superblock;\n    scoped_ptr_t<txn_t> txn;\n    get_btree_superblock_and_txn_for_writing(general_cache_conn.get(),\n        &write_superblock_acq_semaphore, write_access_t::write, 1,\n        write_durability_t::HARD, &superblock, &txn);\n    buf_lock_t sindex_block(superblock->expose_buf(),\n                            superblock->get_sindex_block_id(),\n                            access_t::write);\n    superblock->release();\n\n    /* Note that this function allows creating sindexes with older ReQL versions. For\n    example, suppose that the user upgrades to a newer version of RethinkDB, and then\n    they want to add a replica to a table with an outdated secondary index. Then this\n    function would be called to create the outdated secondary index on the new replica.\n    */\n    sindex_reql_version_info_t version_info;\n    version_info.original_reql_version = config.func_version;\n    version_info.latest_compatible_reql_version = config.func_version;\n    version_info.latest_checked_reql_version = reql_version_t::LATEST;\n    sindex_disk_info_t info(config.func, version_info, config.multi, config.geo);\n\n    write_message_t wm;\n    serialize_sindex_info(&wm, info);\n    vector_stream_t stream;\n    stream.reserve(wm.size());\n    int write_res = send_write_message(&stream, &wm);\n    guarantee(write_res == 0);\n\n    sindex_name_t sindex_name(name);\n    bool success = add_sindex_internal(sindex_name, stream.vector(), &sindex_block);\n    guarantee(success, \"sindex_create() called with a sindex name that exists\");\n\n    rdb_protocol::bring_sindexes_up_to_date(\n        std::set<sindex_name_t>{sindex_name}, this, &sindex_block);\n}\n\nvoid store_t::sindex_rename_multi(\n        const std::map<std::string, std::string> &name_changes,\n        UNUSED signal_t *interruptor)\n        THROWS_ONLY(interrupted_exc_t) {\n    scoped_ptr_t<real_superblock_t> superblock;\n    scoped_ptr_t<txn_t> txn;\n    get_btree_superblock_and_txn_for_writing(general_cache_conn.get(),\n        &write_superblock_acq_semaphore, write_access_t::write, 1,\n        write_durability_t::HARD, &superblock, &txn);\n    buf_lock_t sindex_block(superblock->expose_buf(),\n                            superblock->get_sindex_block_id(),\n                            access_t::write);\n    superblock->release();\n\n    /* First we remove all the secondary indexes and hide their perfmons, but put the\n    definitions and `btree_stats_t`s into `to_put_back` indexed by their new names. Then\n    we go through and put them all back under their new names. */\n    std::map<std::string, std::pair<secondary_index_t, btree_stats_t *> > to_put_back;\n\n    for (const auto &pair : name_changes) {\n        secondary_index_t definition;\n        bool success = get_secondary_index(\n            &sindex_block, sindex_name_t(pair.first), &definition);\n        guarantee(success);\n        success = delete_secondary_index(&sindex_block, sindex_name_t(pair.first));\n        guarantee(success);\n\n        auto slice_it = secondary_index_slices.find(definition.id);\n        guarantee(slice_it != secondary_index_slices.end());\n        guarantee(slice_it->second.has());\n        slice_it->second->assert_thread();\n        btree_stats_t *stats = &slice_it->second->stats;\n        stats->hide();\n\n        to_put_back.insert(std::make_pair(\n            pair.second, std::make_pair(definition, stats)));\n    }\n\n    for (const auto &pair : to_put_back) {\n        set_secondary_index(&sindex_block, sindex_name_t(pair.first), pair.second.first);\n        pair.second.second->rename(&perfmon_collection, \"index-\" + pair.first);\n    }\n\n    if (index_report.has()) {\n        index_report->indexes_renamed(name_changes);\n    }\n}\n\nvoid store_t::sindex_drop(\n        const std::string &name,\n        UNUSED signal_t *interruptor)\n        THROWS_ONLY(interrupted_exc_t) {\n    scoped_ptr_t<real_superblock_t> superblock;\n    scoped_ptr_t<txn_t> txn;\n    get_btree_superblock_and_txn_for_writing(general_cache_conn.get(),\n        &write_superblock_acq_semaphore, write_access_t::write, 1,\n        write_durability_t::HARD, &superblock, &txn);\n    buf_lock_t sindex_block(superblock->expose_buf(),\n                            superblock->get_sindex_block_id(),\n                            access_t::write);\n    superblock->release();\n\n    secondary_index_t sindex;\n    bool success = ::get_secondary_index(&sindex_block, sindex_name_t(name), &sindex);\n    guarantee(success, \"sindex_drop() called on sindex that doesn't exist\");\n\n    /* Mark the secondary index as deleted */\n    success = mark_secondary_index_deleted(&sindex_block, sindex_name_t(name));\n    guarantee(success);\n\n    /* Clear the sindex later. It starts its own transaction and we don't\n    want to deadlock because we're still holding locks. */\n    coro_t::spawn_sometime(std::bind(&store_t::delayed_clear_sindex,\n                                     this,\n                                     sindex,\n                                     drainer.lock()));\n\n    if (index_report.has()) {\n        index_report->index_dropped(name);\n    }\n}\n\nscoped_ptr_t<new_mutex_in_line_t> store_t::get_in_line_for_sindex_queue(\n        buf_lock_t *sindex_block) {",
        "b_contents": "new_mutex_in_line_t store_t::get_in_line_for_sindex_queue(buf_lock_t *sindex_block) {",
        "base_contents": "scoped_ptr_t<new_mutex_in_line_t> store_t::get_in_line_for_sindex_queue(\n        buf_lock_t *sindex_block) {",
        "res_region": "std::map<std::string, std::pair<sindex_config_t, sindex_status_t> > store_t::sindex_list(\n        UNUSED signal_t *interruptor)\n        THROWS_ONLY(interrupted_exc_t) {\n    scoped_ptr_t<real_superblock_t> superblock;\n    scoped_ptr_t<txn_t> txn;\n    get_btree_superblock_and_txn_for_reading(general_cache_conn.get(),\n        CACHE_SNAPSHOTTED_NO, &superblock, &txn);\n    buf_lock_t sindex_block(superblock->expose_buf(),\n                            superblock->get_sindex_block_id(),\n                            access_t::read);\n    superblock->release();\n\n    std::map<sindex_name_t, secondary_index_t> secondary_indexes;\n    get_secondary_indexes(&sindex_block, &secondary_indexes);\n    sindex_block.reset_buf_lock();\n\n    std::map<std::string, std::pair<sindex_config_t, sindex_status_t> > results;\n    for (const auto &pair : secondary_indexes) {\n        guarantee(pair.first.being_deleted == pair.second.being_deleted);\n        if (pair.second.being_deleted) {\n            continue;\n        }\n        std::pair<sindex_config_t, sindex_status_t> *res = &results[pair.first.name];\n        sindex_disk_info_t disk_info;\n        try {\n            deserialize_sindex_info(pair.second.opaque_definition, &disk_info);\n        } catch (const archive_exc_t &) {\n            crash(\"corrupted sindex definition\");\n        }\n\n        res->first.func = disk_info.mapping;\n        res->first.func_version = disk_info.mapping_version_info.original_reql_version;\n        res->first.multi = disk_info.multi;\n        res->first.geo = disk_info.geo;\n\n        res->second.outdated =\n            disk_info.mapping_version_info.latest_compatible_reql_version !=\n                reql_version_t::LATEST;\n        if (pair.second.is_ready()) {\n            res->second.ready = true;\n            res->second.blocks_processed = res->second.blocks_total = 0;\n        } else {\n            res->second.ready = false;\n            progress_completion_fraction_t frac = get_sindex_progress(pair.second.id);\n            if (frac.estimate_of_total_nodes == -1) {\n                res->second.blocks_processed = res->second.blocks_total = 0;\n            } else {\n                res->second.blocks_processed = frac.estimate_of_released_nodes;\n                res->second.blocks_total = frac.estimate_of_total_nodes;\n            }\n        }\n    }\n\n    return results;\n}\n\nvoid store_t::sindex_create(\n        const std::string &name,\n        const sindex_config_t &config,\n        UNUSED signal_t *interruptor)\n        THROWS_ONLY(interrupted_exc_t) {\n    scoped_ptr_t<real_superblock_t> superblock;\n    scoped_ptr_t<txn_t> txn;\n    get_btree_superblock_and_txn_for_writing(general_cache_conn.get(),\n        &write_superblock_acq_semaphore, write_access_t::write, 1,\n        write_durability_t::HARD, &superblock, &txn);\n    buf_lock_t sindex_block(superblock->expose_buf(),\n                            superblock->get_sindex_block_id(),\n                            access_t::write);\n    superblock->release();\n\n    /* Note that this function allows creating sindexes with older ReQL versions. For\n    example, suppose that the user upgrades to a newer version of RethinkDB, and then\n    they want to add a replica to a table with an outdated secondary index. Then this\n    function would be called to create the outdated secondary index on the new replica.\n    */\n    sindex_reql_version_info_t version_info;\n    version_info.original_reql_version = config.func_version;\n    version_info.latest_compatible_reql_version = config.func_version;\n    version_info.latest_checked_reql_version = reql_version_t::LATEST;\n    sindex_disk_info_t info(config.func, version_info, config.multi, config.geo);\n\n    write_message_t wm;\n    serialize_sindex_info(&wm, info);\n    vector_stream_t stream;\n    stream.reserve(wm.size());\n    int write_res = send_write_message(&stream, &wm);\n    guarantee(write_res == 0);\n\n    sindex_name_t sindex_name(name);\n    bool success = add_sindex_internal(sindex_name, stream.vector(), &sindex_block);\n    guarantee(success, \"sindex_create() called with a sindex name that exists\");\n\n    rdb_protocol::bring_sindexes_up_to_date(\n        std::set<sindex_name_t>{sindex_name}, this, &sindex_block);\n}\n\nvoid store_t::sindex_rename_multi(\n        const std::map<std::string, std::string> &name_changes,\n        UNUSED signal_t *interruptor)\n        THROWS_ONLY(interrupted_exc_t) {\n    scoped_ptr_t<real_superblock_t> superblock;\n    scoped_ptr_t<txn_t> txn;\n    get_btree_superblock_and_txn_for_writing(general_cache_conn.get(),\n        &write_superblock_acq_semaphore, write_access_t::write, 1,\n        write_durability_t::HARD, &superblock, &txn);\n    buf_lock_t sindex_block(superblock->expose_buf(),\n                            superblock->get_sindex_block_id(),\n                            access_t::write);\n    superblock->release();\n\n    /* First we remove all the secondary indexes and hide their perfmons, but put the\n    definitions and `btree_stats_t`s into `to_put_back` indexed by their new names. Then\n    we go through and put them all back under their new names. */\n    std::map<std::string, std::pair<secondary_index_t, btree_stats_t *> > to_put_back;\n\n    for (const auto &pair : name_changes) {\n        secondary_index_t definition;\n        bool success = get_secondary_index(\n            &sindex_block, sindex_name_t(pair.first), &definition);\n        guarantee(success);\n        success = delete_secondary_index(&sindex_block, sindex_name_t(pair.first));\n        guarantee(success);\n\n        auto slice_it = secondary_index_slices.find(definition.id);\n        guarantee(slice_it != secondary_index_slices.end());\n        guarantee(slice_it->second.has());\n        slice_it->second->assert_thread();\n        btree_stats_t *stats = &slice_it->second->stats;\n        stats->hide();\n\n        to_put_back.insert(std::make_pair(\n            pair.second, std::make_pair(definition, stats)));\n    }\n\n    for (const auto &pair : to_put_back) {\n        set_secondary_index(&sindex_block, sindex_name_t(pair.first), pair.second.first);\n        pair.second.second->rename(&perfmon_collection, \"index-\" + pair.first);\n    }\n\n    if (index_report.has()) {\n        index_report->indexes_renamed(name_changes);\n    }\n}\n\nvoid store_t::sindex_drop(\n        const std::string &name,\n        UNUSED signal_t *interruptor)\n        THROWS_ONLY(interrupted_exc_t) {\n    scoped_ptr_t<real_superblock_t> superblock;\n    scoped_ptr_t<txn_t> txn;\n    get_btree_superblock_and_txn_for_writing(general_cache_conn.get(),\n        &write_superblock_acq_semaphore, write_access_t::write, 1,\n        write_durability_t::HARD, &superblock, &txn);\n    buf_lock_t sindex_block(superblock->expose_buf(),\n                            superblock->get_sindex_block_id(),\n                            access_t::write);\n    superblock->release();\n\n    secondary_index_t sindex;\n    bool success = ::get_secondary_index(&sindex_block, sindex_name_t(name), &sindex);\n    guarantee(success, \"sindex_drop() called on sindex that doesn't exist\");\n\n    /* Mark the secondary index as deleted */\n    success = mark_secondary_index_deleted(&sindex_block, sindex_name_t(name));\n    guarantee(success);\n\n    /* Clear the sindex later. It starts its own transaction and we don't\n    want to deadlock because we're still holding locks. */\n    coro_t::spawn_sometime(std::bind(&store_t::delayed_clear_sindex,\n                                     this,\n                                     sindex,\n                                     drainer.lock()));\n\n    if (index_report.has()) {\n        index_report->index_dropped(name);\n    }\n}\n\nnew_mutex_in_line_t store_t::get_in_line_for_sindex_queue(buf_lock_t *sindex_block) {",
        "lookback": "        UNUSED signal_t *interruptor)",
        "lookahead": "    assert_thread();",
        "label": [
            "interleave",
            "complex_conflict"
        ],
        "start_line": 287,
        "end_line": 474,
        "merge_gen_region": null,
        "confidence": 0.5513550043106079,
        "hesitated": true
    }
]