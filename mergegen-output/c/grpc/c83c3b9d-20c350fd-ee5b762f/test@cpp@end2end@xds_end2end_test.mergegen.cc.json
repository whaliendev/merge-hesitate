[
    {
        "a_contents": "  gpr_setenv(\"GRPC_XDS_EXPERIMENTAL_CIRCUIT_BREAKING\", \"true\");",
        "b_contents": "  class TestRpc {\n   public:\n    TestRpc() {}\n\n    void StartRpc(grpc::testing::EchoTestService::Stub* stub) {\n      sender_thread_ = std::thread([this, stub]() {\n        EchoResponse response;\n        EchoRequest request;\n        request.mutable_param()->set_client_cancel_after_us(1 * 1000 * 1000);\n        request.set_message(kRequestMessage);\n        status_ = stub->Echo(&context_, request, &response);\n      });\n    }\n\n    void CancelRpc() {\n      context_.TryCancel();\n      sender_thread_.join();\n    }\n\n   private:\n    std::thread sender_thread_;\n    ClientContext context_;\n    Status status_;\n  };\n\n  gpr_setenv(\"GRPC_XDS_EXPERIMENTAL_CIRCUIT_BREAKING\", \"true\");",
        "base_contents": "  class TestRpc {\n   public:\n    TestRpc() {}\n\n    void StartRpc(grpc::testing::EchoTestService::Stub* stub) {\n      sender_thread_ = std::thread([this, stub]() {\n        EchoResponse response;\n        EchoRequest request;\n        request.mutable_param()->set_client_cancel_after_us(1 * 1000 * 1000);\n        request.set_message(kRequestMessage);\n        status_ = stub->Echo(&context_, request, &response);\n      });\n    }\n\n    void CancelRpc() {\n      context_.TryCancel();\n      sender_thread_.join();\n    }\n\n   private:\n    std::thread sender_thread_;\n    ClientContext context_;\n    Status status_;\n  };\n",
        "res_region": "  gpr_setenv(\"GRPC_XDS_EXPERIMENTAL_CIRCUIT_BREAKING\", \"true\");",
        "lookback": "  constexpr size_t kMaxConcurrentRequests = 10;",
        "lookahead": "  constexpr size_t kMaxConcurrentRequests = 10;",
        "label": [
            "ours",
            "complex_conflict"
        ],
        "start_line": 2414,
        "end_line": 2469,
        "merge_gen_region": null,
        "confidence": 0.6031771898269653,
        "hesitated": true
    },
    {
        "a_contents": "  gpr_unsetenv(\"GRPC_XDS_EXPERIMENTAL_CIRCUIT_BREAKING\");\n}\n\nTEST_P(XdsResolverOnlyTest, CircuitBreakingMultipleChannelsShareCallCounter) {\n  gpr_setenv(\"GRPC_XDS_EXPERIMENTAL_CIRCUIT_BREAKING\", \"true\");\n  constexpr size_t kMaxConcurrentRequests = 10;\n  // Populate new EDS resources.\n  AdsServiceImpl::EdsResourceArgs args({\n      {\"locality0\", GetBackendPorts(0, 1)},\n  });\n  balancers_[0]->ads_service()->SetEdsResource(BuildEdsResource(args));\n  // Update CDS resource to set max concurrent request.\n  CircuitBreakers circuit_breaks;\n  Cluster cluster = default_cluster_;\n  auto* threshold = cluster.mutable_circuit_breakers()->add_thresholds();\n  threshold->set_priority(RoutingPriority::DEFAULT);\n  threshold->mutable_max_requests()->set_value(kMaxConcurrentRequests);\n  balancers_[0]->ads_service()->SetCdsResource(cluster);\n  // Create second channel.\n  auto response_generator2 =\n      grpc_core::MakeRefCounted<grpc_core::FakeResolverResponseGenerator>();\n  auto channel2 = CreateChannel(\n      /*failover_timeout=*/0, /*server_name=*/kServerName,\n      response_generator2.get());\n  auto stub2 = grpc::testing::EchoTestService::NewStub(channel2);\n  // Set resolution results for both channels and for the xDS channel.\n  SetNextResolution({});\n  SetNextResolution({}, response_generator2.get());\n  SetNextResolutionForLbChannelAllBalancers();\n  // Send exactly max_concurrent_requests long RPCs, alternating between\n  // the two channels.\n  LongRunningRpc rpcs[kMaxConcurrentRequests];\n  for (size_t i = 0; i < kMaxConcurrentRequests; ++i) {\n    rpcs[i].StartRpc(i % 2 == 0 ? stub_.get() : stub2.get());\n  }\n  // Wait for all RPCs to be in flight.\n  while (backends_[0]->backend_service()->RpcsWaitingForClientCancel() <\n         kMaxConcurrentRequests) {\n    gpr_sleep_until(gpr_time_add(gpr_now(GPR_CLOCK_REALTIME),\n                                 gpr_time_from_micros(1 * 1000, GPR_TIMESPAN)));\n  }\n  // Sending a RPC now should fail, the error message should tell us\n  // we hit the max concurrent requests limit and got dropped.\n  Status status = SendRpc();\n  EXPECT_FALSE(status.ok());\n  EXPECT_EQ(status.error_message(), \"Call dropped by load balancing policy\");\n  // Cancel one RPC to allow another one through\n  rpcs[0].CancelRpc();\n  status = SendRpc();\n  EXPECT_TRUE(status.ok());\n  for (size_t i = 1; i < kMaxConcurrentRequests; ++i) {\n    rpcs[i].CancelRpc();\n  }\n  // Make sure RPCs go to the correct backend:\n  EXPECT_EQ(kMaxConcurrentRequests + 1,\n            backends_[0]->backend_service()->request_count());\n  gpr_unsetenv(\"GRPC_XDS_EXPERIMENTAL_CIRCUIT_BREAKING\");\n}\n\nTEST_P(XdsResolverOnlyTest, CircuitBreakingDisabled) {\n  constexpr size_t kMaxConcurrentRequests = 10;\n  SetNextResolution({});\n  SetNextResolutionForLbChannelAllBalancers();\n  // Populate new EDS resources.\n  AdsServiceImpl::EdsResourceArgs args({\n      {\"locality0\", GetBackendPorts(0, 1)},\n  });\n  balancers_[0]->ads_service()->SetEdsResource(BuildEdsResource(args));\n  // Update CDS resource to set max concurrent request.\n  CircuitBreakers circuit_breaks;\n  Cluster cluster = default_cluster_;\n  auto* threshold = cluster.mutable_circuit_breakers()->add_thresholds();\n  threshold->set_priority(RoutingPriority::DEFAULT);\n  threshold->mutable_max_requests()->set_value(kMaxConcurrentRequests);\n  balancers_[0]->ads_service()->SetCdsResource(cluster);\n  // Send exactly max_concurrent_requests long RPCs.\n  LongRunningRpc rpcs[kMaxConcurrentRequests];\n  for (size_t i = 0; i < kMaxConcurrentRequests; ++i) {\n    rpcs[i].StartRpc(stub_.get());\n  }\n  // Wait for all RPCs to be in flight.\n  while (backends_[0]->backend_service()->RpcsWaitingForClientCancel() <\n         kMaxConcurrentRequests) {\n    gpr_sleep_until(gpr_time_add(gpr_now(GPR_CLOCK_REALTIME),\n                                 gpr_time_from_micros(1 * 1000, GPR_TIMESPAN)));\n  }\n  // Sending a RPC now should not fail as circuit breaking is disabled.\n  Status status = SendRpc();\n  EXPECT_TRUE(status.ok());\n  for (size_t i = 0; i < kMaxConcurrentRequests; ++i) {\n    rpcs[i].CancelRpc();\n  }\n  // Make sure RPCs go to the correct backend:\n  EXPECT_EQ(kMaxConcurrentRequests + 1,\n            backends_[0]->backend_service()->request_count());",
        "b_contents": "  gpr_unsetenv(\"GRPC_XDS_EXPERIMENTAL_CIRCUIT_BREAKING\");\n}\n\nTEST_P(XdsResolverOnlyTest, CircuitBreakingDisabled) {\n  class TestRpc {\n   public:\n    TestRpc() {}\n\n    void StartRpc(grpc::testing::EchoTestService::Stub* stub) {\n      sender_thread_ = std::thread([this, stub]() {\n        EchoResponse response;\n        EchoRequest request;\n        request.mutable_param()->set_client_cancel_after_us(1 * 1000 * 1000);\n        request.set_message(kRequestMessage);\n        status_ = stub->Echo(&context_, request, &response);\n      });\n    }\n\n    void CancelRpc() {\n      context_.TryCancel();\n      sender_thread_.join();\n    }\n\n   private:\n    std::thread sender_thread_;\n    ClientContext context_;\n    Status status_;\n  };\n\n  constexpr size_t kMaxConcurrentRequests = 10;\n  SetNextResolution({});\n  SetNextResolutionForLbChannelAllBalancers();\n  // Populate new EDS resources.\n  AdsServiceImpl::EdsResourceArgs args({\n      {\"locality0\", GetBackendPorts(0, 1)},\n  });\n  balancers_[0]->ads_service()->SetEdsResource(\n      AdsServiceImpl::BuildEdsResource(args));\n  // Update CDS resource to set max concurrent request.\n  CircuitBreakers circuit_breaks;\n  Cluster cluster = balancers_[0]->ads_service()->default_cluster();\n  auto* threshold = cluster.mutable_circuit_breakers()->add_thresholds();\n  threshold->set_priority(RoutingPriority::DEFAULT);\n  threshold->mutable_max_requests()->set_value(kMaxConcurrentRequests);\n  balancers_[0]->ads_service()->SetCdsResource(cluster);\n  // Send exactly max_concurrent_requests long RPCs.\n  TestRpc rpcs[kMaxConcurrentRequests];\n  for (size_t i = 0; i < kMaxConcurrentRequests; ++i) {\n    rpcs[i].StartRpc(stub_.get());\n  }\n  // Wait for all RPCs to be in flight.\n  while (backends_[0]->backend_service()->RpcsWaitingForClientCancel() <\n         kMaxConcurrentRequests) {\n    gpr_sleep_until(gpr_time_add(gpr_now(GPR_CLOCK_REALTIME),\n                                 gpr_time_from_micros(1 * 1000, GPR_TIMESPAN)));\n  }\n  // Sending a RPC now should not fail as circuit breaking is disabled.\n  Status status = SendRpc();\n  EXPECT_TRUE(status.ok());\n  for (size_t i = 0; i < kMaxConcurrentRequests; ++i) {\n    rpcs[i].CancelRpc();\n  }\n  // Make sure RPCs go to the correct backend:\n  EXPECT_EQ(kMaxConcurrentRequests + 1,\n            backends_[0]->backend_service()->request_count());",
        "base_contents": "",
        "res_region": "  gpr_unsetenv(\"GRPC_XDS_EXPERIMENTAL_CIRCUIT_BREAKING\");\n}\n\nTEST_P(XdsResolverOnlyTest, CircuitBreakingMultipleChannelsShareCallCounter) {\n  gpr_setenv(\"GRPC_XDS_EXPERIMENTAL_CIRCUIT_BREAKING\", \"true\");\n  constexpr size_t kMaxConcurrentRequests = 10;\n  // Populate new EDS resources.\n  AdsServiceImpl::EdsResourceArgs args({\n      {\"locality0\", GetBackendPorts(0, 1)},\n  });\n  balancers_[0]->ads_service()->SetEdsResource(BuildEdsResource(args));\n  // Update CDS resource to set max concurrent request.\n  CircuitBreakers circuit_breaks;\n  Cluster cluster = default_cluster_;\n  auto* threshold = cluster.mutable_circuit_breakers()->add_thresholds();\n  threshold->set_priority(RoutingPriority::DEFAULT);\n  threshold->mutable_max_requests()->set_value(kMaxConcurrentRequests);\n  balancers_[0]->ads_service()->SetCdsResource(cluster);\n  // Create second channel.\n  auto response_generator2 =\n      grpc_core::MakeRefCounted<grpc_core::FakeResolverResponseGenerator>();\n  auto channel2 = CreateChannel(\n      /*failover_timeout=*/0, /*server_name=*/kServerName,\n      response_generator2.get());\n  auto stub2 = grpc::testing::EchoTestService::NewStub(channel2);\n  // Set resolution results for both channels and for the xDS channel.\n  SetNextResolution({});\n  SetNextResolution({}, response_generator2.get());\n  SetNextResolutionForLbChannelAllBalancers();\n  // Send exactly max_concurrent_requests long RPCs, alternating between\n  // the two channels.\n  LongRunningRpc rpcs[kMaxConcurrentRequests];\n  for (size_t i = 0; i < kMaxConcurrentRequests; ++i) {\n    rpcs[i].StartRpc(i % 2 == 0 ? stub_.get() : stub2.get());\n  }\n  // Wait for all RPCs to be in flight.\n  while (backends_[0]->backend_service()->RpcsWaitingForClientCancel() <\n         kMaxConcurrentRequests) {\n    gpr_sleep_until(gpr_time_add(gpr_now(GPR_CLOCK_REALTIME),\n                                 gpr_time_from_micros(1 * 1000, GPR_TIMESPAN)));\n  }\n  // Sending a RPC now should fail, the error message should tell us\n  // we hit the max concurrent requests limit and got dropped.\n  Status status = SendRpc();\n  EXPECT_FALSE(status.ok());\n  EXPECT_EQ(status.error_message(), \"Call dropped by load balancing policy\");\n  // Cancel one RPC to allow another one through\n  rpcs[0].CancelRpc();\n  status = SendRpc();\n  EXPECT_TRUE(status.ok());\n  for (size_t i = 1; i < kMaxConcurrentRequests; ++i) {\n    rpcs[i].CancelRpc();\n  }\n  // Make sure RPCs go to the correct backend:\n  EXPECT_EQ(kMaxConcurrentRequests + 1,\n            backends_[0]->backend_service()->request_count());\n  gpr_unsetenv(\"GRPC_XDS_EXPERIMENTAL_CIRCUIT_BREAKING\");\n}\n\nTEST_P(XdsResolverOnlyTest, CircuitBreakingDisabled) {\n  constexpr size_t kMaxConcurrentRequests = 10;\n  SetNextResolution({});\n  SetNextResolutionForLbChannelAllBalancers();\n  // Populate new EDS resources.\n  AdsServiceImpl::EdsResourceArgs args({\n      {\"locality0\", GetBackendPorts(0, 1)},\n  });\n  balancers_[0]->ads_service()->SetEdsResource(BuildEdsResource(args));\n  // Update CDS resource to set max concurrent request.\n  CircuitBreakers circuit_breaks;\n  Cluster cluster = default_cluster_;\n  auto* threshold = cluster.mutable_circuit_breakers()->add_thresholds();\n  threshold->set_priority(RoutingPriority::DEFAULT);\n  threshold->mutable_max_requests()->set_value(kMaxConcurrentRequests);\n  balancers_[0]->ads_service()->SetCdsResource(cluster);\n  // Send exactly max_concurrent_requests long RPCs.\n  LongRunningRpc rpcs[kMaxConcurrentRequests];\n  for (size_t i = 0; i < kMaxConcurrentRequests; ++i) {\n    rpcs[i].StartRpc(stub_.get());\n  }\n  // Wait for all RPCs to be in flight.\n  while (backends_[0]->backend_service()->RpcsWaitingForClientCancel() <\n         kMaxConcurrentRequests) {\n    gpr_sleep_until(gpr_time_add(gpr_now(GPR_CLOCK_REALTIME),\n                                 gpr_time_from_micros(1 * 1000, GPR_TIMESPAN)));\n  }\n  // Sending a RPC now should not fail as circuit breaking is disabled.\n  Status status = SendRpc();\n  EXPECT_TRUE(status.ok());\n  for (size_t i = 0; i < kMaxConcurrentRequests; ++i) {\n    rpcs[i].CancelRpc();\n  }\n  // Make sure RPCs go to the correct backend:\n  EXPECT_EQ(kMaxConcurrentRequests + 1,\n            backends_[0]->backend_service()->request_count());",
        "lookback": "}",
        "lookahead": "}",
        "label": [
            "ours",
            "one_side_deletion"
        ],
        "start_line": 2511,
        "end_line": 2674,
        "merge_gen_region": null,
        "confidence": 0.6766757965087891,
        "hesitated": true
    }
]