[
    {
        "a_contents": "/******************************************************************************\n * Copyright 2018 The Apollo Authors. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *****************************************************************************/\n#include \"modules/perception/onboard/component/multi_sensor_fusion_component.h\"\n\n#include \"cyber/time/clock.h\"\n#include \"modules/common/util/perf_util.h\"\n#include \"modules/perception/base/object_pool_types.h\"\n#include \"modules/perception/onboard/common_flags/common_flags.h\"\n#include \"modules/perception/onboard/msg_serializer/msg_serializer.h\"\n\nnamespace apollo {\nnamespace perception {\nnamespace onboard {\n\nusing apollo::cyber::common::GetAbsolutePath;\n\nuint32_t MultiSensorFusionComponent::s_seq_num_ = 0;\nstd::mutex MultiSensorFusionComponent::s_mutex_;\n\nbool MultiSensorFusionComponent::Init() {\n  FusionComponentConfig comp_config;\n  if (!GetProtoConfig(&comp_config)) {\n    return false;\n  }\n  AINFO << \"Fusion Component Configs: \" << comp_config.DebugString();\n\n  // to load component configs\n  fusion_name_ = comp_config.fusion_name();\n  fusion_method_ = comp_config.fusion_method();\n  fusion_main_sensor_ = comp_config.fusion_main_sensor();\n  object_in_roi_check_ = comp_config.object_in_roi_check();\n  radius_for_roi_object_check_ = comp_config.radius_for_roi_object_check();\n\n  // read pipeline config\n  std::string sensor_fusion_conf_dir = comp_config.sensor_fusion_conf_dir();\n  std::string sensor_fusion_conf_file = comp_config.sensor_fusion_conf_file();\n\n  std::string work_root = \"\";\n  std::string sensor_fusion_config_path =\n      GetAbsolutePath(sensor_fusion_conf_dir, sensor_fusion_conf_file);\n  sensor_fusion_config_path =\n      GetAbsolutePath(work_root, sensor_fusion_config_path);\n\n  if (!cyber::common::GetProtoFromFile(\n          sensor_fusion_config_path, &multi_sensor_fusion_config_)) {\n    AERROR << \"Read config failed: \" << sensor_fusion_config_path;\n    return false;\n  }\n\n  // init algorithm plugin\n  ACHECK(InitAlgorithmPlugin()) << \"Failed to init algorithm plugin.\";\n  writer_ = node_->CreateWriter<PerceptionObstacles>(\n      comp_config.output_obstacles_channel_name());\n  inner_writer_ = node_->CreateWriter<SensorFrameMessage>(\n      comp_config.output_viz_fused_content_channel_name());\n  return true;\n}\n\nbool MultiSensorFusionComponent::Proc(\n  const std::shared_ptr<SensorFrameMessage>& message) {\n  if (message->process_stage_ == ProcessStage::SENSOR_FUSION) {\n    return true;\n  }\n  std::shared_ptr<PerceptionObstacles> out_message(new (std::nothrow)\n                                                       PerceptionObstacles);\n  std::shared_ptr<SensorFrameMessage> viz_message(new (std::nothrow)\n                                                      SensorFrameMessage);\n  bool status = InternalProc(message, out_message, viz_message);\n  if (status) {\n    // TODO(conver sensor id)\n    if (message->sensor_id_ != fusion_main_sensor_) {\n      AINFO << \"Fusion receive from \" << message->sensor_id_ << \"not from \"\n            << fusion_main_sensor_ << \". Skip send.\";\n    } else {\n      // Send(\"/apollo/perception/obstacles\", out_message);\n      writer_->Write(out_message);\n      AINFO << \"Send fusion processing output message.\";\n      // send msg for visualization\n      if (FLAGS_obs_enable_visualization) {\n        // Send(\"/apollo/perception/inner/PrefusedObjects\", viz_message);\n        inner_writer_->Write(viz_message);\n      }\n    }\n  }\n  return status;\n}\n\nbool MultiSensorFusionComponent::InitAlgorithmPlugin() {\n  fusion::BaseMultiSensorFusion* fusion =\n    fusion::BaseMultiSensorFusionRegisterer::GetInstanceByName(fusion_name_);\n  CHECK_NOTNULL(fusion);\n  fusion_.reset(fusion);\n  // fusion::ObstacleMultiSensorFusionParam param;\n  // param.main_sensor = fusion_main_sensor_;\n  // param.fusion_method = fusion_method_;\n  // ACHECK(fusion_->Init(param)) << \"Failed to init ObstacleMultiSensorFusion\";\n\n  ACHECK(fusion_->Init(multi_sensor_fusion_config_))\n      << \"Failed to init ObstacleMultiSensorFusion\";\n\n  if (FLAGS_obs_enable_hdmap_input && object_in_roi_check_) {\n    hdmap_input_ = map::HDMapInput::Instance();\n    ACHECK(hdmap_input_->Init()) << \"Failed to init hdmap input.\";\n  }\n  AINFO << \"Init algorithm successfully, onboard fusion: \" << fusion_method_;\n  return true;\n}\n\nbool MultiSensorFusionComponent::InternalProc(\n    const std::shared_ptr<SensorFrameMessage const>& in_message,\n    std::shared_ptr<PerceptionObstacles> out_message,\n    std::shared_ptr<SensorFrameMessage> viz_message) {\n  {\n    std::unique_lock<std::mutex> lock(s_mutex_);\n    s_seq_num_++;\n  }\n\n  PERF_BLOCK_START();\n  const double timestamp = in_message->timestamp_;\n  const uint64_t lidar_timestamp = in_message->lidar_timestamp_;\n  std::vector<base::ObjectPtr> valid_objects;\n  if (in_message->error_code_ != apollo::common::ErrorCode::OK) {\n    if (!MsgSerializer::SerializeMsg(\n            timestamp, lidar_timestamp, in_message->seq_num_, valid_objects,\n            in_message->error_code_, out_message.get())) {\n      AERROR << \"Failed to gen PerceptionObstacles object.\";\n      return false;\n    }\n    if (FLAGS_obs_enable_visualization) {\n      viz_message->process_stage_ = ProcessStage::SENSOR_FUSION;\n      viz_message->error_code_ = in_message->error_code_;\n    }\n    AERROR << \"Fusion receive message with error code, skip it.\";\n    return true;\n  }\n\n  pipeline::DataFrame data_frame;\n  fusion::FusionFrame fusion_frame;\n  data_frame.fusion_frame = &fusion_frame;\n\n  fusion_frame.frame = in_message->frame_;\n  fusion_frame.frame->timestamp = in_message->timestamp_;\n  if (!fusion_->Process(&data_frame)) {\n    AERROR << \"Failed to call fusion plugin.\";\n    return false;\n  }\n  std::vector<base::ObjectPtr>& fused_objects = fusion_frame.fused_objects;\n\n  // base::FramePtr frame = in_message->frame_;\n  // frame->timestamp = in_message->timestamp_;\n\n  // std::vector<base::ObjectPtr> fused_objects;\n  // if (!fusion_->Process(frame, &fused_objects)) {\n  //   AERROR << \"Failed to call fusion plugin.\";\n  //   return false;\n  // }\n\n  PERF_BLOCK_END_WITH_INDICATOR(\"fusion_process\", in_message->sensor_id_);\n\n  if (in_message->sensor_id_ != fusion_main_sensor_) {\n    return true;\n  }\n\n  Eigen::Matrix4d sensor2world_pose =\n      in_message->frame_->sensor2world_pose.matrix();\n  if (object_in_roi_check_ && FLAGS_obs_enable_hdmap_input) {\n    // get hdmap\n    base::HdmapStructPtr hdmap(new base::HdmapStruct());\n    if (hdmap_input_) {\n      base::PointD position;\n      position.x = sensor2world_pose(0, 3);\n      position.y = sensor2world_pose(1, 3);\n      position.z = sensor2world_pose(2, 3);\n      hdmap_input_->GetRoiHDMapStruct(position, radius_for_roi_object_check_,\n                                      hdmap);\n      // TODO(use check)\n      // ObjectInRoiSlackCheck(hdmap, fused_objects, &valid_objects);\n      valid_objects.assign(fused_objects.begin(), fused_objects.end());\n    } else {\n      valid_objects.assign(fused_objects.begin(), fused_objects.end());\n    }\n  } else {\n    valid_objects.assign(fused_objects.begin(), fused_objects.end());\n  }\n  PERF_BLOCK_END_WITH_INDICATOR(\"fusion_roi_check\", in_message->sensor_id_);\n\n  // produce visualization msg\n  if (FLAGS_obs_enable_visualization) {\n    viz_message->timestamp_ = in_message->timestamp_;\n    viz_message->seq_num_ = in_message->seq_num_;\n    viz_message->frame_ = base::FramePool::Instance().Get();\n    viz_message->frame_->sensor2world_pose =\n        in_message->frame_->sensor2world_pose;\n    viz_message->sensor_id_ = in_message->sensor_id_;\n    viz_message->hdmap_ = in_message->hdmap_;\n    viz_message->process_stage_ = ProcessStage::SENSOR_FUSION;\n    viz_message->error_code_ = in_message->error_code_;\n    viz_message->frame_->objects = fused_objects;\n  }\n  // produce pb output msg\n  apollo::common::ErrorCode error_code = apollo::common::ErrorCode::OK;\n  if (!MsgSerializer::SerializeMsg(timestamp, lidar_timestamp,\n                                   in_message->seq_num_, valid_objects,\n                                   error_code, out_message.get())) {\n    AERROR << \"Failed to gen PerceptionObstacles object.\";\n    return false;\n  }\n  PERF_BLOCK_END_WITH_INDICATOR(\"fusion_serialize_message\",\n                                in_message->sensor_id_);\n\n  const double cur_time = ::apollo::cyber::Clock::NowInSeconds();\n  const double latency = (cur_time - timestamp) * 1e3;\n  AINFO << std::setprecision(16) << \"FRAME_STATISTICS:Obstacle:End:msg_time[\"\n        << timestamp << \"]:cur_time[\" << cur_time << \"]:cur_latency[\" << latency\n        << \"]:obj_cnt[\" << valid_objects.size() << \"]\";\n  AINFO << \"publish_number: \" << valid_objects.size() << \" obj\";\n  return true;\n}\n\n}  // namespace onboard\n}  // namespace perception\n}  // namespace apollo",
        "b_contents": "/******************************************************************************\n * Copyright 2018 The Apollo Authors. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *****************************************************************************/\n#include \"modules/perception/onboard/component/multi_sensor_fusion_component.h\"\n\n#include \"cyber/time/clock.h\"\n#include \"modules/common/util/perf_util.h\"\n#include \"modules/perception/base/object_pool_types.h\"\n#include \"modules/perception/onboard/common_flags/common_flags.h\"\n#include \"modules/perception/onboard/msg_serializer/msg_serializer.h\"\n\nnamespace apollo {\nnamespace perception {\nnamespace onboard {\n\nusing apollo::cyber::common::GetAbsolutePath;\n\nuint32_t MultiSensorFusionComponent::s_seq_num_ = 0;\nstd::mutex MultiSensorFusionComponent::s_mutex_;\n\nbool MultiSensorFusionComponent::Init() {\n  FusionComponentConfig comp_config;\n  if (!GetProtoConfig(&comp_config)) {\n    return false;\n  }\n  AINFO << \"Fusion Component Configs: \" << comp_config.DebugString();\n\n  // to load component configs\n  fusion_name_ = comp_config.fusion_name();\n  fusion_method_ = comp_config.fusion_method();\n  fusion_main_sensor_ = comp_config.fusion_main_sensor();\n  object_in_roi_check_ = comp_config.object_in_roi_check();\n  radius_for_roi_object_check_ = comp_config.radius_for_roi_object_check();\n\n  // read pipeline config\n  std::string sensor_fusion_conf_dir = comp_config.sensor_fusion_conf_dir();\n  std::string sensor_fusion_conf_file = comp_config.sensor_fusion_conf_file();\n\n  std::string work_root = \"\";\n  std::string sensor_fusion_config_path =\n      GetAbsolutePath(sensor_fusion_conf_dir, sensor_fusion_conf_file);\n  sensor_fusion_config_path =\n      GetAbsolutePath(work_root, sensor_fusion_config_path);\n\n  if (!cyber::common::GetProtoFromFile(\n          sensor_fusion_config_path, &multi_sensor_fusion_config_)) {\n    AERROR << \"Read config failed: \" << sensor_fusion_config_path;\n    return false;\n  }\n\n  // init algorithm plugin\n  ACHECK(InitAlgorithmPlugin()) << \"Failed to init algorithm plugin.\";\n  writer_ = node_->CreateWriter<PerceptionObstacles>(\n      comp_config.output_obstacles_channel_name());\n  inner_writer_ = node_->CreateWriter<SensorFrameMessage>(\n      comp_config.output_viz_fused_content_channel_name());\n  return true;\n}\n\nbool MultiSensorFusionComponent::Proc(const std::shared_ptr<SensorFrameMessage>& message) {\n  if (message->process_stage_ == ProcessStage::SENSOR_FUSION) {\n    return true;\n  }\n  std::shared_ptr<PerceptionObstacles> out_message(new (std::nothrow)\n                                                       PerceptionObstacles);\n  std::shared_ptr<SensorFrameMessage> viz_message(new (std::nothrow)\n                                                      SensorFrameMessage);\n  bool status = InternalProc(message, out_message, viz_message);\n  if (status) {\n    // TODO(conver sensor id)\n    if (message->sensor_id_ != fusion_main_sensor_) {\n      AINFO << \"Fusion receive from \" << message->sensor_id_ << \"not from \"\n            << fusion_main_sensor_ << \". Skip send.\";\n    } else {\n      // Send(\"/apollo/perception/obstacles\", out_message);\n      writer_->Write(out_message);\n      AINFO << \"Send fusion processing output message.\";\n      // send msg for visualization\n      if (FLAGS_obs_enable_visualization) {\n        // Send(\"/apollo/perception/inner/PrefusedObjects\", viz_message);\n        inner_writer_->Write(viz_message);\n      }\n    }\n  }\n  return status;\n}\n\nbool MultiSensorFusionComponent::InitAlgorithmPlugin() {\n  fusion::BaseMultiSensorFusion* fusion =\n    fusion::BaseMultiSensorFusionRegisterer::GetInstanceByName(fusion_name_);\n  CHECK_NOTNULL(fusion);\n  fusion_.reset(fusion);\n  // fusion::ObstacleMultiSensorFusionParam param;\n  // param.main_sensor = fusion_main_sensor_;\n  // param.fusion_method = fusion_method_;\n  // ACHECK(fusion_->Init(param)) << \"Failed to init ObstacleMultiSensorFusion\";\n\n  ACHECK(fusion_->Init(multi_sensor_fusion_config_))\n      << \"Failed to init ObstacleMultiSensorFusion\";\n\n  if (FLAGS_obs_enable_hdmap_input && object_in_roi_check_) {\n    hdmap_input_ = map::HDMapInput::Instance();\n    ACHECK(hdmap_input_->Init()) << \"Failed to init hdmap input.\";\n  }\n  AINFO << \"Init algorithm successfully, onboard fusion: \" << fusion_method_;\n  return true;\n}\n\nbool MultiSensorFusionComponent::InternalProc(\n    const std::shared_ptr<SensorFrameMessage const>& in_message,\n    std::shared_ptr<PerceptionObstacles> out_message,\n    std::shared_ptr<SensorFrameMessage> viz_message) {\n  {\n    std::unique_lock<std::mutex> lock(s_mutex_);\n    s_seq_num_++;\n  }\n\n  PERF_BLOCK_START();\n  const double timestamp = in_message->timestamp_;\n  const uint64_t lidar_timestamp = in_message->lidar_timestamp_;\n  std::vector<base::ObjectPtr> valid_objects;\n  if (in_message->error_code_ != apollo::common::ErrorCode::OK) {\n    if (!MsgSerializer::SerializeMsg(\n            timestamp, lidar_timestamp, in_message->seq_num_, valid_objects,\n            in_message->error_code_, out_message.get())) {\n      AERROR << \"Failed to gen PerceptionObstacles object.\";\n      return false;\n    }\n    if (FLAGS_obs_enable_visualization) {\n      viz_message->process_stage_ = ProcessStage::SENSOR_FUSION;\n      viz_message->error_code_ = in_message->error_code_;\n    }\n    AERROR << \"Fusion receive message with error code, skip it.\";\n    return true;\n  }\n\n  pipeline::DataFrame data_frame;\n  fusion::FusionFrame fusion_frame;\n  data_frame.fusion_frame = &fusion_frame;\n\n  fusion_frame.frame = in_message->frame_;\n  fusion_frame.frame->timestamp = in_message->timestamp_;\n  if (!fusion_->Process(&data_frame)) {\n    AERROR << \"Failed to call fusion plugin.\";\n    return false;\n  }\n  std::vector<base::ObjectPtr>& fused_objects = fusion_frame.fused_objects;\n\n  // base::FramePtr frame = in_message->frame_;\n  // frame->timestamp = in_message->timestamp_;\n\n  // std::vector<base::ObjectPtr> fused_objects;\n  // if (!fusion_->Process(frame, &fused_objects)) {\n  //   AERROR << \"Failed to call fusion plugin.\";\n  //   return false;\n  // }\n\n  PERF_BLOCK_END_WITH_INDICATOR(\"fusion_process\", in_message->sensor_id_);\n\n  if (in_message->sensor_id_ != fusion_main_sensor_) {\n    return true;\n  }\n\n  Eigen::Matrix4d sensor2world_pose =\n      in_message->frame_->sensor2world_pose.matrix();\n  if (object_in_roi_check_ && FLAGS_obs_enable_hdmap_input) {\n    // get hdmap\n    base::HdmapStructPtr hdmap(new base::HdmapStruct());\n    if (hdmap_input_) {\n      base::PointD position;\n      position.x = sensor2world_pose(0, 3);\n      position.y = sensor2world_pose(1, 3);\n      position.z = sensor2world_pose(2, 3);\n      hdmap_input_->GetRoiHDMapStruct(position, radius_for_roi_object_check_,\n                                      hdmap);\n      // TODO(use check)\n      // ObjectInRoiSlackCheck(hdmap, fused_objects, &valid_objects);\n      valid_objects.assign(fused_objects.begin(), fused_objects.end());\n    } else {\n      valid_objects.assign(fused_objects.begin(), fused_objects.end());\n    }\n  } else {\n    valid_objects.assign(fused_objects.begin(), fused_objects.end());\n  }\n  PERF_BLOCK_END_WITH_INDICATOR(\"fusion_roi_check\", in_message->sensor_id_);\n\n  // produce visualization msg\n  if (FLAGS_obs_enable_visualization) {\n    viz_message->timestamp_ = in_message->timestamp_;\n    viz_message->seq_num_ = in_message->seq_num_;\n    viz_message->frame_ = base::FramePool::Instance().Get();\n    viz_message->frame_->sensor2world_pose =\n        in_message->frame_->sensor2world_pose;\n    viz_message->sensor_id_ = in_message->sensor_id_;\n    viz_message->hdmap_ = in_message->hdmap_;\n    viz_message->process_stage_ = ProcessStage::SENSOR_FUSION;\n    viz_message->error_code_ = in_message->error_code_;\n    viz_message->frame_->objects = fused_objects;\n  }\n  // produce pb output msg\n  apollo::common::ErrorCode error_code = apollo::common::ErrorCode::OK;\n  if (!MsgSerializer::SerializeMsg(timestamp, lidar_timestamp,\n                                   in_message->seq_num_, valid_objects,\n                                   error_code, out_message.get())) {\n    AERROR << \"Failed to gen PerceptionObstacles object.\";\n    return false;\n  }\n  PERF_BLOCK_END_WITH_INDICATOR(\"fusion_serialize_message\",\n                                in_message->sensor_id_);\n\n  const double cur_time = ::apollo::cyber::Clock::NowInSeconds();\n  const double latency = (cur_time - timestamp) * 1e3;\n  AINFO << std::setprecision(16) << \"FRAME_STATISTICS:Obstacle:End:msg_time[\"\n        << timestamp << \"]:cur_time[\" << cur_time << \"]:cur_latency[\" << latency\n        << \"]:obj_cnt[\" << valid_objects.size() << \"]\";\n  AINFO << \"publish_number: \" << valid_objects.size() << \" obj\";\n  return true;\n}\n\n}  // namespace onboard\n}  // namespace perception\n}  // namespace apollo",
        "base_contents": "",
        "res_region": "/******************************************************************************\n * Copyright 2018 The Apollo Authors. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *****************************************************************************/\n#include \"modules/perception/onboard/component/multi_sensor_fusion_component.h\"\n\n#include \"cyber/time/clock.h\"\n#include \"modules/common/util/perf_util.h\"\n#include \"modules/perception/base/object_pool_types.h\"\n#include \"modules/perception/onboard/common_flags/common_flags.h\"\n#include \"modules/perception/onboard/msg_serializer/msg_serializer.h\"\n\nnamespace apollo {\nnamespace perception {\nnamespace onboard {\n\nusing apollo::cyber::common::GetAbsolutePath;\n\nuint32_t MultiSensorFusionComponent::s_seq_num_ = 0;\nstd::mutex MultiSensorFusionComponent::s_mutex_;\n\nbool MultiSensorFusionComponent::Init() {\n  FusionComponentConfig comp_config;\n  if (!GetProtoConfig(&comp_config)) {\n    return false;\n  }\n  AINFO << \"Fusion Component Configs: \" << comp_config.DebugString();\n\n  // to load component configs\n  fusion_name_ = comp_config.fusion_name();\n  fusion_method_ = comp_config.fusion_method();\n  fusion_main_sensor_ = comp_config.fusion_main_sensor();\n  object_in_roi_check_ = comp_config.object_in_roi_check();\n  radius_for_roi_object_check_ = comp_config.radius_for_roi_object_check();\n\n  // read pipeline config\n  std::string sensor_fusion_conf_dir = comp_config.sensor_fusion_conf_dir();\n  std::string sensor_fusion_conf_file = comp_config.sensor_fusion_conf_file();\n\n  std::string work_root = \"\";\n  std::string sensor_fusion_config_path =\n      GetAbsolutePath(sensor_fusion_conf_dir, sensor_fusion_conf_file);\n  sensor_fusion_config_path =\n      GetAbsolutePath(work_root, sensor_fusion_config_path);\n\n  if (!cyber::common::GetProtoFromFile(\n          sensor_fusion_config_path, &multi_sensor_fusion_config_)) {\n    AERROR << \"Read config failed: \" << sensor_fusion_config_path;\n    return false;\n  }\n\n  // init algorithm plugin\n  ACHECK(InitAlgorithmPlugin()) << \"Failed to init algorithm plugin.\";\n  writer_ = node_->CreateWriter<PerceptionObstacles>(\n      comp_config.output_obstacles_channel_name());\n  inner_writer_ = node_->CreateWriter<SensorFrameMessage>(\n      comp_config.output_viz_fused_content_channel_name());\n  return true;\n}\n\nbool MultiSensorFusionComponent::Proc(\n  const std::shared_ptr<SensorFrameMessage>& message) {\n  if (message->process_stage_ == ProcessStage::SENSOR_FUSION) {\n    return true;\n  }\n  std::shared_ptr<PerceptionObstacles> out_message(new (std::nothrow)\n                                                       PerceptionObstacles);\n  std::shared_ptr<SensorFrameMessage> viz_message(new (std::nothrow)\n                                                      SensorFrameMessage);\n  bool status = InternalProc(message, out_message, viz_message);\n  if (status) {\n    // TODO(conver sensor id)\n    if (message->sensor_id_ != fusion_main_sensor_) {\n      AINFO << \"Fusion receive from \" << message->sensor_id_ << \"not from \"\n            << fusion_main_sensor_ << \". Skip send.\";\n    } else {\n      // Send(\"/apollo/perception/obstacles\", out_message);\n      writer_->Write(out_message);\n      AINFO << \"Send fusion processing output message.\";\n      // send msg for visualization\n      if (FLAGS_obs_enable_visualization) {\n        // Send(\"/apollo/perception/inner/PrefusedObjects\", viz_message);\n        inner_writer_->Write(viz_message);\n      }\n    }\n  }\n  return status;\n}\n\nbool MultiSensorFusionComponent::InitAlgorithmPlugin() {\n  fusion::BaseMultiSensorFusion* fusion =\n    fusion::BaseMultiSensorFusionRegisterer::GetInstanceByName(fusion_name_);\n  CHECK_NOTNULL(fusion);\n  fusion_.reset(fusion);\n  // fusion::ObstacleMultiSensorFusionParam param;\n  // param.main_sensor = fusion_main_sensor_;\n  // param.fusion_method = fusion_method_;\n  // ACHECK(fusion_->Init(param)) << \"Failed to init ObstacleMultiSensorFusion\";\n\n  ACHECK(fusion_->Init(multi_sensor_fusion_config_))\n      << \"Failed to init ObstacleMultiSensorFusion\";\n\n  if (FLAGS_obs_enable_hdmap_input && object_in_roi_check_) {\n    hdmap_input_ = map::HDMapInput::Instance();\n    ACHECK(hdmap_input_->Init()) << \"Failed to init hdmap input.\";\n  }\n  AINFO << \"Init algorithm successfully, onboard fusion: \" << fusion_method_;\n  return true;\n}\n\nbool MultiSensorFusionComponent::InternalProc(\n    const std::shared_ptr<SensorFrameMessage const>& in_message,\n    std::shared_ptr<PerceptionObstacles> out_message,\n    std::shared_ptr<SensorFrameMessage> viz_message) {\n  {\n    std::unique_lock<std::mutex> lock(s_mutex_);\n    s_seq_num_++;\n  }\n\n  PERF_BLOCK_START();\n  const double timestamp = in_message->timestamp_;\n  const uint64_t lidar_timestamp = in_message->lidar_timestamp_;\n  std::vector<base::ObjectPtr> valid_objects;\n  if (in_message->error_code_ != apollo::common::ErrorCode::OK) {\n    if (!MsgSerializer::SerializeMsg(\n            timestamp, lidar_timestamp, in_message->seq_num_, valid_objects,\n            in_message->error_code_, out_message.get())) {\n      AERROR << \"Failed to gen PerceptionObstacles object.\";\n      return false;\n    }\n    if (FLAGS_obs_enable_visualization) {\n      viz_message->process_stage_ = ProcessStage::SENSOR_FUSION;\n      viz_message->error_code_ = in_message->error_code_;\n    }\n    AERROR << \"Fusion receive message with error code, skip it.\";\n    return true;\n  }\n\n  pipeline::DataFrame data_frame;\n  fusion::FusionFrame fusion_frame;\n  data_frame.fusion_frame = &fusion_frame;\n\n  fusion_frame.frame = in_message->frame_;\n  fusion_frame.frame->timestamp = in_message->timestamp_;\n  if (!fusion_->Process(&data_frame)) {\n    AERROR << \"Failed to call fusion plugin.\";\n    return false;\n  }\n  std::vector<base::ObjectPtr>& fused_objects = fusion_frame.fused_objects;\n\n  // base::FramePtr frame = in_message->frame_;\n  // frame->timestamp = in_message->timestamp_;\n\n  // std::vector<base::ObjectPtr> fused_objects;\n  // if (!fusion_->Process(frame, &fused_objects)) {\n  //   AERROR << \"Failed to call fusion plugin.\";\n  //   return false;\n  // }\n\n  PERF_BLOCK_END_WITH_INDICATOR(\"fusion_process\", in_message->sensor_id_);\n\n  if (in_message->sensor_id_ != fusion_main_sensor_) {\n    return true;\n  }\n\n  Eigen::Matrix4d sensor2world_pose =\n      in_message->frame_->sensor2world_pose.matrix();\n  if (object_in_roi_check_ && FLAGS_obs_enable_hdmap_input) {\n    // get hdmap\n    base::HdmapStructPtr hdmap(new base::HdmapStruct());\n    if (hdmap_input_) {\n      base::PointD position;\n      position.x = sensor2world_pose(0, 3);\n      position.y = sensor2world_pose(1, 3);\n      position.z = sensor2world_pose(2, 3);\n      hdmap_input_->GetRoiHDMapStruct(position, radius_for_roi_object_check_,\n                                      hdmap);\n      // TODO(use check)\n      // ObjectInRoiSlackCheck(hdmap, fused_objects, &valid_objects);\n      valid_objects.assign(fused_objects.begin(), fused_objects.end());\n    } else {\n      valid_objects.assign(fused_objects.begin(), fused_objects.end());\n    }\n  } else {\n    valid_objects.assign(fused_objects.begin(), fused_objects.end());\n  }\n  PERF_BLOCK_END_WITH_INDICATOR(\"fusion_roi_check\", in_message->sensor_id_);\n\n  // produce visualization msg\n  if (FLAGS_obs_enable_visualization) {\n    viz_message->timestamp_ = in_message->timestamp_;\n    viz_message->seq_num_ = in_message->seq_num_;\n    viz_message->frame_ = base::FramePool::Instance().Get();\n    viz_message->frame_->sensor2world_pose =\n        in_message->frame_->sensor2world_pose;\n    viz_message->sensor_id_ = in_message->sensor_id_;\n    viz_message->hdmap_ = in_message->hdmap_;\n    viz_message->process_stage_ = ProcessStage::SENSOR_FUSION;\n    viz_message->error_code_ = in_message->error_code_;\n    viz_message->frame_->objects = fused_objects;\n  }\n  // produce pb output msg\n  apollo::common::ErrorCode error_code = apollo::common::ErrorCode::OK;\n  if (!MsgSerializer::SerializeMsg(timestamp, lidar_timestamp,\n                                   in_message->seq_num_, valid_objects,\n                                   error_code, out_message.get())) {\n    AERROR << \"Failed to gen PerceptionObstacles object.\";\n    return false;\n  }\n  PERF_BLOCK_END_WITH_INDICATOR(\"fusion_serialize_message\",\n                                in_message->sensor_id_);\n\n  const double cur_time = ::apollo::cyber::Clock::NowInSeconds();\n  const double latency = (cur_time - timestamp) * 1e3;\n  AINFO << std::setprecision(16) << \"FRAME_STATISTICS:Obstacle:End:msg_time[\"\n        << timestamp << \"]:cur_time[\" << cur_time << \"]:cur_latency[\" << latency\n        << \"]:obj_cnt[\" << valid_objects.size() << \"]\";\n  AINFO << \"publish_number: \" << valid_objects.size() << \" obj\";\n  return true;\n}\n\n}  // namespace onboard\n}  // namespace perception\n}  // namespace apollo",
        "lookback": " * Copyright 2018 The Apollo Authors. All Rights Reserved.",
        "lookahead": "",
        "label": [
            "ours",
            "base_underutilized"
        ],
        "start_line": 0,
        "end_line": 472,
        "merge_gen_region": " Copyright Thepol Authors All Reserved/****************************************************************************** Copyright Thepol Authors All Reserved * Licensed the Apache, 20theLicense * may use file in with the. You obtain copy the License * may a of License * *://../licensesLICENSE20 * Unless by law agreed in,, * to writing software distributed the is on \" IS BASIS * WARRANTIES CONDITIONS ANY, either or. See License the for specific governing and limitations the License *****************************************************************************/includemodulesper/boardcomponentmultisensorfusioncomponenth # \"bertimeclockh # \"/commonutilperfutilh # \"/ceptionbaseobjectpooltypesh # \"/per/boardcommonflagscommonflagsh # \"/per///__.\"includemodulesper/boardmsgserializermsgserializerhh namespacepol { namespaceception namespaceboard usingpol::bercommonGetPath uint_ MultiFusion::________ 0 stdmutexSensorusion::__; MultiFComponentInit {usionConfig compconfig ifGetConfig(&_)) return; A <<F Components \" comp_.(); to component config fusionname =_.fusionname fusionmethod =_.__(); fusionmainsensor =__.___();_____ =__",
        "confidence": 0.9346351027488708,
        "hesitated": false,
        "resolved": false
    }
]