[
    {
        "a_contents": "/******************************************************************************\n * Copyright 2021 The Apollo Authors. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *****************************************************************************/\n\n#include \"modules/prediction/evaluator/vehicle/jointly_prediction_planning_evaluator.h\"\n\n#include <limits>\n#include <omp.h>\n\n#include \"Eigen/Dense\"\n#include \"cyber/common/file.h\"\n#include \"modules/common/math/linear_interpolation.h\"\n#include \"modules/prediction/common/prediction_gflags.h\"\n#include \"modules/prediction/common/prediction_map.h\"\n#include \"modules/prediction/common/prediction_system_gflags.h\"\n#include \"modules/prediction/common/prediction_util.h\"\n#include \"modules/prediction/container/adc_trajectory/adc_trajectory_container.h\"\n\nnamespace apollo {\nnamespace prediction {\n\nusing apollo::common::TrajectoryPoint;\nusing apollo::common::math::Vec2d;\nusing apollo::common::math::InterpolateUsingLinearApproximation;\nusing apollo::prediction::VectorNet;\n\nJointlyPredictionPlanningEvaluator::JointlyPredictionPlanningEvaluator()\n    : device_(torch::kCPU) {\n  evaluator_type_ = ObstacleConf::JOINTLY_PREDICTION_PLANNING_EVALUATOR;\n  LoadModel();\n}\n\nvoid JointlyPredictionPlanningEvaluator::Clear() {}\n\nbool JointlyPredictionPlanningEvaluator::Evaluate(Obstacle* obstacle_ptr,\n                                     ObstaclesContainer* obstacles_container) {\n  const ADCTrajectoryContainer* adc_trajectory_container;\n  Evaluate(adc_trajectory_container, obstacle_ptr, obstacles_container);\n  return true;\n}\n\nbool JointlyPredictionPlanningEvaluator::Evaluate(\n      const ADCTrajectoryContainer* adc_trajectory_container,\n      Obstacle* obstacle_ptr,\n      ObstaclesContainer* obstacles_container) {\n  omp_set_num_threads(1);\n\n  obstacle_ptr->SetEvaluatorType(evaluator_type_);\n\n  Clear();\n  CHECK_NOTNULL(obstacle_ptr);\n  int id = obstacle_ptr->id();\n  if (!obstacle_ptr->latest_feature().IsInitialized()) {\n    AERROR << \"Obstacle [\" << id << \"] has no latest feature.\";\n    return false;\n  }\n  Feature* latest_feature_ptr = obstacle_ptr->mutable_latest_feature();\n  CHECK_NOTNULL(latest_feature_ptr);\n\n  if (adc_trajectory_container == nullptr) {\n    AERROR << \"Null adc trajectory container\";\n    return false;\n  }\n\n  // obs data vector\n  // Extract features of pos_history\n  std::vector<std::pair<double, double>> target_pos_history(20, {0.0, 0.0});\n  std::vector<std::pair<double, double>> all_obs_length;\n  std::vector<std::vector<std::pair<double, double>>> all_obs_pos_history;\n  if (!ExtractObstaclesHistory(obstacle_ptr, obstacles_container,\n                               &target_pos_history, &all_obs_length,\n                               &all_obs_pos_history)) {\n    ADEBUG << \"Obstacle [\" << id << \"] failed to extract obstacle history\";\n    return false;\n  }\n\n  // Query the map data vector\n  FeatureVector map_feature;\n  PidVector map_p_id;\n  double pos_x = latest_feature_ptr->position().x();\n  double pos_y = latest_feature_ptr->position().y();\n  common::PointENU center_point;\n  center_point.set_x(pos_x);\n  center_point.set_y(pos_y);\n  double heading = latest_feature_ptr->velocity_heading();\n\n  auto start_time_query = std::chrono::system_clock::now();\n\n  if (!vector_net_.query(center_point, heading, &map_feature, &map_p_id)) {\n    return false;\n  }\n\n  auto end_time_query = std::chrono::system_clock::now();\n  std::chrono::duration<double> diff_query = end_time_query - start_time_query;\n  ADEBUG << \"vectors query used time: \" << diff_query.count() * 1000 << \" ms.\";\n\n  // Process all obs pos_history & obs pid\n  auto start_time_data_prep = std::chrono::system_clock::now();\n  int obs_num =\n      obstacles_container->curr_frame_considered_obstacle_ids().size();\n  torch::Tensor target_obstacle_pos = torch::zeros({20, 2});\n  torch::Tensor target_obstacle_pos_step = torch::zeros({20, 2});\n  torch::Tensor all_obstacle_pos = torch::zeros({obs_num, 20, 2});\n  torch::Tensor all_obs_p_id = torch::zeros({obs_num, 2});\n  for (int i = 0; i < obs_num; ++i) {\n    std::vector<double> obs_p_id{std::numeric_limits<float>::max(),\n                              std::numeric_limits<float>::max()};\n    for (int j = 0; j < 20; ++j) {\n      // Process obs pid\n      if (obs_p_id[0] > std::abs(all_obs_pos_history[i][j].first)) {\n        obs_p_id[0] = std::abs(all_obs_pos_history[i][j].first);\n        all_obs_p_id[i][0] = obs_p_id[0];\n      }\n      if (obs_p_id[1] > std::abs(all_obs_pos_history[i][j].second)) {\n        obs_p_id[1] = std::abs(all_obs_pos_history[i][j].second);\n        all_obs_p_id[i][1] = obs_p_id[1];\n      }\n      // Process obs pos history\n      target_obstacle_pos[19 - j][0] = target_pos_history[j].first;\n      target_obstacle_pos[19 - j][1] = target_pos_history[j].second;\n      all_obstacle_pos[i][19 - j][0] = all_obs_pos_history[i][j].first;\n      all_obstacle_pos[i][19 - j][1] = all_obs_pos_history[i][j].second;\n      if (j == 19 || (j > 0 && target_pos_history[j].first == 0.0)) {\n        break;\n      }\n      target_obstacle_pos_step[19 - j][0] =\n          target_pos_history[j].first - target_pos_history[j + 1].first;\n      target_obstacle_pos_step[19 - j][1] =\n          target_pos_history[j].second - target_pos_history[j + 1].second;\n    }\n  }\n\n  // Process mask\n  // process v_mask for obs\n  torch::Tensor vector_mask = torch::zeros({450, 50});\n  int obs_count = 0;\n  for (int id : obstacles_container->curr_frame_considered_obstacle_ids()) {\n    Obstacle* obstacle = obstacles_container->GetObstacle(id);\n    int obs_his_size =\n        (obstacle->history_size() <= 20) ? obstacle->history_size() : 20;\n    if (obs_his_size > 0) {\n      vector_mask.index_put_({obs_count,\n          torch::indexing::Slice(torch::indexing::None,\n                                -(obs_his_size))}, 1);\n    } else {\n      vector_mask.index_put_({obs_count, torch::indexing::Slice()}, 1);\n    }\n    ++obs_count;\n  }\n\n  // process map data & map p id & v_mask for map polyline\n  int map_polyline_num = map_feature.size();\n  int data_length =\n      ((obs_num + map_polyline_num) < 450) ? (obs_num + map_polyline_num) : 450;\n  for (int i = obs_num; i < data_length; ++i) {\n    int one_polyline_vector_size = map_feature[i].size();\n    int one_polyline_vector_num = std::abs(one_polyline_vector_size);\n    if (one_polyline_vector_size < 0) {\n      vector_mask.index_put_({i, torch::indexing::Slice()}, 1);\n      continue;\n    }\n    if (one_polyline_vector_num < 50) {\n      vector_mask.index_put_({i, torch::indexing::Slice(one_polyline_vector_num,\n                                                        torch::indexing::None)},\n                             1);\n    }\n  }\n  torch::Tensor map_data = torch::zeros({map_polyline_num, 50, 9});\n  torch::Tensor all_map_p_id = torch::zeros({map_polyline_num, 2});\n  for (int i = 0; i < map_polyline_num && i < 450; ++i) {\n    all_map_p_id[i][0] = map_p_id[i][0];\n    all_map_p_id[i][1] = map_p_id[i][1];\n    int one_polyline_vector_size = map_feature[i].size();\n    if (one_polyline_vector_size < 0) {\n      continue;\n    }\n    int one_polyline_vector_num = std::abs(one_polyline_vector_size);\n    for (int j = 0; j < one_polyline_vector_num && j < 50; ++j) {\n      map_data.index_put_({i, j},\n                          torch::from_blob(map_feature[i][j].data(), {9}));\n    }\n  }\n\n  // process p mask\n  torch::Tensor polyline_mask = torch::zeros({450});\n  if (data_length < 450) {\n    polyline_mask.index_put_(\n        {torch::indexing::Slice(data_length, torch::indexing::None)}, 1);\n  }\n\n  // Extend obs data to specific dimension\n  torch::Tensor obs_pos_data = torch::cat(\n      {all_obstacle_pos.index(\n           {torch::indexing::Slice(),\n            torch::indexing::Slice(torch::indexing::None, -1),\n            torch::indexing::Slice()}),\n       all_obstacle_pos.index({torch::indexing::Slice(),\n                               torch::indexing::Slice(1, torch::indexing::None),\n                               torch::indexing::Slice()})},\n      2);\n  // Add obs length\n  torch::Tensor obs_length_tmp = torch::zeros({obs_num, 2});\n  for (int i = 0; i < obs_num; ++i) {\n    obs_length_tmp[i][0] = all_obs_length[i].first;\n    obs_length_tmp[i][1] = all_obs_length[i].second;\n  }\n  torch::Tensor obs_length = obs_length_tmp.unsqueeze(1).repeat({1, 19, 1});\n  // Add obs attribute\n  torch::Tensor obs_attr_agent =\n      torch::tensor({11.0, 4.0}).unsqueeze(0).unsqueeze(0).repeat({1, 19, 1});\n  torch::Tensor obs_attr_other =\n      torch::tensor({10.0, 4.0}).unsqueeze(0).unsqueeze(0).repeat(\n        {(obs_num - 1), 19, 1});\n  torch::Tensor obs_attr = torch::cat({obs_attr_agent, obs_attr_other}, 0);\n  // ADD obs id\n  torch::Tensor obs_id =\n      torch::arange(0, obs_num).unsqueeze(1).repeat({1, 19}).unsqueeze(2);\n  // Process obs data\n  torch::Tensor obs_data_with_len = torch::cat({obs_pos_data, obs_length}, 2);\n  torch::Tensor obs_data_with_attr =\n      torch::cat({obs_data_with_len, obs_attr}, 2);\n  torch::Tensor obs_data_with_id = torch::cat({obs_data_with_attr, obs_id}, 2);\n  torch::Tensor obs_data_final =\n      torch::cat({torch::zeros({obs_num, (50 - 19), 9}), obs_data_with_id}, 1);\n\n  // Extend data & pid to specific demension\n  torch::Tensor data_tmp = torch::cat({obs_data_final, map_data}, 0);\n  torch::Tensor p_id_tmp = torch::cat({all_obs_p_id, all_map_p_id}, 0);\n  torch::Tensor vector_data;\n  torch::Tensor polyline_id;\n  if (data_length < 450) {\n    torch::Tensor data_zeros = torch::zeros({(450 - data_length), 50, 9});\n    torch::Tensor p_id_zeros = torch::zeros({(450 - data_length), 2});\n    vector_data = torch::cat({data_tmp, data_zeros}, 0);\n    polyline_id = torch::cat({p_id_tmp, p_id_zeros}, 0);\n  } else {\n    vector_data = data_tmp;\n    polyline_id = p_id_tmp;\n  }\n\n  // Empty rand mask as placeholder\n  torch::Tensor rand_mask = torch::zeros({0});\n  // Change mask type to bool\n  auto bool_vector_mask = vector_mask.toType(at::kBool);\n  auto bool_polyline_mask = polyline_mask.toType(at::kBool);\n\n  // Process ADC trajectory & Extract features of ADC trajectory\n  std::vector<std::pair<double, double>> adc_traj_curr_pos(30, {0.0, 0.0});\n  torch::Tensor adc_trajectory = torch::zeros({1, 30, 6});\n  const auto& adc_traj = adc_trajectory_container->adc_trajectory();\n  size_t adc_traj_points_num = adc_traj.trajectory_point().size();\n  std::vector<TrajectoryPoint> adc_traj_points;\n  // ADC trajectory info as model input needs to match with\n  // the predicted obstalce's timestamp.\n  double time_interval = obstacle_ptr->latest_feature().timestamp() -\n      adc_traj.header().timestamp_sec();\n  for (size_t i = 0; i < adc_traj_points_num - 1; ++i) {\n    double delta_time = time_interval -\n        adc_traj.trajectory_point(0).relative_time();\n    adc_traj_points.emplace_back(\n        InterpolateUsingLinearApproximation(\n            adc_traj.trajectory_point(i),\n            adc_traj.trajectory_point(i + 1), delta_time));\n  }\n  if (!ExtractADCTrajectory(&adc_traj_points,\n      obstacle_ptr, &adc_traj_curr_pos)) {\n    ADEBUG << \"Failed to extract adc trajectory\";\n    return false;\n  }\n  size_t traj_points_num = adc_traj_points.size();\n  for (size_t j = 0; j < 30; ++j) {\n    if (j > traj_points_num - 1) {\n      adc_trajectory[0][j][0] =\n          adc_traj_curr_pos[traj_points_num - 1].first;\n      adc_trajectory[0][j][1] =\n          adc_traj_curr_pos[traj_points_num - 1].second;\n      adc_trajectory[0][j][2] =\n          adc_traj_points[traj_points_num - 1].path_point().theta();\n      adc_trajectory[0][j][3] =\n          adc_traj_points[traj_points_num - 1].v();\n      adc_trajectory[0][j][4] =\n          adc_traj_points[traj_points_num - 1].a();\n      adc_trajectory[0][j][5] =\n          adc_traj_points[traj_points_num - 1].path_point().kappa();\n    } else {\n      adc_trajectory[0][j][0] =\n          adc_traj_curr_pos[j].first;\n      adc_trajectory[0][j][1] =\n          adc_traj_curr_pos[j].second;\n      adc_trajectory[0][j][2] =\n          adc_traj_points[j].path_point().theta();\n      adc_trajectory[0][j][3] =\n          adc_traj_points[j].v();\n      adc_trajectory[0][j][4] =\n          adc_traj_points[j].a();\n      adc_trajectory[0][j][5] =\n          adc_traj_points[j].path_point().kappa();\n    }\n  }\n\n  // Build input features for torch\n  std::vector<torch::jit::IValue> torch_inputs;\n  auto X_value = c10::ivalue::Tuple::create(\n      {std::move(target_obstacle_pos.unsqueeze(0).to(device_)),\n       std::move(target_obstacle_pos_step.unsqueeze(0).to(device_)),\n       std::move(vector_data.unsqueeze(0).to(device_)),\n       std::move(bool_vector_mask.unsqueeze(0).to(device_)),\n       std::move(bool_polyline_mask.unsqueeze(0).to(device_)),\n       std::move(rand_mask.unsqueeze(0).to(device_)),\n       std::move(polyline_id.unsqueeze(0).to(device_))});\n  torch_inputs.push_back(c10::ivalue::Tuple::create(\n      {X_value, std::move(adc_trajectory.to(device_))}));\n\n  auto end_time_data_prep = std::chrono::system_clock::now();\n  std::chrono::duration<double> diff_data_prep =\n      end_time_data_prep - start_time_data_prep;\n  ADEBUG << \"vectornet input tensor prepration used time: \"\n         << diff_data_prep.count() * 1000 << \" ms.\";\n\n  // Compute pred_traj\n  auto start_time_inference = std::chrono::system_clock::now();\n  at::Tensor torch_output_tensor = torch_default_output_tensor_;\n  torch_output_tensor =\n      torch_vehicle_model_.forward(torch_inputs).toTensor().to(torch::kCPU);\n\n  auto end_time_inference = std::chrono::system_clock::now();\n  std::chrono::duration<double> diff_inference =\n      end_time_inference - start_time_inference;\n  ADEBUG << \"vectornet inference used time: \" << diff_inference.count() * 1000\n         << \" ms.\";\n\n  // Get the trajectory\n  auto torch_output = torch_output_tensor.accessor<float, 3>();\n  Trajectory* trajectory = latest_feature_ptr->add_predicted_trajectory();\n  trajectory->set_probability(1.0);\n\n  for (int i = 0; i < 30; ++i) {\n    double prev_x = pos_x;\n    double prev_y = pos_y;\n    if (i > 0) {\n      const auto& last_point = trajectory->trajectory_point(i - 1).path_point();\n      prev_x = last_point.x();\n      prev_y = last_point.y();\n    }\n    TrajectoryPoint* point = trajectory->add_trajectory_point();\n    double dx = static_cast<double>(torch_output[0][i][0]);\n    double dy = static_cast<double>(torch_output[0][i][1]);\n\n    double heading = latest_feature_ptr->velocity_heading();\n    Vec2d offset(dx, dy);\n    Vec2d rotated_offset = offset.rotate(heading);\n    double point_x = pos_x + rotated_offset.x();\n    double point_y = pos_y + rotated_offset.y();\n    point->mutable_path_point()->set_x(point_x);\n    point->mutable_path_point()->set_y(point_y);\n\n    if (i < 10) {  // use origin heading for the first second\n      point->mutable_path_point()->set_theta(\n          latest_feature_ptr->velocity_heading());\n    } else {\n      point->mutable_path_point()->set_theta(\n          std::atan2(trajectory->trajectory_point(i).path_point().y() -\n                         trajectory->trajectory_point(i - 1).path_point().y(),\n                     trajectory->trajectory_point(i).path_point().x() -\n                         trajectory->trajectory_point(i - 1).path_point().x()));\n    }\n    point->set_relative_time(static_cast<double>(i) *\n                             FLAGS_prediction_trajectory_time_resolution);\n    if (i == 0) {\n      point->set_v(latest_feature_ptr->speed());\n    } else {\n      double diff_x = point_x - prev_x;\n      double diff_y = point_y - prev_y;\n      point->set_v(std::hypot(diff_x, diff_y) /\n                   FLAGS_prediction_trajectory_time_resolution);\n    }\n  }\n\n  return true;\n}\n\nbool JointlyPredictionPlanningEvaluator::ExtractObstaclesHistory(\n    Obstacle* obstacle_ptr, ObstaclesContainer* obstacles_container,\n    std::vector<std::pair<double, double>>* target_pos_history,\n    std::vector<std::pair<double, double>>* all_obs_length,\n    std::vector<std::vector<std::pair<double, double>>>* all_obs_pos_history) {\n  const Feature& obs_curr_feature = obstacle_ptr->latest_feature();\n  double obs_curr_heading = obs_curr_feature.velocity_heading();\n  std::pair<double, double> obs_curr_pos = std::make_pair(\n      obs_curr_feature.position().x(), obs_curr_feature.position().y());\n  // Extract target obstacle history\n  std::vector<std::pair<double, double>> tar_pos_his(20, {0.0, 0.0});\n  for (std::size_t i = 0; i < obstacle_ptr->history_size() && i < 20; ++i) {\n    const Feature& target_feature = obstacle_ptr->feature(i);\n    if (!target_feature.IsInitialized()) {\n      break;\n    }\n    tar_pos_his[i] =\n        WorldCoordToObjCoord(std::make_pair(target_feature.position().x(),\n                                            target_feature.position().y()),\n                             obs_curr_pos, obs_curr_heading);\n  }\n  all_obs_length->emplace_back(\n      std::make_pair(obs_curr_feature.length(), obs_curr_feature.width()));\n  all_obs_pos_history->emplace_back(tar_pos_his);\n  target_pos_history = &tar_pos_his;\n\n  // Extract other obstacles & convert pos to traget obstacle relative coord\n  std::vector<std::pair<double, double>> pos_history(20, {0.0, 0.0});\n  for (int id : obstacles_container->curr_frame_considered_obstacle_ids()) {\n    Obstacle* obstacle = obstacles_container->GetObstacle(id);\n    int target_id = obstacle_ptr->id();\n    if (id == target_id) {\n      continue;\n    }\n    const Feature& other_obs_curr_feature = obstacle->latest_feature();\n    all_obs_length->emplace_back(std::make_pair(\n        other_obs_curr_feature.length(), other_obs_curr_feature.width()));\n\n    for (std::size_t i = 0; i < obstacle->history_size() && i < 20; ++i) {\n      const Feature& feature = obstacle->feature(i);\n      if (!feature.IsInitialized()) {\n        break;\n      }\n      pos_history[i] = WorldCoordToObjCoord(\n          std::make_pair(feature.position().x(), feature.position().y()),\n          obs_curr_pos, obs_curr_heading);\n    }\n    all_obs_pos_history->emplace_back(pos_history);\n  }\n  return true;\n}\n\nbool JointlyPredictionPlanningEvaluator::ExtractADCTrajectory(\n    std::vector<TrajectoryPoint>* trajectory_points,\n    Obstacle* obstacle_ptr,\n    std::vector<std::pair<double, double>>* adc_traj_curr_pos) {\n  adc_traj_curr_pos->resize(30, {0.0, 0.0});\n  const Feature& obs_curr_feature = obstacle_ptr->latest_feature();\n  double obs_curr_heading = obs_curr_feature.velocity_heading();\n  std::pair<double, double> obs_curr_pos = std::make_pair(\n      obs_curr_feature.position().x(), obs_curr_feature.position().y());\n  size_t adc_traj_points_num = trajectory_points->size();\n  for (size_t i = 0; i < 30; ++i) {\n    if (i > adc_traj_points_num -1) {\n      adc_traj_curr_pos->at(i) =\n          adc_traj_curr_pos->at(adc_traj_points_num - 1);\n    } else {\n      adc_traj_curr_pos->at(i) = WorldCoordToObjCoord(\n          std::make_pair(trajectory_points->at(i).path_point().x(),\n          trajectory_points->at(i).path_point().y()),\n          obs_curr_pos, obs_curr_heading);\n    }\n  }\n  return true;\n}\n\nvoid JointlyPredictionPlanningEvaluator::LoadModel() {\n  if (FLAGS_use_cuda && torch::cuda::is_available()) {\n    ADEBUG << \"CUDA is available\";\n    device_ = torch::Device(torch::kCUDA);\n    torch_vehicle_model_ =\n        torch::jit::load(FLAGS_torch_vehicle_jointly_model_file, device_);\n  } else {\n    torch_vehicle_model_ =\n        torch::jit::load(FLAGS_torch_vehicle_jointly_model_cpu_file, device_);\n  }\n  torch::set_num_threads(1);\n\n  // Fake intput for the first frame\n  torch::Tensor target_obstacle_pos = torch::zeros({1, 20, 2});\n  torch::Tensor target_obstacle_pos_step = torch::zeros({1, 20, 2});\n  torch::Tensor vector_data = torch::zeros({1, 450, 50, 9});\n  torch::Tensor vector_mask = torch::randn({1, 450, 50}) > 0.9;\n  torch::Tensor polyline_mask = torch::randn({1, 450}) > 0.9;\n  torch::Tensor rand_mask = torch::zeros({0});\n  torch::Tensor polyline_id = torch::zeros({1, 450, 2});\n  torch::Tensor adc_trajectory = torch::zeros({1, 30, 6});\n  std::vector<torch::jit::IValue> torch_inputs;\n\n  auto X_value = c10::ivalue::Tuple::create(\n      {std::move(target_obstacle_pos.to(device_)),\n       std::move(target_obstacle_pos_step.to(device_)),\n       std::move(vector_data.to(device_)), std::move(vector_mask.to(device_)),\n       std::move(polyline_mask.to(device_)), std::move(rand_mask.to(device_)),\n       std::move(polyline_id.to(device_))});\n  torch_inputs.push_back(c10::ivalue::Tuple::create(\n      {X_value, std::move(adc_trajectory.to(device_))}));\n  // Run inference twice to avoid very slow first inference later\n  torch_default_output_tensor_ =\n      torch_vehicle_model_.forward(torch_inputs).toTensor().to(torch::kCPU);\n  torch_default_output_tensor_ =\n      torch_vehicle_model_.forward(torch_inputs).toTensor().to(torch::kCPU);\n}\n\n}  // namespace prediction\n}  // namespace apollo",
        "b_contents": "/******************************************************************************\n * Copyright 2021 The Apollo Authors. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *****************************************************************************/\n\n#include \"modules/prediction/evaluator/vehicle/jointly_prediction_planning_evaluator.h\"\n\n#include <limits>\n#include <omp.h>\n\n#include \"Eigen/Dense\"\n#include \"cyber/common/file.h\"\n#include \"modules/common/math/linear_interpolation.h\"\n#include \"modules/prediction/common/prediction_gflags.h\"\n#include \"modules/prediction/common/prediction_map.h\"\n#include \"modules/prediction/common/prediction_system_gflags.h\"\n#include \"modules/prediction/common/prediction_util.h\"\n#include \"modules/prediction/container/adc_trajectory/adc_trajectory_container.h\"\n\nnamespace apollo {\nnamespace prediction {\n\nusing apollo::common::TrajectoryPoint;\nusing apollo::common::math::Vec2d;\nusing apollo::common::math::InterpolateUsingLinearApproximation;\nusing apollo::prediction::VectorNet;\n\nJointlyPredictionPlanningEvaluator::JointlyPredictionPlanningEvaluator()\n    : device_(torch::kCPU) {\n  evaluator_type_ = ObstacleConf::JOINTLY_PREDICTION_PLANNING_EVALUATOR;\n  LoadModel();\n}\n\nvoid JointlyPredictionPlanningEvaluator::Clear() {}\n\nbool JointlyPredictionPlanningEvaluator::Evaluate(Obstacle* obstacle_ptr,\n                                     ObstaclesContainer* obstacles_container) {\n  const ADCTrajectoryContainer* adc_trajectory_container;\n  Evaluate(adc_trajectory_container, obstacle_ptr, obstacles_container);\n  return true;\n}\n\nbool JointlyPredictionPlanningEvaluator::Evaluate(\n      const ADCTrajectoryContainer* adc_trajectory_container,\n      Obstacle* obstacle_ptr,\n      ObstaclesContainer* obstacles_container) {\n  omp_set_num_threads(1);\n\n  obstacle_ptr->SetEvaluatorType(evaluator_type_);\n\n  Clear();\n  CHECK_NOTNULL(obstacle_ptr);\n  int id = obstacle_ptr->id();\n  if (!obstacle_ptr->latest_feature().IsInitialized()) {\n    AERROR << \"Obstacle [\" << id << \"] has no latest feature.\";\n    return false;\n  }\n  Feature* latest_feature_ptr = obstacle_ptr->mutable_latest_feature();\n  CHECK_NOTNULL(latest_feature_ptr);\n\n  if (adc_trajectory_container == nullptr) {\n    AERROR << \"Null adc trajectory container\";\n    return false;\n  }\n\n  // obs data vector\n  // Extract features of pos_history\n  std::vector<std::pair<double, double>> target_pos_history(20, {0.0, 0.0});\n  std::vector<std::pair<double, double>> all_obs_length;\n  std::vector<std::vector<std::pair<double, double>>> all_obs_pos_history;\n  // Process mask\n  // process v_mask for obs\n  torch::Tensor vector_mask = torch::zeros({450, 50});\n\n  if (!ExtractObstaclesHistory(obstacle_ptr, obstacles_container,\n                               &target_pos_history, &all_obs_length,\n                               &all_obs_pos_history, &vector_mask)) {\n    ADEBUG << \"Obstacle [\" << id << \"] failed to extract obstacle history\";\n    return false;\n  }\n\n  // Query the map data vector\n  FeatureVector map_feature;\n  PidVector map_p_id;\n  double pos_x = latest_feature_ptr->position().x();\n  double pos_y = latest_feature_ptr->position().y();\n  common::PointENU center_point;\n  center_point.set_x(pos_x);\n  center_point.set_y(pos_y);\n  double heading = latest_feature_ptr->velocity_heading();\n\n  auto start_time_query = std::chrono::system_clock::now();\n\n  if (!vector_net_.query(center_point, heading, &map_feature, &map_p_id)) {\n    return false;\n  }\n\n  auto end_time_query = std::chrono::system_clock::now();\n  std::chrono::duration<double> diff_query = end_time_query - start_time_query;\n  ADEBUG << \"vectors query used time: \" << diff_query.count() * 1000 << \" ms.\";\n\n  // Process all obs pos_history & obs pid\n  auto start_time_data_prep = std::chrono::system_clock::now();\n  int obs_num =\n      obstacles_container->curr_frame_considered_obstacle_ids().size();\n  torch::Tensor target_obstacle_pos = torch::zeros({20, 2});\n  torch::Tensor target_obstacle_pos_step = torch::zeros({20, 2});\n  for (int j = 0; j < 20; ++j) {\n    target_obstacle_pos[19 - j][0] = target_pos_history[j].first;\n    target_obstacle_pos[19 - j][1] = target_pos_history[j].second;\n    if (j == 19 || (j > 0 && target_pos_history[j + 1].first == 0.0)) {\n      break;\n    }\n    target_obstacle_pos_step[19 - j][0] =\n        target_pos_history[j].first - target_pos_history[j + 1].first;\n    target_obstacle_pos_step[19 - j][1] =\n        target_pos_history[j].second - target_pos_history[j + 1].second;\n  }\n\n  torch::Tensor all_obstacle_pos = torch::zeros({obs_num, 20, 2});\n  torch::Tensor all_obs_p_id = torch::zeros({obs_num, 2});\n  for (int i = 0; i < obs_num; ++i) {\n    std::vector<double> obs_p_id{std::numeric_limits<float>::max(),\n                              std::numeric_limits<float>::max()};\n    for (int j = 0; j < 20; ++j) {\n      // Process obs pid\n      if (obs_p_id[0] > all_obs_pos_history[i][j].first) {\n        obs_p_id[0] = all_obs_pos_history[i][j].first;\n      }\n      if (obs_p_id[1] > all_obs_pos_history[i][j].second) {\n        obs_p_id[1] = all_obs_pos_history[i][j].second;\n      }\n      // Process obs pos history\n      all_obstacle_pos[i][19 - j][0] = all_obs_pos_history[i][j].first;\n      all_obstacle_pos[i][19 - j][1] = all_obs_pos_history[i][j].second;\n    }\n    all_obs_p_id[i][0] = obs_p_id[0];\n    all_obs_p_id[i][1] = obs_p_id[1];\n  }\n\n  // process map data & map p id & v_mask for map polyline\n  int map_polyline_num = map_feature.size();\n  int data_length =\n      ((obs_num + map_polyline_num) < 450) ? (obs_num + map_polyline_num) : 450;\n  for (int i = 0; i < map_polyline_num && obs_num + i < 450; ++i) {\n    size_t one_polyline_vector_size = map_feature[i].size();\n    if (one_polyline_vector_size < 50) {\n      vector_mask.index_put_({obs_num + i,\n                             torch::indexing::Slice(one_polyline_vector_size,\n                                                    torch::indexing::None)},\n                             1);\n    }\n  }\n\n  torch::Tensor map_data = torch::zeros({map_polyline_num, 50, 9});\n  torch::Tensor all_map_p_id = torch::zeros({map_polyline_num, 2});\n  auto opts = torch::TensorOptions().dtype(torch::kDouble);\n\n  for (int i = 0; i < map_polyline_num && i + obs_num < 450; ++i) {\n    all_map_p_id[i][0] = map_p_id[i][0];\n    all_map_p_id[i][1] = map_p_id[i][1];\n\n    int one_polyline_vector_size = map_feature[i].size();\n    for (int j = 0; j < one_polyline_vector_size && j < 50; ++j) {\n      map_data.index_put_({i, j},\n                          torch::from_blob(map_feature[i][j].data(),\n                          {9}, opts));\n    }\n  }\n  map_data = map_data.toType(at::kFloat);\n\n  // process p mask\n  torch::Tensor polyline_mask = torch::zeros({450});\n  if (data_length < 450) {\n    polyline_mask.index_put_(\n        {torch::indexing::Slice(data_length, torch::indexing::None)}, 1);\n  }\n\n  // Extend obs data to specific dimension\n  torch::Tensor obs_pos_data = torch::cat(\n      {all_obstacle_pos.index(\n           {torch::indexing::Slice(),\n            torch::indexing::Slice(torch::indexing::None, -1),\n            torch::indexing::Slice()}),\n       all_obstacle_pos.index({torch::indexing::Slice(),\n                               torch::indexing::Slice(1, torch::indexing::None),\n                               torch::indexing::Slice()})},\n      2);\n  // Add obs length\n  torch::Tensor obs_length_tmp = torch::zeros({obs_num, 2});\n  for (int i = 0; i < obs_num; ++i) {\n    obs_length_tmp[i][0] = all_obs_length[i].first;\n    obs_length_tmp[i][1] = all_obs_length[i].second;\n  }\n  torch::Tensor obs_length = obs_length_tmp.unsqueeze(1).repeat({1, 19, 1});\n  // Add obs attribute\n  torch::Tensor obs_attr_agent =\n      torch::tensor({11.0, 4.0}).unsqueeze(0).unsqueeze(0).repeat({1, 19, 1});\n  torch::Tensor obs_attr_other =\n      torch::tensor({10.0, 4.0}).unsqueeze(0).unsqueeze(0).repeat(\n        {(obs_num - 1), 19, 1});\n  torch::Tensor obs_attr = torch::cat({obs_attr_agent, obs_attr_other}, 0);\n  // ADD obs id\n  // add 500 to avoid same id as in map_info\n  torch::Tensor obs_id =\n      torch::arange(500, obs_num + 500).unsqueeze(1).repeat(\n        {1, 19}).unsqueeze(2);\n  // Process obs data\n  torch::Tensor obs_data_with_len = torch::cat({obs_pos_data, obs_length}, 2);\n  torch::Tensor obs_data_with_attr =\n      torch::cat({obs_data_with_len, obs_attr}, 2);\n  torch::Tensor obs_data_with_id = torch::cat({obs_data_with_attr, obs_id}, 2);\n  torch::Tensor obs_data_final =\n      torch::cat({torch::zeros({obs_num, (50 - 19), 9}), obs_data_with_id}, 1);\n\n  // Extend data & pid to specific demension\n  torch::Tensor data_tmp = torch::cat({obs_data_final, map_data}, 0);\n  torch::Tensor p_id_tmp = torch::cat({all_obs_p_id, all_map_p_id}, 0);\n  torch::Tensor vector_data;\n  torch::Tensor polyline_id;\n  if (data_length < 450) {\n    torch::Tensor data_zeros = torch::zeros({(450 - data_length), 50, 9});\n    torch::Tensor p_id_zeros = torch::zeros({(450 - data_length), 2});\n    vector_data = torch::cat({data_tmp, data_zeros}, 0);\n    polyline_id = torch::cat({p_id_tmp, p_id_zeros}, 0);\n  } else {\n    vector_data = data_tmp;\n    polyline_id = p_id_tmp;\n  }\n\n  // Empty rand mask as placeholder\n  auto rand_mask = torch::zeros({450}).toType(at::kBool);\n  // Change mask type to bool\n  auto bool_vector_mask = vector_mask.toType(at::kBool);\n  auto bool_polyline_mask = polyline_mask.toType(at::kBool);\n\n  // Process ADC trajectory & Extract features of ADC trajectory\n  std::vector<std::pair<double, double>> adc_traj_curr_pos(30, {0.0, 0.0});\n  torch::Tensor adc_trajectory = torch::zeros({1, 30, 6});\n  const auto& adc_traj = adc_trajectory_container->adc_trajectory();\n  size_t adc_traj_points_num = adc_traj.trajectory_point().size();\n  std::vector<TrajectoryPoint> adc_traj_points;\n  // ADC trajectory info as model input needs to match with\n  // the predicted obstalce's timestamp.\n  double time_interval = obstacle_ptr->latest_feature().timestamp() -\n      adc_traj.header().timestamp_sec();\n  for (size_t i = 0; i < adc_traj_points_num - 1; ++i) {\n    double delta_time = time_interval -\n        adc_traj.trajectory_point(0).relative_time();\n    adc_traj_points.emplace_back(\n        InterpolateUsingLinearApproximation(\n            adc_traj.trajectory_point(i),\n            adc_traj.trajectory_point(i + 1), delta_time));\n  }\n  if (!ExtractADCTrajectory(&adc_traj_points,\n      obstacle_ptr, &adc_traj_curr_pos)) {\n    ADEBUG << \"Failed to extract adc trajectory\";\n    return false;\n  }\n  size_t traj_points_num = adc_traj_points.size();\n  for (size_t j = 0; j < 30; ++j) {\n    if (j > traj_points_num - 1) {\n      adc_trajectory[0][j][0] =\n          adc_traj_curr_pos[traj_points_num - 1].first;\n      adc_trajectory[0][j][1] =\n          adc_traj_curr_pos[traj_points_num - 1].second;\n      adc_trajectory[0][j][2] =\n          adc_traj_points[traj_points_num - 1].path_point().theta();\n      adc_trajectory[0][j][3] =\n          adc_traj_points[traj_points_num - 1].v();\n      adc_trajectory[0][j][4] =\n          adc_traj_points[traj_points_num - 1].a();\n      adc_trajectory[0][j][5] =\n          adc_traj_points[traj_points_num - 1].path_point().kappa();\n    } else {\n      adc_trajectory[0][j][0] =\n          adc_traj_curr_pos[j].first;\n      adc_trajectory[0][j][1] =\n          adc_traj_curr_pos[j].second;\n      adc_trajectory[0][j][2] =\n          adc_traj_points[j].path_point().theta();\n      adc_trajectory[0][j][3] =\n          adc_traj_points[j].v();\n      adc_trajectory[0][j][4] =\n          adc_traj_points[j].a();\n      adc_trajectory[0][j][5] =\n          adc_traj_points[j].path_point().kappa();\n    }\n  }\n\n  // Build input features for torch\n  std::vector<torch::jit::IValue> torch_inputs;\n  auto X_value = c10::ivalue::Tuple::create(\n      {std::move(target_obstacle_pos.unsqueeze(0).to(device_)),\n       std::move(target_obstacle_pos_step.unsqueeze(0).to(device_)),\n       std::move(vector_data.unsqueeze(0).to(device_)),\n       std::move(bool_vector_mask.unsqueeze(0).to(device_)),\n       std::move(bool_polyline_mask.unsqueeze(0).to(device_)),\n       std::move(rand_mask.unsqueeze(0).to(device_)),\n       std::move(polyline_id.unsqueeze(0).to(device_))});\n  torch_inputs.push_back(c10::ivalue::Tuple::create(\n      {X_value, std::move(adc_trajectory.to(device_))}));\n\n  auto end_time_data_prep = std::chrono::system_clock::now();\n  std::chrono::duration<double> diff_data_prep =\n      end_time_data_prep - start_time_data_prep;\n  ADEBUG << \"vectornet input tensor prepration used time: \"\n         << diff_data_prep.count() * 1000 << \" ms.\";\n\n  // Compute pred_traj\n  auto start_time_inference = std::chrono::system_clock::now();\n  at::Tensor torch_output_tensor = torch_default_output_tensor_;\n  torch_output_tensor =\n      torch_vehicle_model_.forward(torch_inputs).toTensor().to(torch::kCPU);\n\n  auto end_time_inference = std::chrono::system_clock::now();\n  std::chrono::duration<double> diff_inference =\n      end_time_inference - start_time_inference;\n  ADEBUG << \"vectornet-interaction inference used time: \"\n         << diff_inference.count() * 1000\n         << \" ms.\";\n\n  // Get the trajectory\n  auto torch_output = torch_output_tensor.accessor<float, 3>();\n  Trajectory* trajectory = latest_feature_ptr->add_predicted_trajectory();\n  trajectory->set_probability(1.0);\n\n  for (int i = 0; i < 30; ++i) {\n    double prev_x = pos_x;\n    double prev_y = pos_y;\n    if (i > 0) {\n      const auto& last_point = trajectory->trajectory_point(i - 1).path_point();\n      prev_x = last_point.x();\n      prev_y = last_point.y();\n    }\n    TrajectoryPoint* point = trajectory->add_trajectory_point();\n    double dx = static_cast<double>(torch_output[0][i][0]);\n    double dy = static_cast<double>(torch_output[0][i][1]);\n\n    double heading = latest_feature_ptr->velocity_heading();\n    Vec2d offset(dx, dy);\n    Vec2d rotated_offset = offset.rotate(heading);\n    double point_x = pos_x + rotated_offset.x();\n    double point_y = pos_y + rotated_offset.y();\n    point->mutable_path_point()->set_x(point_x);\n    point->mutable_path_point()->set_y(point_y);\n\n    if (i < 10) {  // use origin heading for the first second\n      point->mutable_path_point()->set_theta(\n          latest_feature_ptr->velocity_heading());\n    } else {\n      point->mutable_path_point()->set_theta(\n          std::atan2(trajectory->trajectory_point(i).path_point().y() -\n                         trajectory->trajectory_point(i - 1).path_point().y(),\n                     trajectory->trajectory_point(i).path_point().x() -\n                         trajectory->trajectory_point(i - 1).path_point().x()));\n    }\n    point->set_relative_time(static_cast<double>(i) *\n                             FLAGS_prediction_trajectory_time_resolution);\n    if (i == 0) {\n      point->set_v(latest_feature_ptr->speed());\n    } else {\n      double diff_x = point_x - prev_x;\n      double diff_y = point_y - prev_y;\n      point->set_v(std::hypot(diff_x, diff_y) /\n                   FLAGS_prediction_trajectory_time_resolution);\n    }\n  }\n\n  return true;\n}\n\nbool JointlyPredictionPlanningEvaluator::ExtractObstaclesHistory(\n    Obstacle* obstacle_ptr, ObstaclesContainer* obstacles_container,\n    std::vector<std::pair<double, double>>* target_pos_history,\n    std::vector<std::pair<double, double>>* all_obs_length,\n    std::vector<std::vector<std::pair<double, double>>>* all_obs_pos_history,\n    torch::Tensor* vector_mask) {\n  const Feature& obs_curr_feature = obstacle_ptr->latest_feature();\n  double obs_curr_heading = obs_curr_feature.velocity_heading();\n  std::pair<double, double> obs_curr_pos = std::make_pair(\n      obs_curr_feature.position().x(), obs_curr_feature.position().y());\n  // Extract target obstacle history\n  for (std::size_t i = 0; i < obstacle_ptr->history_size() && i < 20; ++i) {\n    const Feature& target_feature = obstacle_ptr->feature(i);\n    if (!target_feature.IsInitialized()) {\n      break;\n    }\n    target_pos_history->at(i) =\n        WorldCoordToObjCoord(std::make_pair(target_feature.position().x(),\n                                            target_feature.position().y()),\n                             obs_curr_pos, obs_curr_heading);\n  }\n  all_obs_length->emplace_back(\n      std::make_pair(obs_curr_feature.length(), obs_curr_feature.width()));\n  all_obs_pos_history->emplace_back(*target_pos_history);\n\n  // Extract other obstacles & convert pos to traget obstacle relative coord\n  std::vector<std::pair<double, double>> pos_history(20, {0.0, 0.0});\n  for (int id : obstacles_container->curr_frame_considered_obstacle_ids()) {\n    Obstacle* obstacle = obstacles_container->GetObstacle(id);\n    int target_id = obstacle_ptr->id();\n    if (id == target_id) {\n      continue;\n    }\n    const Feature& other_obs_curr_feature = obstacle->latest_feature();\n    all_obs_length->emplace_back(std::make_pair(\n        other_obs_curr_feature.length(), other_obs_curr_feature.width()));\n\n    size_t obs_his_size = obstacle->history_size();\n    obs_his_size = obs_his_size <= 20 ? obs_his_size : 20;\n    int cur_idx = all_obs_pos_history->size();\n    if (obs_his_size > 1) {\n      vector_mask->index_put_({cur_idx,\n                              torch::indexing::Slice(torch::indexing::None,\n                                                     -(obs_his_size - 1))}, 1);\n    } else {\n      vector_mask->index_put_({cur_idx,\n                              torch::indexing::Slice(torch::indexing::None,\n                              -1)}, 1);\n    }\n\n    for (size_t i = 0; i < obs_his_size; ++i) {\n      const Feature& feature = obstacle->feature(i);\n      if (!feature.IsInitialized()) {\n        break;\n      }\n      pos_history[i] = WorldCoordToObjCoord(\n          std::make_pair(feature.position().x(), feature.position().y()),\n          obs_curr_pos, obs_curr_heading);\n    }\n    all_obs_pos_history->emplace_back(pos_history);\n  }\n  return true;\n}\n\nbool JointlyPredictionPlanningEvaluator::ExtractADCTrajectory(\n    std::vector<TrajectoryPoint>* trajectory_points,\n    Obstacle* obstacle_ptr,\n    std::vector<std::pair<double, double>>* adc_traj_curr_pos) {\n  adc_traj_curr_pos->resize(30, {0.0, 0.0});\n  const Feature& obs_curr_feature = obstacle_ptr->latest_feature();\n  double obs_curr_heading = obs_curr_feature.velocity_heading();\n  std::pair<double, double> obs_curr_pos = std::make_pair(\n      obs_curr_feature.position().x(), obs_curr_feature.position().y());\n  size_t adc_traj_points_num = trajectory_points->size();\n  for (size_t i = 0; i < 30; ++i) {\n    if (i > adc_traj_points_num -1) {\n      adc_traj_curr_pos->at(i) =\n          adc_traj_curr_pos->at(adc_traj_points_num - 1);\n    } else {\n      adc_traj_curr_pos->at(i) = WorldCoordToObjCoord(\n          std::make_pair(trajectory_points->at(i).path_point().x(),\n          trajectory_points->at(i).path_point().y()),\n          obs_curr_pos, obs_curr_heading);\n    }\n  }\n  return true;\n}\n\nvoid JointlyPredictionPlanningEvaluator::LoadModel() {\n  if (FLAGS_use_cuda && torch::cuda::is_available()) {\n    ADEBUG << \"CUDA is available\";\n    device_ = torch::Device(torch::kCUDA);\n    torch_vehicle_model_ =\n        torch::jit::load(FLAGS_torch_vehicle_jointly_model_file, device_);\n  } else {\n    torch_vehicle_model_ =\n        torch::jit::load(FLAGS_torch_vehicle_jointly_model_cpu_file, device_);\n  }\n  torch::set_num_threads(1);\n\n  // Fake intput for the first frame\n  torch::Tensor target_obstacle_pos = torch::randn({1, 20, 2});\n  torch::Tensor target_obstacle_pos_step = torch::randn({1, 20, 2});\n  torch::Tensor vector_data = torch::randn({1, 450, 50, 9});\n  torch::Tensor vector_mask = torch::randn({1, 450, 50}) > 0.9;\n  torch::Tensor polyline_mask = torch::randn({1, 450}) > 0.9;\n  torch::Tensor rand_mask = torch::zeros({1, 450});\n  torch::Tensor polyline_id = torch::randn({1, 450, 2});\n  torch::Tensor adc_trajectory = torch::zeros({1, 30, 6});\n  std::vector<torch::jit::IValue> torch_inputs;\n  auto X_value = c10::ivalue::Tuple::create(\n      {std::move(target_obstacle_pos.to(device_)),\n       std::move(target_obstacle_pos_step.to(device_)),\n       std::move(vector_data.to(device_)), std::move(vector_mask.to(device_)),\n       std::move(polyline_mask.to(device_)), std::move(rand_mask.to(device_)),\n       std::move(polyline_id.to(device_))});\n  torch_inputs.push_back(c10::ivalue::Tuple::create(\n      {X_value, std::move(adc_trajectory.to(device_))}));\n  // Run inference twice to avoid very slow first inference later\n  torch_default_output_tensor_ =\n      torch_vehicle_model_.forward(torch_inputs).toTensor().to(torch::kCPU);\n  torch_default_output_tensor_ =\n      torch_vehicle_model_.forward(torch_inputs).toTensor().to(torch::kCPU);\n}\n\n}  // namespace prediction\n}  // namespace apollo",
        "base_contents": "",
        "res_region": "/******************************************************************************\n * Copyright 2021 The Apollo Authors. All Rights Reserved.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *****************************************************************************/\n\n#include \"modules/prediction/evaluator/vehicle/jointly_prediction_planning_evaluator.h\"\n\n#include <limits>\n#include <omp.h>\n\n#include \"Eigen/Dense\"\n#include \"cyber/common/file.h\"\n#include \"modules/common/math/linear_interpolation.h\"\n#include \"modules/prediction/common/prediction_gflags.h\"\n#include \"modules/prediction/common/prediction_map.h\"\n#include \"modules/prediction/common/prediction_system_gflags.h\"\n#include \"modules/prediction/common/prediction_util.h\"\n#include \"modules/prediction/container/adc_trajectory/adc_trajectory_container.h\"\n\nnamespace apollo {\nnamespace prediction {\n\nusing apollo::common::TrajectoryPoint;\nusing apollo::common::math::Vec2d;\nusing apollo::common::math::InterpolateUsingLinearApproximation;\nusing apollo::prediction::VectorNet;\n\nJointlyPredictionPlanningEvaluator::JointlyPredictionPlanningEvaluator()\n    : device_(torch::kCPU) {\n  evaluator_type_ = ObstacleConf::JOINTLY_PREDICTION_PLANNING_EVALUATOR;\n  LoadModel();\n}\n\nvoid JointlyPredictionPlanningEvaluator::Clear() {}\n\nbool JointlyPredictionPlanningEvaluator::Evaluate(Obstacle* obstacle_ptr,\n                                     ObstaclesContainer* obstacles_container) {\n  const ADCTrajectoryContainer* adc_trajectory_container;\n  Evaluate(adc_trajectory_container, obstacle_ptr, obstacles_container);\n  return true;\n}\n\nbool JointlyPredictionPlanningEvaluator::Evaluate(\n      const ADCTrajectoryContainer* adc_trajectory_container,\n      Obstacle* obstacle_ptr,\n      ObstaclesContainer* obstacles_container) {\n  omp_set_num_threads(1);\n\n  obstacle_ptr->SetEvaluatorType(evaluator_type_);\n\n  Clear();\n  CHECK_NOTNULL(obstacle_ptr);\n  int id = obstacle_ptr->id();\n  if (!obstacle_ptr->latest_feature().IsInitialized()) {\n    AERROR << \"Obstacle [\" << id << \"] has no latest feature.\";\n    return false;\n  }\n  Feature* latest_feature_ptr = obstacle_ptr->mutable_latest_feature();\n  CHECK_NOTNULL(latest_feature_ptr);\n\n  if (adc_trajectory_container == nullptr) {\n    AERROR << \"Null adc trajectory container\";\n    return false;\n  }\n\n  // obs data vector\n  // Extract features of pos_history\n  std::vector<std::pair<double, double>> target_pos_history(20, {0.0, 0.0});\n  std::vector<std::pair<double, double>> all_obs_length;\n  std::vector<std::vector<std::pair<double, double>>> all_obs_pos_history;\n  // Process mask\n  // process v_mask for obs\n  torch::Tensor vector_mask = torch::zeros({450, 50});\n\n  if (!ExtractObstaclesHistory(obstacle_ptr, obstacles_container,\n                               &target_pos_history, &all_obs_length,\n                               &all_obs_pos_history, &vector_mask)) {\n    ADEBUG << \"Obstacle [\" << id << \"] failed to extract obstacle history\";\n    return false;\n  }\n\n  // Query the map data vector\n  FeatureVector map_feature;\n  PidVector map_p_id;\n  double pos_x = latest_feature_ptr->position().x();\n  double pos_y = latest_feature_ptr->position().y();\n  common::PointENU center_point;\n  center_point.set_x(pos_x);\n  center_point.set_y(pos_y);\n  double heading = latest_feature_ptr->velocity_heading();\n\n  auto start_time_query = std::chrono::system_clock::now();\n\n  if (!vector_net_.query(center_point, heading, &map_feature, &map_p_id)) {\n    return false;\n  }\n\n  auto end_time_query = std::chrono::system_clock::now();\n  std::chrono::duration<double> diff_query = end_time_query - start_time_query;\n  ADEBUG << \"vectors query used time: \" << diff_query.count() * 1000 << \" ms.\";\n\n  // Process all obs pos_history & obs pid\n  auto start_time_data_prep = std::chrono::system_clock::now();\n  int obs_num =\n      obstacles_container->curr_frame_considered_obstacle_ids().size();\n  torch::Tensor target_obstacle_pos = torch::zeros({20, 2});\n  torch::Tensor target_obstacle_pos_step = torch::zeros({20, 2});\n  for (int j = 0; j < 20; ++j) {\n    target_obstacle_pos[19 - j][0] = target_pos_history[j].first;\n    target_obstacle_pos[19 - j][1] = target_pos_history[j].second;\n    if (j == 19 || (j > 0 && target_pos_history[j + 1].first == 0.0)) {\n      break;\n    }\n    target_obstacle_pos_step[19 - j][0] =\n        target_pos_history[j].first - target_pos_history[j + 1].first;\n    target_obstacle_pos_step[19 - j][1] =\n        target_pos_history[j].second - target_pos_history[j + 1].second;\n  }\n\n  torch::Tensor all_obstacle_pos = torch::zeros({obs_num, 20, 2});\n  torch::Tensor all_obs_p_id = torch::zeros({obs_num, 2});\n  for (int i = 0; i < obs_num; ++i) {\n    std::vector<double> obs_p_id{std::numeric_limits<float>::max(),\n                              std::numeric_limits<float>::max()};\n    for (int j = 0; j < 20; ++j) {\n      // Process obs pid\n      if (obs_p_id[0] > all_obs_pos_history[i][j].first) {\n        obs_p_id[0] = all_obs_pos_history[i][j].first;\n      }\n      if (obs_p_id[1] > all_obs_pos_history[i][j].second) {\n        obs_p_id[1] = all_obs_pos_history[i][j].second;\n      }\n      // Process obs pos history\n      all_obstacle_pos[i][19 - j][0] = all_obs_pos_history[i][j].first;\n      all_obstacle_pos[i][19 - j][1] = all_obs_pos_history[i][j].second;\n    }\n    all_obs_p_id[i][0] = obs_p_id[0];\n    all_obs_p_id[i][1] = obs_p_id[1];\n  }\n\n  // process map data & map p id & v_mask for map polyline\n  int map_polyline_num = map_feature.size();\n  int data_length =\n      ((obs_num + map_polyline_num) < 450) ? (obs_num + map_polyline_num) : 450;\n  for (int i = 0; i < map_polyline_num && obs_num + i < 450; ++i) {\n    size_t one_polyline_vector_size = map_feature[i].size();\n    if (one_polyline_vector_size < 50) {\n      vector_mask.index_put_({obs_num + i,\n                             torch::indexing::Slice(one_polyline_vector_size,\n                                                    torch::indexing::None)},\n                             1);\n    }\n  }\n\n  torch::Tensor map_data = torch::zeros({map_polyline_num, 50, 9});\n  torch::Tensor all_map_p_id = torch::zeros({map_polyline_num, 2});\n  auto opts = torch::TensorOptions().dtype(torch::kDouble);\n\n  for (int i = 0; i < map_polyline_num && i + obs_num < 450; ++i) {\n    all_map_p_id[i][0] = map_p_id[i][0];\n    all_map_p_id[i][1] = map_p_id[i][1];\n\n    int one_polyline_vector_size = map_feature[i].size();\n    for (int j = 0; j < one_polyline_vector_size && j < 50; ++j) {\n      map_data.index_put_({i, j},\n                          torch::from_blob(map_feature[i][j].data(),\n                          {9}, opts));\n    }\n  }\n  map_data = map_data.toType(at::kFloat);\n\n  // process p mask\n  torch::Tensor polyline_mask = torch::zeros({450});\n  if (data_length < 450) {\n    polyline_mask.index_put_(\n        {torch::indexing::Slice(data_length, torch::indexing::None)}, 1);\n  }\n\n  // Extend obs data to specific dimension\n  torch::Tensor obs_pos_data = torch::cat(\n      {all_obstacle_pos.index(\n           {torch::indexing::Slice(),\n            torch::indexing::Slice(torch::indexing::None, -1),\n            torch::indexing::Slice()}),\n       all_obstacle_pos.index({torch::indexing::Slice(),\n                               torch::indexing::Slice(1, torch::indexing::None),\n                               torch::indexing::Slice()})},\n      2);\n  // Add obs length\n  torch::Tensor obs_length_tmp = torch::zeros({obs_num, 2});\n  for (int i = 0; i < obs_num; ++i) {\n    obs_length_tmp[i][0] = all_obs_length[i].first;\n    obs_length_tmp[i][1] = all_obs_length[i].second;\n  }\n  torch::Tensor obs_length = obs_length_tmp.unsqueeze(1).repeat({1, 19, 1});\n  // Add obs attribute\n  torch::Tensor obs_attr_agent =\n      torch::tensor({11.0, 4.0}).unsqueeze(0).unsqueeze(0).repeat({1, 19, 1});\n  torch::Tensor obs_attr_other =\n      torch::tensor({10.0, 4.0}).unsqueeze(0).unsqueeze(0).repeat(\n        {(obs_num - 1), 19, 1});\n  torch::Tensor obs_attr = torch::cat({obs_attr_agent, obs_attr_other}, 0);\n  // ADD obs id\n  // add 500 to avoid same id as in map_info\n  torch::Tensor obs_id =\n      torch::arange(500, obs_num + 500).unsqueeze(1).repeat(\n        {1, 19}).unsqueeze(2);\n  // Process obs data\n  torch::Tensor obs_data_with_len = torch::cat({obs_pos_data, obs_length}, 2);\n  torch::Tensor obs_data_with_attr =\n      torch::cat({obs_data_with_len, obs_attr}, 2);\n  torch::Tensor obs_data_with_id = torch::cat({obs_data_with_attr, obs_id}, 2);\n  torch::Tensor obs_data_final =\n      torch::cat({torch::zeros({obs_num, (50 - 19), 9}), obs_data_with_id}, 1);\n\n  // Extend data & pid to specific demension\n  torch::Tensor data_tmp = torch::cat({obs_data_final, map_data}, 0);\n  torch::Tensor p_id_tmp = torch::cat({all_obs_p_id, all_map_p_id}, 0);\n  torch::Tensor vector_data;\n  torch::Tensor polyline_id;\n  if (data_length < 450) {\n    torch::Tensor data_zeros = torch::zeros({(450 - data_length), 50, 9});\n    torch::Tensor p_id_zeros = torch::zeros({(450 - data_length), 2});\n    vector_data = torch::cat({data_tmp, data_zeros}, 0);\n    polyline_id = torch::cat({p_id_tmp, p_id_zeros}, 0);\n  } else {\n    vector_data = data_tmp;\n    polyline_id = p_id_tmp;\n  }\n\n  // Empty rand mask as placeholder\n  auto rand_mask = torch::zeros({450}).toType(at::kBool);\n  // Change mask type to bool\n  auto bool_vector_mask = vector_mask.toType(at::kBool);\n  auto bool_polyline_mask = polyline_mask.toType(at::kBool);\n\n  // Process ADC trajectory & Extract features of ADC trajectory\n  std::vector<std::pair<double, double>> adc_traj_curr_pos(30, {0.0, 0.0});\n  torch::Tensor adc_trajectory = torch::zeros({1, 30, 6});\n  const auto& adc_traj = adc_trajectory_container->adc_trajectory();\n  size_t adc_traj_points_num = adc_traj.trajectory_point().size();\n  std::vector<TrajectoryPoint> adc_traj_points;\n  // ADC trajectory info as model input needs to match with\n  // the predicted obstalce's timestamp.\n  double time_interval = obstacle_ptr->latest_feature().timestamp() -\n      adc_traj.header().timestamp_sec();\n  for (size_t i = 0; i < adc_traj_points_num - 1; ++i) {\n    double delta_time = time_interval -\n        adc_traj.trajectory_point(0).relative_time();\n    adc_traj_points.emplace_back(\n        InterpolateUsingLinearApproximation(\n            adc_traj.trajectory_point(i),\n            adc_traj.trajectory_point(i + 1), delta_time));\n  }\n  if (!ExtractADCTrajectory(&adc_traj_points,\n      obstacle_ptr, &adc_traj_curr_pos)) {\n    ADEBUG << \"Failed to extract adc trajectory\";\n    return false;\n  }\n  size_t traj_points_num = adc_traj_points.size();\n  for (size_t j = 0; j < 30; ++j) {\n    if (j > traj_points_num - 1) {\n      adc_trajectory[0][j][0] =\n          adc_traj_curr_pos[traj_points_num - 1].first;\n      adc_trajectory[0][j][1] =\n          adc_traj_curr_pos[traj_points_num - 1].second;\n      adc_trajectory[0][j][2] =\n          adc_traj_points[traj_points_num - 1].path_point().theta();\n      adc_trajectory[0][j][3] =\n          adc_traj_points[traj_points_num - 1].v();\n      adc_trajectory[0][j][4] =\n          adc_traj_points[traj_points_num - 1].a();\n      adc_trajectory[0][j][5] =\n          adc_traj_points[traj_points_num - 1].path_point().kappa();\n    } else {\n      adc_trajectory[0][j][0] =\n          adc_traj_curr_pos[j].first;\n      adc_trajectory[0][j][1] =\n          adc_traj_curr_pos[j].second;\n      adc_trajectory[0][j][2] =\n          adc_traj_points[j].path_point().theta();\n      adc_trajectory[0][j][3] =\n          adc_traj_points[j].v();\n      adc_trajectory[0][j][4] =\n          adc_traj_points[j].a();\n      adc_trajectory[0][j][5] =\n          adc_traj_points[j].path_point().kappa();\n    }\n  }\n\n  // Build input features for torch\n  std::vector<torch::jit::IValue> torch_inputs;\n  auto X_value = c10::ivalue::Tuple::create(\n      {std::move(target_obstacle_pos.unsqueeze(0).to(device_)),\n       std::move(target_obstacle_pos_step.unsqueeze(0).to(device_)),\n       std::move(vector_data.unsqueeze(0).to(device_)),\n       std::move(bool_vector_mask.unsqueeze(0).to(device_)),\n       std::move(bool_polyline_mask.unsqueeze(0).to(device_)),\n       std::move(rand_mask.unsqueeze(0).to(device_)),\n       std::move(polyline_id.unsqueeze(0).to(device_))});\n  torch_inputs.push_back(c10::ivalue::Tuple::create(\n      {X_value, std::move(adc_trajectory.to(device_))}));\n\n  auto end_time_data_prep = std::chrono::system_clock::now();\n  std::chrono::duration<double> diff_data_prep =\n      end_time_data_prep - start_time_data_prep;\n  ADEBUG << \"vectornet input tensor prepration used time: \"\n         << diff_data_prep.count() * 1000 << \" ms.\";\n\n  // Compute pred_traj\n  auto start_time_inference = std::chrono::system_clock::now();\n  at::Tensor torch_output_tensor = torch_default_output_tensor_;\n  torch_output_tensor =\n      torch_vehicle_model_.forward(torch_inputs).toTensor().to(torch::kCPU);\n\n  auto end_time_inference = std::chrono::system_clock::now();\n  std::chrono::duration<double> diff_inference =\n      end_time_inference - start_time_inference;\n  ADEBUG << \"vectornet-interaction inference used time: \"\n         << diff_inference.count() * 1000\n         << \" ms.\";\n\n  // Get the trajectory\n  auto torch_output = torch_output_tensor.accessor<float, 3>();\n  Trajectory* trajectory = latest_feature_ptr->add_predicted_trajectory();\n  trajectory->set_probability(1.0);\n\n  for (int i = 0; i < 30; ++i) {\n    double prev_x = pos_x;\n    double prev_y = pos_y;\n    if (i > 0) {\n      const auto& last_point = trajectory->trajectory_point(i - 1).path_point();\n      prev_x = last_point.x();\n      prev_y = last_point.y();\n    }\n    TrajectoryPoint* point = trajectory->add_trajectory_point();\n    double dx = static_cast<double>(torch_output[0][i][0]);\n    double dy = static_cast<double>(torch_output[0][i][1]);\n\n    double heading = latest_feature_ptr->velocity_heading();\n    Vec2d offset(dx, dy);\n    Vec2d rotated_offset = offset.rotate(heading);\n    double point_x = pos_x + rotated_offset.x();\n    double point_y = pos_y + rotated_offset.y();\n    point->mutable_path_point()->set_x(point_x);\n    point->mutable_path_point()->set_y(point_y);\n\n    if (i < 10) {  // use origin heading for the first second\n      point->mutable_path_point()->set_theta(\n          latest_feature_ptr->velocity_heading());\n    } else {\n      point->mutable_path_point()->set_theta(\n          std::atan2(trajectory->trajectory_point(i).path_point().y() -\n                         trajectory->trajectory_point(i - 1).path_point().y(),\n                     trajectory->trajectory_point(i).path_point().x() -\n                         trajectory->trajectory_point(i - 1).path_point().x()));\n    }\n    point->set_relative_time(static_cast<double>(i) *\n                             FLAGS_prediction_trajectory_time_resolution);\n    if (i == 0) {\n      point->set_v(latest_feature_ptr->speed());\n    } else {\n      double diff_x = point_x - prev_x;\n      double diff_y = point_y - prev_y;\n      point->set_v(std::hypot(diff_x, diff_y) /\n                   FLAGS_prediction_trajectory_time_resolution);\n    }\n  }\n\n  return true;\n}\n\nbool JointlyPredictionPlanningEvaluator::ExtractObstaclesHistory(\n    Obstacle* obstacle_ptr, ObstaclesContainer* obstacles_container,\n    std::vector<std::pair<double, double>>* target_pos_history,\n    std::vector<std::pair<double, double>>* all_obs_length,\n    std::vector<std::vector<std::pair<double, double>>>* all_obs_pos_history,\n    torch::Tensor* vector_mask) {\n  const Feature& obs_curr_feature = obstacle_ptr->latest_feature();\n  double obs_curr_heading = obs_curr_feature.velocity_heading();\n  std::pair<double, double> obs_curr_pos = std::make_pair(\n      obs_curr_feature.position().x(), obs_curr_feature.position().y());\n  // Extract target obstacle history\n  for (std::size_t i = 0; i < obstacle_ptr->history_size() && i < 20; ++i) {\n    const Feature& target_feature = obstacle_ptr->feature(i);\n    if (!target_feature.IsInitialized()) {\n      break;\n    }\n    target_pos_history->at(i) =\n        WorldCoordToObjCoord(std::make_pair(target_feature.position().x(),\n                                            target_feature.position().y()),\n                             obs_curr_pos, obs_curr_heading);\n  }\n  all_obs_length->emplace_back(\n      std::make_pair(obs_curr_feature.length(), obs_curr_feature.width()));\n  all_obs_pos_history->emplace_back(*target_pos_history);\n\n  // Extract other obstacles & convert pos to traget obstacle relative coord\n  std::vector<std::pair<double, double>> pos_history(20, {0.0, 0.0});\n  for (int id : obstacles_container->curr_frame_considered_obstacle_ids()) {\n    Obstacle* obstacle = obstacles_container->GetObstacle(id);\n    int target_id = obstacle_ptr->id();\n    if (id == target_id) {\n      continue;\n    }\n    const Feature& other_obs_curr_feature = obstacle->latest_feature();\n    all_obs_length->emplace_back(std::make_pair(\n        other_obs_curr_feature.length(), other_obs_curr_feature.width()));\n\n    size_t obs_his_size = obstacle->history_size();\n    obs_his_size = obs_his_size <= 20 ? obs_his_size : 20;\n    int cur_idx = all_obs_pos_history->size();\n    if (obs_his_size > 1) {\n      vector_mask->index_put_({cur_idx,\n                              torch::indexing::Slice(torch::indexing::None,\n                                                     -(obs_his_size - 1))}, 1);\n    } else {\n      vector_mask->index_put_({cur_idx,\n                              torch::indexing::Slice(torch::indexing::None,\n                              -1)}, 1);\n    }\n\n    for (size_t i = 0; i < obs_his_size; ++i) {\n      const Feature& feature = obstacle->feature(i);\n      if (!feature.IsInitialized()) {\n        break;\n      }\n      pos_history[i] = WorldCoordToObjCoord(\n          std::make_pair(feature.position().x(), feature.position().y()),\n          obs_curr_pos, obs_curr_heading);\n    }\n    all_obs_pos_history->emplace_back(pos_history);\n  }\n  return true;\n}\n\nbool JointlyPredictionPlanningEvaluator::ExtractADCTrajectory(\n    std::vector<TrajectoryPoint>* trajectory_points,\n    Obstacle* obstacle_ptr,\n    std::vector<std::pair<double, double>>* adc_traj_curr_pos) {\n  adc_traj_curr_pos->resize(30, {0.0, 0.0});\n  const Feature& obs_curr_feature = obstacle_ptr->latest_feature();\n  double obs_curr_heading = obs_curr_feature.velocity_heading();\n  std::pair<double, double> obs_curr_pos = std::make_pair(\n      obs_curr_feature.position().x(), obs_curr_feature.position().y());\n  size_t adc_traj_points_num = trajectory_points->size();\n  for (size_t i = 0; i < 30; ++i) {\n    if (i > adc_traj_points_num -1) {\n      adc_traj_curr_pos->at(i) =\n          adc_traj_curr_pos->at(adc_traj_points_num - 1);\n    } else {\n      adc_traj_curr_pos->at(i) = WorldCoordToObjCoord(\n          std::make_pair(trajectory_points->at(i).path_point().x(),\n          trajectory_points->at(i).path_point().y()),\n          obs_curr_pos, obs_curr_heading);\n    }\n  }\n  return true;\n}\n\nvoid JointlyPredictionPlanningEvaluator::LoadModel() {\n  if (FLAGS_use_cuda && torch::cuda::is_available()) {\n    ADEBUG << \"CUDA is available\";\n    device_ = torch::Device(torch::kCUDA);\n    torch_vehicle_model_ =\n        torch::jit::load(FLAGS_torch_vehicle_jointly_model_file, device_);\n  } else {\n    torch_vehicle_model_ =\n        torch::jit::load(FLAGS_torch_vehicle_jointly_model_cpu_file, device_);\n  }\n  torch::set_num_threads(1);\n\n  // Fake intput for the first frame\n  torch::Tensor target_obstacle_pos = torch::randn({1, 20, 2});\n  torch::Tensor target_obstacle_pos_step = torch::randn({1, 20, 2});\n  torch::Tensor vector_data = torch::randn({1, 450, 50, 9});\n  torch::Tensor vector_mask = torch::randn({1, 450, 50}) > 0.9;\n  torch::Tensor polyline_mask = torch::randn({1, 450}) > 0.9;\n  torch::Tensor rand_mask = torch::zeros({1, 450});\n  torch::Tensor polyline_id = torch::randn({1, 450, 2});\n  torch::Tensor adc_trajectory = torch::zeros({1, 30, 6});\n  std::vector<torch::jit::IValue> torch_inputs;\n  auto X_value = c10::ivalue::Tuple::create(\n      {std::move(target_obstacle_pos.to(device_)),\n       std::move(target_obstacle_pos_step.to(device_)),\n       std::move(vector_data.to(device_)), std::move(vector_mask.to(device_)),\n       std::move(polyline_mask.to(device_)), std::move(rand_mask.to(device_)),\n       std::move(polyline_id.to(device_))});\n  torch_inputs.push_back(c10::ivalue::Tuple::create(\n      {X_value, std::move(adc_trajectory.to(device_))}));\n  // Run inference twice to avoid very slow first inference later\n  torch_default_output_tensor_ =\n      torch_vehicle_model_.forward(torch_inputs).toTensor().to(torch::kCPU);\n  torch_default_output_tensor_ =\n      torch_vehicle_model_.forward(torch_inputs).toTensor().to(torch::kCPU);\n}\n\n}  // namespace prediction\n}  // namespace apollo",
        "lookback": " * Copyright 2021 The Apollo Authors. All Rights Reserved.",
        "lookahead": "",
        "label": [
            "base",
            "one_side_deletion"
        ],
        "start_line": 0,
        "end_line": 1022,
        "merge_gen_region": " Copyright021 Alo Authors All Reserved/****************************************************************************** Copyright021 Apol Authors All Reserved * Licensed the Apache, 20theLicense *\"); you not this except in with the. * may a of License * may a of License * * httpwwwapacheorglicensesLICENSE20 * Unless by law agreed in, * to writing software distributed the is on \" IS BASIS * WARRANTIES CONDITIONS ANY, either or. See License the for specific governing and limitations the License *****************************************************************************/includemodulespredictionevalu////////lyjoint___ningevalu.atorh # <>includeomph # \"////////__.\"includelimits # <.>includeEigenDense # \"cy///fileh # \"modulescommonmathlinearinter.\"includemodulespredictionpredictiong.h # \"////__.\"includemodulespredictionpredictionmaph # \"////___flagsh # \"///_.\"includemodulespredictionpredictionmaph # \"////__g.h # \"////_.\"includemodulespredictionpredictioncontaineradctraectoryadctraectorycontainerh namespacepol { namespace { alo usingpol::::ajectory; alo",
        "confidence": 0.9395811557769775,
        "hesitated": false,
        "resolved": false
    }
]