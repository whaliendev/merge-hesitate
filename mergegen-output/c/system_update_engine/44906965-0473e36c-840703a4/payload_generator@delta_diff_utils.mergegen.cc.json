[
    {
        "a_contents": "#include <unistd.h>",
        "b_contents": "#endif\n#include <unistd.h>",
        "base_contents": "",
        "res_region": "#endif\n#include <unistd.h>",
        "lookback": "#include <unistd.h>",
        "lookahead": "",
        "label": [
            "base",
            "one_side_deletion"
        ],
        "start_line": 27,
        "end_line": 34,
        "merge_gen_region": null,
        "confidence": 0.8194699883460999,
        "hesitated": true
    },
    {
        "a_contents": "#include <base/threading/simple_thread.h>\n#include <brillo/data_encoding.h>\n#include <bsdiff/bsdiff.h>",
        "b_contents": "#include <base/threading/simple_thread.h>\n#include <bsdiff/bsdiff.h>",
        "base_contents": "",
        "res_region": "#include <base/threading/simple_thread.h>\n#include <brillo/data_encoding.h>\n#include <bsdiff/bsdiff.h>",
        "lookback": "#include <brillo/data_encoding.h>",
        "lookahead": "",
        "label": [
            "ours",
            "one_side_deletion"
        ],
        "start_line": 45,
        "end_line": 53,
        "merge_gen_region": null,
        "confidence": 0.8519178628921509,
        "hesitated": true
    },
    {
        "a_contents": "// The maximum destination size allowed for puffdiff. In general, puffdiff\n// should work for arbitrary big files, but the payload application is quite\n// memory intensive, so we limit these operations to 50 MiB.\nconst uint64_t kMaxPuffdiffDestinationSize = 50 * 1024 * 1024;  // bytes",
        "b_contents": "// The maximum destination size allowed for puffdiff. In general, puffdiff\n// should work for arbitrary big files, but the payload application is quite\n// memory intensive, so we limit these operations to 150 MiB.\nconst uint64_t kMaxPuffdiffDestinationSize = 150 * 1024 * 1024;  // bytes",
        "base_contents": "// The maximum destination size allowed for imgdiff. In general, imgdiff should\n// work for arbitrary big files, but the payload application is quite memory\n// intensive, so we limit these operations to 50 MiB.\nconst uint64_t kMaxImgdiffDestinationSize = 50 * 1024 * 1024;  // bytes",
        "res_region": "// The maximum destination size allowed for puffdiff. In general, puffdiff\n// should work for arbitrary big files, but the payload application is quite\n// memory intensive, so we limit these operations to 150 MiB.\nconst uint64_t kMaxPuffdiffDestinationSize = 150 * 1024 * 1024;  // bytes",
        "lookback": "// should work for arbitrary big files, but the payload application is quite",
        "lookahead": "",
        "label": [
            "base",
            "complex_conflict"
        ],
        "start_line": 82,
        "end_line": 97,
        "merge_gen_region": null,
        "confidence": 0.8250504732131958,
        "hesitated": true
    },
    {
        "a_contents": "// This class encapsulates a file delta processing thread work. The\n// processor computes the delta between the source and target files;\n// and write the compressed delta to the blob.\nclass FileDeltaProcessor : public base::DelegateSimpleThread::Delegate {\n public:\n  FileDeltaProcessor(const string& old_part,\n                     const string& new_part,\n                     const PayloadVersion& version,\n                     const vector<Extent>& old_extents,\n                     const vector<Extent>& new_extents,\n                     const string& name,\n                     ssize_t chunk_blocks,\n                     BlobFileWriter* blob_file)\n      : old_part_(old_part),\n        new_part_(new_part),\n        version_(version),\n        old_extents_(old_extents),\n        new_extents_(new_extents),\n        name_(name),\n        chunk_blocks_(chunk_blocks),\n        blob_file_(blob_file) {}\n\n  FileDeltaProcessor(FileDeltaProcessor&& processor) = default;\n\n  ~FileDeltaProcessor() override = default;\n\n  // Overrides DelegateSimpleThread::Delegate.\n  // Calculate the list of operations and write their corresponding deltas to\n  // the blob_file.\n  void Run() override;\n\n  // Merge each file processor's ops list to aops.\n  void MergeOperation(vector<AnnotatedOperation>* aops);\n\n private:\n  const string& old_part_;\n  const string& new_part_;\n  const PayloadVersion& version_;\n\n  // The block ranges of the old/new file within the src/tgt image\n  const vector<Extent> old_extents_;\n  const vector<Extent> new_extents_;\n  const string name_;\n  // Block limit of one aop.\n  ssize_t chunk_blocks_;\n  BlobFileWriter* blob_file_;\n\n  // The list of ops to reach the new file from the old file.\n  vector<AnnotatedOperation> file_aops_;\n\n  DISALLOW_COPY_AND_ASSIGN(FileDeltaProcessor);\n};\n\nvoid FileDeltaProcessor::Run() {\n  TEST_AND_RETURN(blob_file_ != nullptr);\n\n  if (!DeltaReadFile(&file_aops_,\n                     old_part_,\n                     new_part_,\n                     old_extents_,\n                     new_extents_,\n                     name_,\n                     chunk_blocks_,\n                     version_,\n                     blob_file_)) {\n    LOG(ERROR) << \"Failed to generate delta for \" << name_ << \" (\"\n               << BlocksInExtents(new_extents_) << \" blocks)\";\n  }\n}\n\nvoid FileDeltaProcessor::MergeOperation(vector<AnnotatedOperation>* aops) {\n  aops->reserve(aops->size() + file_aops_.size());\n  std::move(file_aops_.begin(), file_aops_.end(), std::back_inserter(*aops));\n}\n",
        "b_contents": "// This class encapsulates a file delta processing thread work. The\n// processor computes the delta between the source and target files;\n// and write the compressed delta to the blob.\nclass FileDeltaProcessor : public base::DelegateSimpleThread::Delegate {\n public:\n  FileDeltaProcessor(const string& old_part,\n                     const string& new_part,\n                     const PayloadVersion& version,\n                     const vector<Extent>& old_extents,\n                     const vector<Extent>& new_extents,\n                     const vector<puffin::BitExtent>& old_deflates,\n                     const vector<puffin::BitExtent>& new_deflates,\n                     const string& name,\n                     ssize_t chunk_blocks,\n                     BlobFileWriter* blob_file)\n      : old_part_(old_part),\n        new_part_(new_part),\n        version_(version),\n        old_extents_(old_extents),\n        new_extents_(new_extents),\n        old_deflates_(old_deflates),\n        new_deflates_(new_deflates),\n        name_(name),\n        chunk_blocks_(chunk_blocks),\n        blob_file_(blob_file) {}\n\n  FileDeltaProcessor(FileDeltaProcessor&& processor) = default;\n\n  ~FileDeltaProcessor() override = default;\n\n  // Overrides DelegateSimpleThread::Delegate.\n  // Calculate the list of operations and write their corresponding deltas to\n  // the blob_file.\n  void Run() override;\n\n  // Merge each file processor's ops list to aops.\n  void MergeOperation(vector<AnnotatedOperation>* aops);\n\n private:\n  const string old_part_;\n  const string new_part_;\n  const PayloadVersion& version_;\n\n  // The block ranges of the old/new file within the src/tgt image\n  const vector<Extent> old_extents_;\n  const vector<Extent> new_extents_;\n  const vector<puffin::BitExtent> old_deflates_;\n  const vector<puffin::BitExtent> new_deflates_;\n  const string name_;\n  // Block limit of one aop.\n  ssize_t chunk_blocks_;\n  BlobFileWriter* blob_file_;\n\n  // The list of ops to reach the new file from the old file.\n  vector<AnnotatedOperation> file_aops_;\n\n  DISALLOW_COPY_AND_ASSIGN(FileDeltaProcessor);\n};\n\nvoid FileDeltaProcessor::Run() {\n  TEST_AND_RETURN(blob_file_ != nullptr);\n\n  LOG(INFO) << \"Encoding file \" << name_ << \" (\"\n            << utils::BlocksInExtents(new_extents_) << \" blocks)\";\n\n  if (!DeltaReadFile(&file_aops_,\n                     old_part_,\n                     new_part_,\n                     old_extents_,\n                     new_extents_,\n                     old_deflates_,\n                     new_deflates_,\n                     name_,\n                     chunk_blocks_,\n                     version_,\n                     blob_file_)) {\n    LOG(ERROR) << \"Failed to generate delta for \" << name_ << \" (\"\n               << utils::BlocksInExtents(new_extents_) << \" blocks)\";\n  }\n}\n\nvoid FileDeltaProcessor::MergeOperation(vector<AnnotatedOperation>* aops) {\n  aops->reserve(aops->size() + file_aops_.size());\n  std::move(file_aops_.begin(), file_aops_.end(), std::back_inserter(*aops));\n}\n",
        "base_contents": "",
        "res_region": "// This class encapsulates a file delta processing thread work. The\n// processor computes the delta between the source and target files;\n// and write the compressed delta to the blob.\nclass FileDeltaProcessor : public base::DelegateSimpleThread::Delegate {\n public:\n  FileDeltaProcessor(const string& old_part,\n                     const string& new_part,\n                     const PayloadVersion& version,\n                     const vector<Extent>& old_extents,\n                     const vector<Extent>& new_extents,\n                     const vector<puffin::BitExtent>& old_deflates,\n                     const vector<puffin::BitExtent>& new_deflates,\n                     const string& name,\n                     ssize_t chunk_blocks,\n                     BlobFileWriter* blob_file)\n      : old_part_(old_part),\n        new_part_(new_part),\n        version_(version),\n        old_extents_(old_extents),\n        new_extents_(new_extents),\n        old_deflates_(old_deflates),\n        new_deflates_(new_deflates),\n        name_(name),\n        chunk_blocks_(chunk_blocks),\n        blob_file_(blob_file) {}\n\n  FileDeltaProcessor(FileDeltaProcessor&& processor) = default;\n\n  ~FileDeltaProcessor() override = default;\n\n  // Overrides DelegateSimpleThread::Delegate.\n  // Calculate the list of operations and write their corresponding deltas to\n  // the blob_file.\n  void Run() override;\n\n  // Merge each file processor's ops list to aops.\n  void MergeOperation(vector<AnnotatedOperation>* aops);\n\n private:\n  const string& old_part_;\n  const string& new_part_;\n  const PayloadVersion& version_;\n\n  // The block ranges of the old/new file within the src/tgt image\n  const vector<Extent> old_extents_;\n  const vector<Extent> new_extents_;\n  const vector<puffin::BitExtent> old_deflates_;\n  const vector<puffin::BitExtent> new_deflates_;\n  const string name_;\n  // Block limit of one aop.\n  ssize_t chunk_blocks_;\n  BlobFileWriter* blob_file_;\n\n  // The list of ops to reach the new file from the old file.\n  vector<AnnotatedOperation> file_aops_;\n\n  DISALLOW_COPY_AND_ASSIGN(FileDeltaProcessor);\n};\n\nvoid FileDeltaProcessor::Run() {\n  TEST_AND_RETURN(blob_file_ != nullptr);\n\n  LOG(INFO) << \"Encoding file \" << name_ << \" (\"\n            << utils::BlocksInExtents(new_extents_) << \" blocks)\";\n\n  if (!DeltaReadFile(&file_aops_,\n                     old_part_,\n                     new_part_,\n                     old_extents_,\n                     new_extents_,\n                     old_deflates_,\n                     new_deflates_,\n                     name_,\n                     chunk_blocks_,\n                     version_,\n                     blob_file_)) {\n    LOG(ERROR) << \"Failed to generate delta for \" << name_ << \" (\"\n               << utils::BlocksInExtents(new_extents_) << \" blocks)\";\n  }\n}\n\nvoid FileDeltaProcessor::MergeOperation(vector<AnnotatedOperation>* aops) {\n  aops->reserve(aops->size() + file_aops_.size());\n  std::move(file_aops_.begin(), file_aops_.end(), std::back_inserter(*aops));\n}\n",
        "lookback": "// processor computes the delta between the source and target files;",
        "lookahead": "bool DeltaReadPartition(vector<AnnotatedOperation>* aops,",
        "label": [
            "interleave",
            "one_side_deletion"
        ],
        "start_line": 198,
        "end_line": 362,
        "merge_gen_region": null,
        "confidence": 0.8680990934371948,
        "hesitated": true
    },
    {
        "a_contents": "    file_delta_processors.emplace_back(old_part.path,\n                                       new_part.path,\n                                       version,\n                                       std::move(old_file_extents),\n                                       std::move(new_file_extents),\n                                       new_file.name,  // operation name\n                                       hard_chunk_blocks,\n                                       blob_file);\n  }\n\n  size_t max_threads = GetMaxThreads();\n  base::DelegateSimpleThreadPool thread_pool(\"incremental-update-generator\",\n                                             max_threads);\n  thread_pool.Start();\n  for (auto& processor : file_delta_processors) {\n    thread_pool.AddWork(&processor);\n  }\n  thread_pool.JoinAll();\n\n  for (auto& processor : file_delta_processors) {\n    processor.MergeOperation(aops);",
        "b_contents": "    file_delta_processors.emplace_back(old_part.path,\n                                       new_part.path,\n                                       version,\n                                       std::move(old_file_extents),\n                                       std::move(new_file_extents),\n                                       old_file.deflates,\n                                       new_file.deflates,\n                                       new_file.name,  // operation name\n                                       hard_chunk_blocks,\n                                       blob_file);\n  }\n\n  size_t max_threads = GetMaxThreads();\n  base::DelegateSimpleThreadPool thread_pool(\"incremental-update-generator\",\n                                             max_threads);\n  thread_pool.Start();\n  for (auto& processor : file_delta_processors) {\n    thread_pool.AddWork(&processor);\n  }\n  thread_pool.JoinAll();\n\n  for (auto& processor : file_delta_processors) {\n    processor.MergeOperation(aops);",
        "base_contents": "    TEST_AND_RETURN_FALSE(DeltaReadFile(aops,\n                                        old_part.path,\n                                        new_part.path,\n                                        old_file_extents,\n                                        new_file_extents,\n                                        new_file.name,  // operation name\n                                        hard_chunk_blocks,\n                                        version,\n                                        blob_file));",
        "res_region": "    file_delta_processors.emplace_back(old_part.path,\n                                       new_part.path,\n                                       version,\n                                       std::move(old_file_extents),\n                                       std::move(new_file_extents),\n                                       old_file.deflates,\n                                       new_file.deflates,\n                                       new_file.name,  // operation name\n                                       hard_chunk_blocks,\n                                       blob_file);\n  }\n\n  size_t max_threads = GetMaxThreads();\n  base::DelegateSimpleThreadPool thread_pool(\"incremental-update-generator\",\n                                             max_threads);\n  thread_pool.Start();\n  for (auto& processor : file_delta_processors) {\n    thread_pool.AddWork(&processor);\n  }\n  thread_pool.JoinAll();\n\n  for (auto& processor : file_delta_processors) {\n    processor.MergeOperation(aops);",
        "lookback": "                                       new_part.path,",
        "lookahead": "  }",
        "label": [
            "base",
            "complex_conflict"
        ],
        "start_line": 436,
        "end_line": 492,
        "merge_gen_region": null,
        "confidence": 0.8499258756637573,
        "hesitated": true
    },
    {
        "a_contents": "      if (puffdiff_allowed) {\n        LOG(ERROR) << \"puffdiff is not supported yet!\";\n        return false;",
        "b_contents": "      if (puffdiff_allowed) {\n        // Find all deflate positions inside the given extents and then put all\n        // deflates together because we have already read all the extents into\n        // one buffer.\n        vector<puffin::BitExtent> src_deflates;\n        TEST_AND_RETURN_FALSE(deflate_utils::FindAndCompactDeflates(\n            src_extents, old_deflates, &src_deflates));\n\n        vector<puffin::BitExtent> dst_deflates;\n        TEST_AND_RETURN_FALSE(deflate_utils::FindAndCompactDeflates(\n            dst_extents, new_deflates, &dst_deflates));\n\n        // Remove equal deflates. TODO(*): We can do a N*N check using\n        // hashing. It will not reduce the payload size, but it will speeds up\n        // the puffing on the client device.\n        auto src = src_deflates.begin();\n        auto dst = dst_deflates.begin();\n        for (; src != src_deflates.end() && dst != dst_deflates.end();) {\n          auto src_in_bytes = deflate_utils::ExpandToByteExtent(*src);\n          auto dst_in_bytes = deflate_utils::ExpandToByteExtent(*dst);\n          if (src_in_bytes.length == dst_in_bytes.length &&\n              !memcmp(old_data.data() + src_in_bytes.offset,\n                      new_data.data() + dst_in_bytes.offset,\n                      src_in_bytes.length)) {\n            src = src_deflates.erase(src);\n            dst = dst_deflates.erase(dst);\n          } else {\n            src++;\n            dst++;\n          }\n        }\n\n        // Only Puffdiff if both files have at least one deflate left.\n        if (!src_deflates.empty() && !dst_deflates.empty()) {\n          brillo::Blob puffdiff_delta;\n          string temp_file_path;\n          TEST_AND_RETURN_FALSE(utils::MakeTempFile(\n              \"puffdiff-delta.XXXXXX\", &temp_file_path, nullptr));\n          ScopedPathUnlinker temp_file_unlinker(temp_file_path);\n\n          // Perform PuffDiff operation.\n          TEST_AND_RETURN_FALSE(puffin::PuffDiff(old_data,\n                                                 new_data,\n                                                 src_deflates,\n                                                 dst_deflates,\n                                                 temp_file_path,\n                                                 &puffdiff_delta));\n          TEST_AND_RETURN_FALSE(puffdiff_delta.size() > 0);\n          if (puffdiff_delta.size() < data_blob.size()) {\n            operation.set_type(InstallOperation::PUFFDIFF);\n            data_blob = std::move(puffdiff_delta);\n          }\n        }",
        "base_contents": "      if (imgdiff_allowed && ContainsGZip(old_data) && ContainsGZip(new_data)) {\n        brillo::Blob imgdiff_delta;\n        // Imgdiff might fail in some cases, only use the result if it succeed,\n        // otherwise print the extents to analyze.\n        if (DiffFiles(kImgdiffPath,\n                      old_chunk.value(),\n                      new_chunk.value(),\n                      &imgdiff_delta) &&\n            imgdiff_delta.size() > 0) {\n          if (imgdiff_delta.size() < data_blob.size()) {\n            operation.set_type(InstallOperation::IMGDIFF);\n            data_blob = std::move(imgdiff_delta);\n          }\n        } else {\n          LOG(ERROR) << \"Imgdiff failed with source extents: \"\n                     << ExtentsToString(src_extents)\n                     << \", destination extents: \"\n                     << ExtentsToString(dst_extents);\n        }",
        "res_region": "      if (puffdiff_allowed) {\n        // Find all deflate positions inside the given extents and then put all\n        // deflates together because we have already read all the extents into\n        // one buffer.\n        vector<puffin::BitExtent> src_deflates;\n        TEST_AND_RETURN_FALSE(deflate_utils::FindAndCompactDeflates(\n            src_extents, old_deflates, &src_deflates));\n\n        vector<puffin::BitExtent> dst_deflates;\n        TEST_AND_RETURN_FALSE(deflate_utils::FindAndCompactDeflates(\n            dst_extents, new_deflates, &dst_deflates));\n\n        // Remove equal deflates. TODO(*): We can do a N*N check using\n        // hashing. It will not reduce the payload size, but it will speeds up\n        // the puffing on the client device.\n        auto src = src_deflates.begin();\n        auto dst = dst_deflates.begin();\n        for (; src != src_deflates.end() && dst != dst_deflates.end();) {\n          auto src_in_bytes = deflate_utils::ExpandToByteExtent(*src);\n          auto dst_in_bytes = deflate_utils::ExpandToByteExtent(*dst);\n          if (src_in_bytes.length == dst_in_bytes.length &&\n              !memcmp(old_data.data() + src_in_bytes.offset,\n                      new_data.data() + dst_in_bytes.offset,\n                      src_in_bytes.length)) {\n            src = src_deflates.erase(src);\n            dst = dst_deflates.erase(dst);\n          } else {\n            src++;\n            dst++;\n          }\n        }\n\n        // Only Puffdiff if both files have at least one deflate left.\n        if (!src_deflates.empty() && !dst_deflates.empty()) {\n          brillo::Blob puffdiff_delta;\n          string temp_file_path;\n          TEST_AND_RETURN_FALSE(utils::MakeTempFile(\n              \"puffdiff-delta.XXXXXX\", &temp_file_path, nullptr));\n          ScopedPathUnlinker temp_file_unlinker(temp_file_path);\n\n          // Perform PuffDiff operation.\n          TEST_AND_RETURN_FALSE(puffin::PuffDiff(old_data,\n                                                 new_data,\n                                                 src_deflates,\n                                                 dst_deflates,\n                                                 temp_file_path,\n                                                 &puffdiff_delta));\n          TEST_AND_RETURN_FALSE(puffdiff_delta.size() > 0);\n          if (puffdiff_delta.size() < data_blob.size()) {\n            operation.set_type(InstallOperation::PUFFDIFF);\n            data_blob = std::move(puffdiff_delta);\n          }\n        }",
        "lookback": "        // Find all deflate positions inside the given extents and then put all",
        "lookahead": "      }",
        "label": [
            "base",
            "complex_conflict"
        ],
        "start_line": 899,
        "end_line": 977,
        "merge_gen_region": null,
        "confidence": 0.8708277344703674,
        "hesitated": true
    }
]