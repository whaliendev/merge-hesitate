[
    {
        "a_contents": "",
        "b_contents": "/*-*************************************\n*  Long distance matching\n***************************************/\n\n/** ZSTD_ldm_getSmallHash() :\n *  numBits should be <= 32\n *  If numBits==0, returns 0.\n *  @return : the most significant numBits of value. */\nstatic U32 ZSTD_ldm_getSmallHash(U64 value, U32 numBits)\n{\n    assert(numBits <= 32);\n    return numBits == 0 ? 0 : (U32)(value >> (64 - numBits));\n}\n\n/** ZSTD_ldm_getChecksum() :\n *  numBitsToDiscard should be <= 32\n *  @return : the next most significant 32 bits after numBitsToDiscard */\nstatic U32 ZSTD_ldm_getChecksum(U64 hash, U32 numBitsToDiscard)\n{\n    assert(numBitsToDiscard <= 32);\n    return (hash >> (64 - 32 - numBitsToDiscard)) & 0xFFFFFFFF;\n}\n\n/** ZSTD_ldm_getTag() ;\n *  Given the hash, returns the most significant numTagBits bits\n *  after (32 + hbits) bits.\n *\n *  If there are not enough bits remaining, return the last\n *  numTagBits bits. */\nstatic U32 ZSTD_ldm_getTag(U64 hash, U32 hbits, U32 numTagBits)\n{\n    assert(numTagBits < 32 && hbits <= 32);\n    if (32 - hbits < numTagBits) {\n        return hash & (((U32)1 << numTagBits) - 1);\n    } else {\n        return (hash >> (32 - hbits - numTagBits)) & (((U32)1 << numTagBits) - 1);\n    }\n}\n\n/** ZSTD_ldm_getBucket() :\n *  Returns a pointer to the start of the bucket associated with hash. */\nstatic ldmEntry_t* ZSTD_ldm_getBucket(\n        ldmState_t* ldmState, size_t hash, ldmParams_t const ldmParams)\n{\n    return ldmState->hashTable + (hash << ldmParams.bucketSizeLog);\n}\n\n/** ZSTD_ldm_insertEntry() :\n *  Insert the entry with corresponding hash into the hash table */\nstatic void ZSTD_ldm_insertEntry(ldmState_t* ldmState,\n                                 size_t const hash, const ldmEntry_t entry,\n                                 ldmParams_t const ldmParams)\n{\n    BYTE* const bucketOffsets = ldmState->bucketOffsets;\n    *(ZSTD_ldm_getBucket(ldmState, hash, ldmParams) + bucketOffsets[hash]) = entry;\n    bucketOffsets[hash]++;\n    bucketOffsets[hash] &= ((U32)1 << ldmParams.bucketSizeLog) - 1;\n}\n\n/** ZSTD_ldm_makeEntryAndInsertByTag() :\n *\n *  Gets the small hash, checksum, and tag from the rollingHash.\n *\n *  If the tag matches (1 << ldmParams.hashEveryLog)-1, then\n *  creates an ldmEntry from the offset, and inserts it into the hash table.\n *\n *  hBits is the length of the small hash, which is the most significant hBits\n *  of rollingHash. The checksum is the next 32 most significant bits, followed\n *  by ldmParams.hashEveryLog bits that make up the tag. */\nstatic void ZSTD_ldm_makeEntryAndInsertByTag(ldmState_t* ldmState,\n                                             U64 const rollingHash,\n                                             U32 const hBits,\n                                             U32 const offset,\n                                             ldmParams_t const ldmParams)\n{\n    U32 const tag = ZSTD_ldm_getTag(rollingHash, hBits, ldmParams.hashEveryLog);\n    U32 const tagMask = ((U32)1 << ldmParams.hashEveryLog) - 1;\n    if (tag == tagMask) {\n        U32 const hash = ZSTD_ldm_getSmallHash(rollingHash, hBits);\n        U32 const checksum = ZSTD_ldm_getChecksum(rollingHash, hBits);\n        ldmEntry_t entry;\n        entry.offset = offset;\n        entry.checksum = checksum;\n        ZSTD_ldm_insertEntry(ldmState, hash, entry, ldmParams);\n    }\n}\n\n/** ZSTD_ldm_getRollingHash() :\n *  Get a 64-bit hash using the first len bytes from buf.\n *\n *  Giving bytes s = s_1, s_2, ... s_k, the hash is defined to be\n *  H(s) = s_1*(a^(k-1)) + s_2*(a^(k-2)) + ... + s_k*(a^0)\n *\n *  where the constant a is defined to be prime8bytes.\n *\n *  The implementation adds an offset to each byte, so\n *  H(s) = (s_1 + HASH_CHAR_OFFSET)*(a^(k-1)) + ... */\nstatic U64 ZSTD_ldm_getRollingHash(const BYTE* buf, U32 len)\n{\n    U64 ret = 0;\n    U32 i;\n    for (i = 0; i < len; i++) {\n        ret *= prime8bytes;\n        ret += buf[i] + LDM_HASH_CHAR_OFFSET;\n    }\n    return ret;\n}\n\n/** ZSTD_ldm_ipow() :\n *  Return base^exp. */\nstatic U64 ZSTD_ldm_ipow(U64 base, U64 exp)\n{\n    U64 ret = 1;\n    while (exp) {\n        if (exp & 1) { ret *= base; }\n        exp >>= 1;\n        base *= base;\n    }\n    return ret;\n}\n\nstatic U64 ZSTD_ldm_getHashPower(U32 minMatchLength) {\n    assert(minMatchLength >= ZSTD_LDM_MINMATCH_MIN);\n    return ZSTD_ldm_ipow(prime8bytes, minMatchLength - 1);\n}\n\n/** ZSTD_ldm_updateHash() :\n *  Updates hash by removing toRemove and adding toAdd. */\nstatic U64 ZSTD_ldm_updateHash(U64 hash, BYTE toRemove, BYTE toAdd, U64 hashPower)\n{\n    hash -= ((toRemove + LDM_HASH_CHAR_OFFSET) * hashPower);\n    hash *= prime8bytes;\n    hash += toAdd + LDM_HASH_CHAR_OFFSET;\n    return hash;\n}\n\n/** ZSTD_ldm_countBackwardsMatch() :\n *  Returns the number of bytes that match backwards before pIn and pMatch.\n *\n *  We count only bytes where pMatch >= pBase and pIn >= pAnchor. */\nstatic size_t ZSTD_ldm_countBackwardsMatch(\n            const BYTE* pIn, const BYTE* pAnchor,\n            const BYTE* pMatch, const BYTE* pBase)\n{\n    size_t matchLength = 0;\n    while (pIn > pAnchor && pMatch > pBase && pIn[-1] == pMatch[-1]) {\n        pIn--;\n        pMatch--;\n        matchLength++;\n    }\n    return matchLength;\n}\n\n/** ZSTD_ldm_fillFastTables() :\n *\n *  Fills the relevant tables for the ZSTD_fast and ZSTD_dfast strategies.\n *  This is similar to ZSTD_loadDictionaryContent.\n *\n *  The tables for the other strategies are filled within their\n *  block compressors. */\nstatic size_t ZSTD_ldm_fillFastTables(ZSTD_CCtx* zc, const void* end)\n{\n    const BYTE* const iend = (const BYTE*)end;\n    const U32 mls = zc->appliedParams.cParams.searchLength;\n\n    switch(zc->appliedParams.cParams.strategy)\n    {\n    case ZSTD_fast:\n        ZSTD_fillHashTable(zc, iend, mls);\n        zc->nextToUpdate = (U32)(iend - zc->base);\n        break;\n\n    case ZSTD_dfast:\n        ZSTD_fillDoubleHashTable(zc, iend, mls);\n        zc->nextToUpdate = (U32)(iend - zc->base);\n        break;\n\n    case ZSTD_greedy:\n    case ZSTD_lazy:\n    case ZSTD_lazy2:\n    case ZSTD_btlazy2:\n    case ZSTD_btopt:\n    case ZSTD_btultra:\n        break;\n    default:\n        assert(0);  /* not possible : not a valid strategy id */\n    }\n\n    return 0;\n}\n\n/** ZSTD_ldm_fillLdmHashTable() :\n *\n *  Fills hashTable from (lastHashed + 1) to iend (non-inclusive).\n *  lastHash is the rolling hash that corresponds to lastHashed.\n *\n *  Returns the rolling hash corresponding to position iend-1. */\nstatic U64 ZSTD_ldm_fillLdmHashTable(ldmState_t* state,\n                                     U64 lastHash, const BYTE* lastHashed,\n                                     const BYTE* iend, const BYTE* base,\n                                     U32 hBits, ldmParams_t const ldmParams)\n{\n    U64 rollingHash = lastHash;\n    const BYTE* cur = lastHashed + 1;\n\n    while (cur < iend) {\n        rollingHash = ZSTD_ldm_updateHash(rollingHash, cur[-1],\n                                          cur[ldmParams.minMatchLength-1],\n                                          state->hashPower);\n        ZSTD_ldm_makeEntryAndInsertByTag(state,\n                                         rollingHash, hBits,\n                                         (U32)(cur - base), ldmParams);\n        ++cur;\n    }\n    return rollingHash;\n}\n\n\n/** ZSTD_ldm_limitTableUpdate() :\n *\n *  Sets cctx->nextToUpdate to a position corresponding closer to anchor\n *  if it is far way\n *  (after a long match, only update tables a limited amount). */\nstatic void ZSTD_ldm_limitTableUpdate(ZSTD_CCtx* cctx, const BYTE* anchor)\n{\n    U32 const current = (U32)(anchor - cctx->base);\n    if (current > cctx->nextToUpdate + 1024) {\n        cctx->nextToUpdate =\n            current - MIN(512, current - cctx->nextToUpdate - 1024);\n    }\n}\n\n/** ZSTD_compressBlock_ldm_generic() :\n *\n *  This is a block compressor intended for long distance matching.\n *\n *  The function searches for matches of length at least\n *  ldmParams.minMatchLength using a hash table in cctx->ldmState.\n *  Matches can be at a distance of up to cParams.windowLog.\n *\n *  Upon finding a match, the unmatched literals are compressed using a\n *  ZSTD_blockCompressor (depending on the strategy in the compression\n *  parameters), which stores the matched sequences. The \"long distance\"\n *  match is then stored with the remaining literals from the\n *  ZSTD_blockCompressor. */\nFORCE_INLINE_TEMPLATE\nsize_t ZSTD_compressBlock_ldm_generic(ZSTD_CCtx* cctx,\n                                      const void* src, size_t srcSize)\n{\n    ldmState_t* const ldmState = &(cctx->ldmState);\n    const ldmParams_t ldmParams = cctx->appliedParams.ldmParams;\n    const U64 hashPower = ldmState->hashPower;\n    const U32 hBits = ldmParams.hashLog - ldmParams.bucketSizeLog;\n    const U32 ldmBucketSize = ((U32)1 << ldmParams.bucketSizeLog);\n    const U32 ldmTagMask = ((U32)1 << ldmParams.hashEveryLog) - 1;\n    seqStore_t* const seqStorePtr = &(cctx->seqStore);\n    const BYTE* const base = cctx->base;\n    const BYTE* const istart = (const BYTE*)src;\n    const BYTE* ip = istart;\n    const BYTE* anchor = istart;\n    const U32   lowestIndex = cctx->dictLimit;\n    const BYTE* const lowest = base + lowestIndex;\n    const BYTE* const iend = istart + srcSize;\n    const BYTE* const ilimit = iend - ldmParams.minMatchLength;\n\n    const ZSTD_blockCompressor blockCompressor =\n        ZSTD_selectBlockCompressor(cctx->appliedParams.cParams.strategy, 0);\n    U32* const repToConfirm = seqStorePtr->repToConfirm;\n    U32 savedRep[ZSTD_REP_NUM];\n    U64 rollingHash = 0;\n    const BYTE* lastHashed = NULL;\n    size_t i, lastLiterals;\n\n    /* Save seqStorePtr->rep and copy repToConfirm */\n    for (i = 0; i < ZSTD_REP_NUM; i++)\n        savedRep[i] = repToConfirm[i] = seqStorePtr->rep[i];\n\n    /* Main Search Loop */\n    while (ip < ilimit) {   /* < instead of <=, because repcode check at (ip+1) */\n        size_t mLength;\n        U32 const current = (U32)(ip - base);\n        size_t forwardMatchLength = 0, backwardMatchLength = 0;\n        ldmEntry_t* bestEntry = NULL;\n        if (ip != istart) {\n            rollingHash = ZSTD_ldm_updateHash(rollingHash, lastHashed[0],\n                                              lastHashed[ldmParams.minMatchLength],\n                                              hashPower);\n        } else {\n            rollingHash = ZSTD_ldm_getRollingHash(ip, ldmParams.minMatchLength);\n        }\n        lastHashed = ip;\n\n        /* Do not insert and do not look for a match */\n        if (ZSTD_ldm_getTag(rollingHash, hBits, ldmParams.hashEveryLog) !=\n                ldmTagMask) {\n           ip++;\n           continue;\n        }\n\n        /* Get the best entry and compute the match lengths */\n        {\n            ldmEntry_t* const bucket =\n                ZSTD_ldm_getBucket(ldmState,\n                                   ZSTD_ldm_getSmallHash(rollingHash, hBits),\n                                   ldmParams);\n            ldmEntry_t* cur;\n            size_t bestMatchLength = 0;\n            U32 const checksum = ZSTD_ldm_getChecksum(rollingHash, hBits);\n\n            for (cur = bucket; cur < bucket + ldmBucketSize; ++cur) {\n                const BYTE* const pMatch = cur->offset + base;\n                size_t curForwardMatchLength, curBackwardMatchLength,\n                       curTotalMatchLength;\n                if (cur->checksum != checksum || cur->offset <= lowestIndex) {\n                    continue;\n                }\n\n                curForwardMatchLength = ZSTD_count(ip, pMatch, iend);\n                if (curForwardMatchLength < ldmParams.minMatchLength) {\n                    continue;\n                }\n                curBackwardMatchLength = ZSTD_ldm_countBackwardsMatch(\n                                             ip, anchor, pMatch, lowest);\n                curTotalMatchLength = curForwardMatchLength +\n                                      curBackwardMatchLength;\n\n                if (curTotalMatchLength > bestMatchLength) {\n                    bestMatchLength = curTotalMatchLength;\n                    forwardMatchLength = curForwardMatchLength;\n                    backwardMatchLength = curBackwardMatchLength;\n                    bestEntry = cur;\n                }\n            }\n        }\n\n        /* No match found -- continue searching */\n        if (bestEntry == NULL) {\n            ZSTD_ldm_makeEntryAndInsertByTag(ldmState, rollingHash,\n                                             hBits, current,\n                                             ldmParams);\n            ip++;\n            continue;\n        }\n\n        /* Match found */\n        mLength = forwardMatchLength + backwardMatchLength;\n        ip -= backwardMatchLength;\n\n        /* Call the block compressor on the remaining literals */\n        {\n            U32 const matchIndex = bestEntry->offset;\n            const BYTE* const match = base + matchIndex - backwardMatchLength;\n            U32 const offset = (U32)(ip - match);\n\n            /* Overwrite rep codes */\n            for (i = 0; i < ZSTD_REP_NUM; i++)\n                seqStorePtr->rep[i] = repToConfirm[i];\n\n            /* Fill tables for block compressor */\n            ZSTD_ldm_limitTableUpdate(cctx, anchor);\n            ZSTD_ldm_fillFastTables(cctx, anchor);\n\n            /* Call block compressor and get remaining literals */\n            lastLiterals = blockCompressor(cctx, anchor, ip - anchor);\n            cctx->nextToUpdate = (U32)(ip - base);\n\n            /* Update repToConfirm with the new offset */\n            for (i = ZSTD_REP_NUM - 1; i > 0; i--)\n                repToConfirm[i] = repToConfirm[i-1];\n            repToConfirm[0] = offset;\n\n            /* Store the sequence with the leftover literals */\n            ZSTD_storeSeq(seqStorePtr, lastLiterals, ip - lastLiterals,\n                          offset + ZSTD_REP_MOVE, mLength - MINMATCH);\n        }\n\n        /* Insert the current entry into the hash table */\n        ZSTD_ldm_makeEntryAndInsertByTag(ldmState, rollingHash, hBits,\n                                         (U32)(lastHashed - base),\n                                         ldmParams);\n\n        assert(ip + backwardMatchLength == lastHashed);\n\n        /* Fill the hash table from lastHashed+1 to ip+mLength*/\n        /* Heuristic: don't need to fill the entire table at end of block */\n        if (ip + mLength < ilimit) {\n            rollingHash = ZSTD_ldm_fillLdmHashTable(\n                              ldmState, rollingHash, lastHashed,\n                              ip + mLength, base, hBits, ldmParams);\n            lastHashed = ip + mLength - 1;\n        }\n        ip += mLength;\n        anchor = ip;\n        /* Check immediate repcode */\n        while ( (ip < ilimit)\n             && ( (repToConfirm[1] > 0) && (repToConfirm[1] <= (U32)(ip-lowest))\n             && (MEM_read32(ip) == MEM_read32(ip - repToConfirm[1])) )) {\n\n            size_t const rLength = ZSTD_count(ip+4, ip+4-repToConfirm[1],\n                                              iend) + 4;\n            /* Swap repToConfirm[1] <=> repToConfirm[0] */\n            {\n                U32 const tmpOff = repToConfirm[1];\n                repToConfirm[1] = repToConfirm[0];\n                repToConfirm[0] = tmpOff;\n            }\n\n            ZSTD_storeSeq(seqStorePtr, 0, anchor, 0, rLength-MINMATCH);\n\n            /* Fill the  hash table from lastHashed+1 to ip+rLength*/\n            if (ip + rLength < ilimit) {\n                rollingHash = ZSTD_ldm_fillLdmHashTable(\n                                ldmState, rollingHash, lastHashed,\n                                ip + rLength, base, hBits, ldmParams);\n                lastHashed = ip + rLength - 1;\n            }\n            ip += rLength;\n            anchor = ip;\n        }\n    }\n\n    /* Overwrite rep */\n    for (i = 0; i < ZSTD_REP_NUM; i++)\n        seqStorePtr->rep[i] = repToConfirm[i];\n\n    ZSTD_ldm_limitTableUpdate(cctx, anchor);\n    ZSTD_ldm_fillFastTables(cctx, anchor);\n\n    lastLiterals = blockCompressor(cctx, anchor, iend - anchor);\n    cctx->nextToUpdate = (U32)(iend - base);\n\n    /* Restore seqStorePtr->rep */\n    for (i = 0; i < ZSTD_REP_NUM; i++)\n        seqStorePtr->rep[i] = savedRep[i];\n\n    /* Return the last literals size */\n    return lastLiterals;\n}\n\nstatic size_t ZSTD_compressBlock_ldm(ZSTD_CCtx* ctx,\n                                     const void* src, size_t srcSize)\n{\n    return ZSTD_compressBlock_ldm_generic(ctx, src, srcSize);\n}\n\nstatic size_t ZSTD_compressBlock_ldm_extDict_generic(\n                                 ZSTD_CCtx* ctx,\n                                 const void* src, size_t srcSize)\n{\n    ldmState_t* const ldmState = &(ctx->ldmState);\n    const ldmParams_t ldmParams = ctx->appliedParams.ldmParams;\n    const U64 hashPower = ldmState->hashPower;\n    const U32 hBits = ldmParams.hashLog - ldmParams.bucketSizeLog;\n    const U32 ldmBucketSize = ((U32)1 << ldmParams.bucketSizeLog);\n    const U32 ldmTagMask = ((U32)1 << ldmParams.hashEveryLog) - 1;\n    seqStore_t* const seqStorePtr = &(ctx->seqStore);\n    const BYTE* const base = ctx->base;\n    const BYTE* const dictBase = ctx->dictBase;\n    const BYTE* const istart = (const BYTE*)src;\n    const BYTE* ip = istart;\n    const BYTE* anchor = istart;\n    const U32   lowestIndex = ctx->lowLimit;\n    const BYTE* const dictStart = dictBase + lowestIndex;\n    const U32   dictLimit = ctx->dictLimit;\n    const BYTE* const lowPrefixPtr = base + dictLimit;\n    const BYTE* const dictEnd = dictBase + dictLimit;\n    const BYTE* const iend = istart + srcSize;\n    const BYTE* const ilimit = iend - ldmParams.minMatchLength;\n\n    const ZSTD_blockCompressor blockCompressor =\n        ZSTD_selectBlockCompressor(ctx->appliedParams.cParams.strategy, 1);\n    U32* const repToConfirm = seqStorePtr->repToConfirm;\n    U32 savedRep[ZSTD_REP_NUM];\n    U64 rollingHash = 0;\n    const BYTE* lastHashed = NULL;\n    size_t i, lastLiterals;\n\n    /* Save seqStorePtr->rep and copy repToConfirm */\n    for (i = 0; i < ZSTD_REP_NUM; i++) {\n        savedRep[i] = repToConfirm[i] = seqStorePtr->rep[i];\n    }\n\n    /* Search Loop */\n    while (ip < ilimit) {  /* < instead of <=, because (ip+1) */\n        size_t mLength;\n        const U32 current = (U32)(ip-base);\n        size_t forwardMatchLength = 0, backwardMatchLength = 0;\n        ldmEntry_t* bestEntry = NULL;\n        if (ip != istart) {\n          rollingHash = ZSTD_ldm_updateHash(rollingHash, lastHashed[0],\n                                       lastHashed[ldmParams.minMatchLength],\n                                       hashPower);\n        } else {\n            rollingHash = ZSTD_ldm_getRollingHash(ip, ldmParams.minMatchLength);\n        }\n        lastHashed = ip;\n\n        if (ZSTD_ldm_getTag(rollingHash, hBits, ldmParams.hashEveryLog) !=\n                ldmTagMask) {\n            /* Don't insert and don't look for a match */\n           ip++;\n           continue;\n        }\n\n        /* Get the best entry and compute the match lengths */\n        {\n            ldmEntry_t* const bucket =\n                ZSTD_ldm_getBucket(ldmState,\n                                   ZSTD_ldm_getSmallHash(rollingHash, hBits),\n                                   ldmParams);\n            ldmEntry_t* cur;\n            size_t bestMatchLength = 0;\n            U32 const checksum = ZSTD_ldm_getChecksum(rollingHash, hBits);\n\n            for (cur = bucket; cur < bucket + ldmBucketSize; ++cur) {\n                const BYTE* const curMatchBase =\n                    cur->offset < dictLimit ? dictBase : base;\n                const BYTE* const pMatch = curMatchBase + cur->offset;\n                const BYTE* const matchEnd =\n                    cur->offset < dictLimit ? dictEnd : iend;\n                const BYTE* const lowMatchPtr =\n                    cur->offset < dictLimit ? dictStart : lowPrefixPtr;\n                size_t curForwardMatchLength, curBackwardMatchLength,\n                       curTotalMatchLength;\n\n                if (cur->checksum != checksum || cur->offset <= lowestIndex) {\n                    continue;\n                }\n\n                curForwardMatchLength = ZSTD_count_2segments(\n                                            ip, pMatch, iend,\n                                            matchEnd, lowPrefixPtr);\n                if (curForwardMatchLength < ldmParams.minMatchLength) {\n                    continue;\n                }\n                curBackwardMatchLength = ZSTD_ldm_countBackwardsMatch(\n                                             ip, anchor, pMatch, lowMatchPtr);\n                curTotalMatchLength = curForwardMatchLength +\n                                      curBackwardMatchLength;\n\n                if (curTotalMatchLength > bestMatchLength) {\n                    bestMatchLength = curTotalMatchLength;\n                    forwardMatchLength = curForwardMatchLength;\n                    backwardMatchLength = curBackwardMatchLength;\n                    bestEntry = cur;\n                }\n            }\n        }\n\n        /* No match found -- continue searching */\n        if (bestEntry == NULL) {\n            ZSTD_ldm_makeEntryAndInsertByTag(ldmState, rollingHash, hBits,\n                                             (U32)(lastHashed - base),\n                                             ldmParams);\n            ip++;\n            continue;\n        }\n\n        /* Match found */\n        mLength = forwardMatchLength + backwardMatchLength;\n        ip -= backwardMatchLength;\n\n        /* Call the block compressor on the remaining literals */\n        {\n            /* ip = current - backwardMatchLength\n             * The match is at (bestEntry->offset - backwardMatchLength) */\n            U32 const matchIndex = bestEntry->offset;\n            U32 const offset = current - matchIndex;\n\n            /* Overwrite rep codes */\n            for (i = 0; i < ZSTD_REP_NUM; i++)\n                seqStorePtr->rep[i] = repToConfirm[i];\n\n            /* Fill the hash table for the block compressor */\n            ZSTD_ldm_limitTableUpdate(ctx, anchor);\n            ZSTD_ldm_fillFastTables(ctx, anchor);\n\n            /* Call block compressor and get remaining literals  */\n            lastLiterals = blockCompressor(ctx, anchor, ip - anchor);\n            ctx->nextToUpdate = (U32)(ip - base);\n\n            /* Update repToConfirm with the new offset */\n            for (i = ZSTD_REP_NUM - 1; i > 0; i--)\n                repToConfirm[i] = repToConfirm[i-1];\n            repToConfirm[0] = offset;\n\n            /* Store the sequence with the leftover literals */\n            ZSTD_storeSeq(seqStorePtr, lastLiterals, ip - lastLiterals,\n                          offset + ZSTD_REP_MOVE, mLength - MINMATCH);\n        }\n\n        /* Insert the current entry into the hash table */\n        ZSTD_ldm_makeEntryAndInsertByTag(ldmState, rollingHash, hBits,\n                                         (U32)(lastHashed - base),\n                                         ldmParams);\n\n        /* Fill the hash table from lastHashed+1 to ip+mLength */\n        assert(ip + backwardMatchLength == lastHashed);\n        if (ip + mLength < ilimit) {\n            rollingHash = ZSTD_ldm_fillLdmHashTable(\n                              ldmState, rollingHash, lastHashed,\n                              ip + mLength, base, hBits,\n                              ldmParams);\n            lastHashed = ip + mLength - 1;\n        }\n        ip += mLength;\n        anchor = ip;\n\n        /* check immediate repcode */\n        while (ip < ilimit) {\n            U32 const current2 = (U32)(ip-base);\n            U32 const repIndex2 = current2 - repToConfirm[1];\n            const BYTE* repMatch2 = repIndex2 < dictLimit ?\n                                    dictBase + repIndex2 : base + repIndex2;\n            if ( (((U32)((dictLimit-1) - repIndex2) >= 3) &\n                        (repIndex2 > lowestIndex))  /* intentional overflow */\n               && (MEM_read32(repMatch2) == MEM_read32(ip)) ) {\n                const BYTE* const repEnd2 = repIndex2 < dictLimit ?\n                                            dictEnd : iend;\n                size_t const repLength2 =\n                        ZSTD_count_2segments(ip+4, repMatch2+4, iend,\n                                             repEnd2, lowPrefixPtr) + 4;\n\n                U32 tmpOffset = repToConfirm[1];\n                repToConfirm[1] = repToConfirm[0];\n                repToConfirm[0] = tmpOffset;\n\n                ZSTD_storeSeq(seqStorePtr, 0, anchor, 0, repLength2-MINMATCH);\n\n                /* Fill the  hash table from lastHashed+1 to ip+repLength2*/\n                if (ip + repLength2 < ilimit) {\n                    rollingHash = ZSTD_ldm_fillLdmHashTable(\n                                      ldmState, rollingHash, lastHashed,\n                                      ip + repLength2, base, hBits,\n                                      ldmParams);\n                    lastHashed = ip + repLength2 - 1;\n                }\n                ip += repLength2;\n                anchor = ip;\n                continue;\n            }\n            break;\n        }\n    }\n\n    /* Overwrite rep */\n    for (i = 0; i < ZSTD_REP_NUM; i++)\n        seqStorePtr->rep[i] = repToConfirm[i];\n\n    ZSTD_ldm_limitTableUpdate(ctx, anchor);\n    ZSTD_ldm_fillFastTables(ctx, anchor);\n\n    /* Call the block compressor one last time on the last literals */\n    lastLiterals = blockCompressor(ctx, anchor, iend - anchor);\n    ctx->nextToUpdate = (U32)(iend - base);\n\n    /* Restore seqStorePtr->rep */\n    for (i = 0; i < ZSTD_REP_NUM; i++)\n        seqStorePtr->rep[i] = savedRep[i];\n\n    /* Return the last literals size */\n    return lastLiterals;\n}\n\nstatic size_t ZSTD_compressBlock_ldm_extDict(ZSTD_CCtx* ctx,\n                                             const void* src, size_t srcSize)\n{\n    return ZSTD_compressBlock_ldm_extDict_generic(ctx, src, srcSize);\n}\n",
        "base_contents": "/*-*************************************\n*  Long distance matching\n***************************************/\n\n/** ZSTD_ldm_getSmallHash() :\n *  numBits should be <= 32\n *  If numBits==0, returns 0.\n *  @return : the most significant numBits of value. */\nstatic U32 ZSTD_ldm_getSmallHash(U64 value, U32 numBits)\n{\n    assert(numBits <= 32);\n    return numBits == 0 ? 0 : (U32)(value >> (64 - numBits));\n}\n\n/** ZSTD_ldm_getChecksum() :\n *  numBitsToDiscard should be <= 32\n *  @return : the next most significant 32 bits after numBitsToDiscard */\nstatic U32 ZSTD_ldm_getChecksum(U64 hash, U32 numBitsToDiscard)\n{\n    assert(numBitsToDiscard <= 32);\n    return (hash >> (64 - 32 - numBitsToDiscard)) & 0xFFFFFFFF;\n}\n\n/** ZSTD_ldm_getTag() ;\n *  Given the hash, returns the most significant numTagBits bits\n *  after (32 + hbits) bits.\n *\n *  If there are not enough bits remaining, return the last\n *  numTagBits bits. */\nstatic U32 ZSTD_ldm_getTag(U64 hash, U32 hbits, U32 numTagBits)\n{\n    assert(numTagBits <= 32 && hbits <= 32);\n    if (32 - hbits < numTagBits) {\n        return hash & ((1 << numTagBits) - 1);\n    } else {\n        return (hash >> (32 - hbits - numTagBits)) & ((1 << numTagBits) - 1);\n    }\n}\n\n/** ZSTD_ldm_getBucket() :\n *  Returns a pointer to the start of the bucket associated with hash. */\nstatic ldmEntry_t* ZSTD_ldm_getBucket(\n        ldmState_t* ldmState, size_t hash, ldmParams_t const ldmParams)\n{\n    return ldmState->hashTable + (hash << ldmParams.bucketSizeLog);\n}\n\n/** ZSTD_ldm_insertEntry() :\n *  Insert the entry with corresponding hash into the hash table */\nstatic void ZSTD_ldm_insertEntry(ldmState_t* ldmState,\n                                 size_t const hash, const ldmEntry_t entry,\n                                 ldmParams_t const ldmParams)\n{\n    BYTE* const bucketOffsets = ldmState->bucketOffsets;\n    *(ZSTD_ldm_getBucket(ldmState, hash, ldmParams) + bucketOffsets[hash]) = entry;\n    bucketOffsets[hash]++;\n    bucketOffsets[hash] &= (1 << ldmParams.bucketSizeLog) - 1;\n}\n\n/** ZSTD_ldm_makeEntryAndInsertByTag() :\n *\n *  Gets the small hash, checksum, and tag from the rollingHash.\n *\n *  If the tag matches (1 << ldmParams.hashEveryLog)-1, then\n *  creates an ldmEntry from the offset, and inserts it into the hash table.\n *\n *  hBits is the length of the small hash, which is the most significant hBits\n *  of rollingHash. The checksum is the next 32 most significant bits, followed\n *  by ldmParams.hashEveryLog bits that make up the tag. */\nstatic void ZSTD_ldm_makeEntryAndInsertByTag(ldmState_t* ldmState,\n                                             U64 const rollingHash,\n                                             U32 const hBits,\n                                             U32 const offset,\n                                             ldmParams_t const ldmParams)\n{\n    U32 const tag = ZSTD_ldm_getTag(rollingHash, hBits, ldmParams.hashEveryLog);\n    U32 const tagMask = (1 << ldmParams.hashEveryLog) - 1;\n    if (tag == tagMask) {\n        U32 const hash = ZSTD_ldm_getSmallHash(rollingHash, hBits);\n        U32 const checksum = ZSTD_ldm_getChecksum(rollingHash, hBits);\n        ldmEntry_t entry;\n        entry.offset = offset;\n        entry.checksum = checksum;\n        ZSTD_ldm_insertEntry(ldmState, hash, entry, ldmParams);\n    }\n}\n\n/** ZSTD_ldm_getRollingHash() :\n *  Get a 64-bit hash using the first len bytes from buf.\n *\n *  Giving bytes s = s_1, s_2, ... s_k, the hash is defined to be\n *  H(s) = s_1*(a^(k-1)) + s_2*(a^(k-2)) + ... + s_k*(a^0)\n *\n *  where the constant a is defined to be prime8bytes.\n *\n *  The implementation adds an offset to each byte, so\n *  H(s) = (s_1 + HASH_CHAR_OFFSET)*(a^(k-1)) + ... */\nstatic U64 ZSTD_ldm_getRollingHash(const BYTE* buf, U32 len)\n{\n    U64 ret = 0;\n    U32 i;\n    for (i = 0; i < len; i++) {\n        ret *= prime8bytes;\n        ret += buf[i] + LDM_HASH_CHAR_OFFSET;\n    }\n    return ret;\n}\n\n/** ZSTD_ldm_ipow() :\n *  Return base^exp. */\nstatic U64 ZSTD_ldm_ipow(U64 base, U64 exp)\n{\n    U64 ret = 1;\n    while (exp) {\n        if (exp & 1) { ret *= base; }\n        exp >>= 1;\n        base *= base;\n    }\n    return ret;\n}\n\nstatic U64 ZSTD_ldm_getHashPower(U32 minMatchLength) {\n    assert(minMatchLength >= ZSTD_LDM_MINMATCH_MIN);\n    return ZSTD_ldm_ipow(prime8bytes, minMatchLength - 1);\n}\n\n/** ZSTD_ldm_updateHash() :\n *  Updates hash by removing toRemove and adding toAdd. */\nstatic U64 ZSTD_ldm_updateHash(U64 hash, BYTE toRemove, BYTE toAdd, U64 hashPower)\n{\n    hash -= ((toRemove + LDM_HASH_CHAR_OFFSET) * hashPower);\n    hash *= prime8bytes;\n    hash += toAdd + LDM_HASH_CHAR_OFFSET;\n    return hash;\n}\n\n/** ZSTD_ldm_countBackwardsMatch() :\n *  Returns the number of bytes that match backwards before pIn and pMatch.\n *\n *  We count only bytes where pMatch >= pBase and pIn >= pAnchor. */\nstatic size_t ZSTD_ldm_countBackwardsMatch(\n            const BYTE* pIn, const BYTE* pAnchor,\n            const BYTE* pMatch, const BYTE* pBase)\n{\n    size_t matchLength = 0;\n    while (pIn > pAnchor && pMatch > pBase && pIn[-1] == pMatch[-1]) {\n        pIn--;\n        pMatch--;\n        matchLength++;\n    }\n    return matchLength;\n}\n\n/** ZSTD_ldm_fillFastTables() :\n *\n *  Fills the relevant tables for the ZSTD_fast and ZSTD_dfast strategies.\n *  This is similar to ZSTD_loadDictionaryContent.\n *\n *  The tables for the other strategies are filled within their\n *  block compressors. */\nstatic size_t ZSTD_ldm_fillFastTables(ZSTD_CCtx* zc, const void* end)\n{\n    const BYTE* const iend = (const BYTE*)end;\n    const U32 mls = zc->appliedParams.cParams.searchLength;\n\n    switch(zc->appliedParams.cParams.strategy)\n    {\n    case ZSTD_fast:\n        ZSTD_fillHashTable(zc, iend, mls);\n        zc->nextToUpdate = (U32)(iend - zc->base);\n        break;\n\n    case ZSTD_dfast:\n        ZSTD_fillDoubleHashTable(zc, iend, mls);\n        zc->nextToUpdate = (U32)(iend - zc->base);\n        break;\n\n    case ZSTD_greedy:\n    case ZSTD_lazy:\n    case ZSTD_lazy2:\n    case ZSTD_btlazy2:\n    case ZSTD_btopt:\n    case ZSTD_btultra:\n        break;\n    default:\n        assert(0);  /* not possible : not a valid strategy id */\n    }\n\n    return 0;\n}\n\n/** ZSTD_ldm_fillLdmHashTable() :\n *\n *  Fills hashTable from (lastHashed + 1) to iend (non-inclusive).\n *  lastHash is the rolling hash that corresponds to lastHashed.\n *\n *  Returns the rolling hash corresponding to position iend-1. */\nstatic U64 ZSTD_ldm_fillLdmHashTable(ldmState_t* state,\n                                     U64 lastHash, const BYTE* lastHashed,\n                                     const BYTE* iend, const BYTE* base,\n                                     U32 hBits, ldmParams_t const ldmParams)\n{\n    U64 rollingHash = lastHash;\n    const BYTE* cur = lastHashed + 1;\n\n    while (cur < iend) {\n        rollingHash = ZSTD_ldm_updateHash(rollingHash, cur[-1],\n                                          cur[ldmParams.minMatchLength-1],\n                                          state->hashPower);\n        ZSTD_ldm_makeEntryAndInsertByTag(state,\n                                         rollingHash, hBits,\n                                         (U32)(cur - base), ldmParams);\n        ++cur;\n    }\n    return rollingHash;\n}\n\n\n/** ZSTD_ldm_limitTableUpdate() :\n *\n *  Sets cctx->nextToUpdate to a position corresponding closer to anchor\n *  if it is far way\n *  (after a long match, only update tables a limited amount). */\nstatic void ZSTD_ldm_limitTableUpdate(ZSTD_CCtx* cctx, const BYTE* anchor)\n{\n    U32 const current = (U32)(anchor - cctx->base);\n    if (current > cctx->nextToUpdate + 1024) {\n        cctx->nextToUpdate =\n            current - MIN(512, current - cctx->nextToUpdate - 1024);\n    }\n}\n\n/** ZSTD_compressBlock_ldm_generic() :\n *\n *  This is a block compressor intended for long distance matching.\n *\n *  The function searches for matches of length at least\n *  ldmParams.minMatchLength using a hash table in cctx->ldmState.\n *  Matches can be at a distance of up to cParams.windowLog.\n *\n *  Upon finding a match, the unmatched literals are compressed using a\n *  ZSTD_blockCompressor (depending on the strategy in the compression\n *  parameters), which stores the matched sequences. The \"long distance\"\n *  match is then stored with the remaining literals from the\n *  ZSTD_blockCompressor. */\nFORCE_INLINE_TEMPLATE\nsize_t ZSTD_compressBlock_ldm_generic(ZSTD_CCtx* cctx,\n                                      const void* src, size_t srcSize)\n{\n    ldmState_t* const ldmState = &(cctx->ldmState);\n    const ldmParams_t ldmParams = cctx->appliedParams.ldmParams;\n    const U64 hashPower = ldmState->hashPower;\n    const U32 hBits = ldmParams.hashLog - ldmParams.bucketSizeLog;\n    const U32 ldmBucketSize = (1 << ldmParams.bucketSizeLog);\n    const U32 ldmTagMask = (1 << ldmParams.hashEveryLog) - 1;\n    seqStore_t* const seqStorePtr = &(cctx->seqStore);\n    const BYTE* const base = cctx->base;\n    const BYTE* const istart = (const BYTE*)src;\n    const BYTE* ip = istart;\n    const BYTE* anchor = istart;\n    const U32   lowestIndex = cctx->dictLimit;\n    const BYTE* const lowest = base + lowestIndex;\n    const BYTE* const iend = istart + srcSize;\n    const BYTE* const ilimit = iend - ldmParams.minMatchLength;\n\n    const ZSTD_blockCompressor blockCompressor =\n        ZSTD_selectBlockCompressor(cctx->appliedParams.cParams.strategy, 0);\n    U32* const repToConfirm = seqStorePtr->repToConfirm;\n    U32 savedRep[ZSTD_REP_NUM];\n    U64 rollingHash = 0;\n    const BYTE* lastHashed = NULL;\n    size_t i, lastLiterals;\n\n    /* Save seqStorePtr->rep and copy repToConfirm */\n    for (i = 0; i < ZSTD_REP_NUM; i++)\n        savedRep[i] = repToConfirm[i] = seqStorePtr->rep[i];\n\n    /* Main Search Loop */\n    while (ip < ilimit) {   /* < instead of <=, because repcode check at (ip+1) */\n        size_t mLength;\n        U32 const current = (U32)(ip - base);\n        size_t forwardMatchLength = 0, backwardMatchLength = 0;\n        ldmEntry_t* bestEntry = NULL;\n        if (ip != istart) {\n            rollingHash = ZSTD_ldm_updateHash(rollingHash, lastHashed[0],\n                                              lastHashed[ldmParams.minMatchLength],\n                                              hashPower);\n        } else {\n            rollingHash = ZSTD_ldm_getRollingHash(ip, ldmParams.minMatchLength);\n        }\n        lastHashed = ip;\n\n        /* Do not insert and do not look for a match */\n        if (ZSTD_ldm_getTag(rollingHash, hBits, ldmParams.hashEveryLog) !=\n                ldmTagMask) {\n           ip++;\n           continue;\n        }\n\n        /* Get the best entry and compute the match lengths */\n        {\n            ldmEntry_t* const bucket =\n                ZSTD_ldm_getBucket(ldmState,\n                                   ZSTD_ldm_getSmallHash(rollingHash, hBits),\n                                   ldmParams);\n            ldmEntry_t* cur;\n            size_t bestMatchLength = 0;\n            U32 const checksum = ZSTD_ldm_getChecksum(rollingHash, hBits);\n\n            for (cur = bucket; cur < bucket + ldmBucketSize; ++cur) {\n                const BYTE* const pMatch = cur->offset + base;\n                size_t curForwardMatchLength, curBackwardMatchLength,\n                       curTotalMatchLength;\n                if (cur->checksum != checksum || cur->offset <= lowestIndex) {\n                    continue;\n                }\n\n                curForwardMatchLength = ZSTD_count(ip, pMatch, iend);\n                if (curForwardMatchLength < ldmParams.minMatchLength) {\n                    continue;\n                }\n                curBackwardMatchLength = ZSTD_ldm_countBackwardsMatch(\n                                             ip, anchor, pMatch, lowest);\n                curTotalMatchLength = curForwardMatchLength +\n                                      curBackwardMatchLength;\n\n                if (curTotalMatchLength > bestMatchLength) {\n                    bestMatchLength = curTotalMatchLength;\n                    forwardMatchLength = curForwardMatchLength;\n                    backwardMatchLength = curBackwardMatchLength;\n                    bestEntry = cur;\n                }\n            }\n        }\n\n        /* No match found -- continue searching */\n        if (bestEntry == NULL) {\n            ZSTD_ldm_makeEntryAndInsertByTag(ldmState, rollingHash,\n                                             hBits, current,\n                                             ldmParams);\n            ip++;\n            continue;\n        }\n\n        /* Match found */\n        mLength = forwardMatchLength + backwardMatchLength;\n        ip -= backwardMatchLength;\n\n        /* Call the block compressor on the remaining literals */\n        {\n            U32 const matchIndex = bestEntry->offset;\n            const BYTE* const match = base + matchIndex - backwardMatchLength;\n            U32 const offset = (U32)(ip - match);\n\n            /* Overwrite rep codes */\n            for (i = 0; i < ZSTD_REP_NUM; i++)\n                seqStorePtr->rep[i] = repToConfirm[i];\n\n            /* Fill tables for block compressor */\n            ZSTD_ldm_limitTableUpdate(cctx, anchor);\n            ZSTD_ldm_fillFastTables(cctx, anchor);\n\n            /* Call block compressor and get remaining literals */\n            lastLiterals = blockCompressor(cctx, anchor, ip - anchor);\n            cctx->nextToUpdate = (U32)(ip - base);\n\n            /* Update repToConfirm with the new offset */\n            for (i = ZSTD_REP_NUM - 1; i > 0; i--)\n                repToConfirm[i] = repToConfirm[i-1];\n            repToConfirm[0] = offset;\n\n            /* Store the sequence with the leftover literals */\n            ZSTD_storeSeq(seqStorePtr, lastLiterals, ip - lastLiterals,\n                          offset + ZSTD_REP_MOVE, mLength - MINMATCH);\n        }\n\n        /* Insert the current entry into the hash table */\n        ZSTD_ldm_makeEntryAndInsertByTag(ldmState, rollingHash, hBits,\n                                         (U32)(lastHashed - base),\n                                         ldmParams);\n\n        assert(ip + backwardMatchLength == lastHashed);\n\n        /* Fill the hash table from lastHashed+1 to ip+mLength*/\n        /* Heuristic: don't need to fill the entire table at end of block */\n        if (ip + mLength < ilimit) {\n            rollingHash = ZSTD_ldm_fillLdmHashTable(\n                              ldmState, rollingHash, lastHashed,\n                              ip + mLength, base, hBits, ldmParams);\n            lastHashed = ip + mLength - 1;\n        }\n        ip += mLength;\n        anchor = ip;\n        /* Check immediate repcode */\n        while ( (ip < ilimit)\n             && ( (repToConfirm[1] > 0) && (repToConfirm[1] <= (U32)(ip-lowest))\n             && (MEM_read32(ip) == MEM_read32(ip - repToConfirm[1])) )) {\n\n            size_t const rLength = ZSTD_count(ip+4, ip+4-repToConfirm[1],\n                                              iend) + 4;\n            /* Swap repToConfirm[1] <=> repToConfirm[0] */\n            {\n                U32 const tmpOff = repToConfirm[1];\n                repToConfirm[1] = repToConfirm[0];\n                repToConfirm[0] = tmpOff;\n            }\n\n            ZSTD_storeSeq(seqStorePtr, 0, anchor, 0, rLength-MINMATCH);\n\n            /* Fill the  hash table from lastHashed+1 to ip+rLength*/\n            if (ip + rLength < ilimit) {\n                rollingHash = ZSTD_ldm_fillLdmHashTable(\n                                ldmState, rollingHash, lastHashed,\n                                ip + rLength, base, hBits, ldmParams);\n                lastHashed = ip + rLength - 1;\n            }\n            ip += rLength;\n            anchor = ip;\n        }\n    }\n\n    /* Overwrite rep */\n    for (i = 0; i < ZSTD_REP_NUM; i++)\n        seqStorePtr->rep[i] = repToConfirm[i];\n\n    ZSTD_ldm_limitTableUpdate(cctx, anchor);\n    ZSTD_ldm_fillFastTables(cctx, anchor);\n\n    lastLiterals = blockCompressor(cctx, anchor, iend - anchor);\n    cctx->nextToUpdate = (U32)(iend - base);\n\n    /* Restore seqStorePtr->rep */\n    for (i = 0; i < ZSTD_REP_NUM; i++)\n        seqStorePtr->rep[i] = savedRep[i];\n\n    /* Return the last literals size */\n    return lastLiterals;\n}\n\nstatic size_t ZSTD_compressBlock_ldm(ZSTD_CCtx* ctx,\n                                     const void* src, size_t srcSize)\n{\n    return ZSTD_compressBlock_ldm_generic(ctx, src, srcSize);\n}\n\nstatic size_t ZSTD_compressBlock_ldm_extDict_generic(\n                                 ZSTD_CCtx* ctx,\n                                 const void* src, size_t srcSize)\n{\n    ldmState_t* const ldmState = &(ctx->ldmState);\n    const ldmParams_t ldmParams = ctx->appliedParams.ldmParams;\n    const U64 hashPower = ldmState->hashPower;\n    const U32 hBits = ldmParams.hashLog - ldmParams.bucketSizeLog;\n    const U32 ldmBucketSize = (1 << ldmParams.bucketSizeLog);\n    const U32 ldmTagMask = (1 << ldmParams.hashEveryLog) - 1;\n    seqStore_t* const seqStorePtr = &(ctx->seqStore);\n    const BYTE* const base = ctx->base;\n    const BYTE* const dictBase = ctx->dictBase;\n    const BYTE* const istart = (const BYTE*)src;\n    const BYTE* ip = istart;\n    const BYTE* anchor = istart;\n    const U32   lowestIndex = ctx->lowLimit;\n    const BYTE* const dictStart = dictBase + lowestIndex;\n    const U32   dictLimit = ctx->dictLimit;\n    const BYTE* const lowPrefixPtr = base + dictLimit;\n    const BYTE* const dictEnd = dictBase + dictLimit;\n    const BYTE* const iend = istart + srcSize;\n    const BYTE* const ilimit = iend - ldmParams.minMatchLength;\n\n    const ZSTD_blockCompressor blockCompressor =\n        ZSTD_selectBlockCompressor(ctx->appliedParams.cParams.strategy, 1);\n    U32* const repToConfirm = seqStorePtr->repToConfirm;\n    U32 savedRep[ZSTD_REP_NUM];\n    U64 rollingHash = 0;\n    const BYTE* lastHashed = NULL;\n    size_t i, lastLiterals;\n\n    /* Save seqStorePtr->rep and copy repToConfirm */\n    for (i = 0; i < ZSTD_REP_NUM; i++) {\n        savedRep[i] = repToConfirm[i] = seqStorePtr->rep[i];\n    }\n\n    /* Search Loop */\n    while (ip < ilimit) {  /* < instead of <=, because (ip+1) */\n        size_t mLength;\n        const U32 current = (U32)(ip-base);\n        size_t forwardMatchLength = 0, backwardMatchLength = 0;\n        ldmEntry_t* bestEntry = NULL;\n        if (ip != istart) {\n          rollingHash = ZSTD_ldm_updateHash(rollingHash, lastHashed[0],\n                                       lastHashed[ldmParams.minMatchLength],\n                                       hashPower);\n        } else {\n            rollingHash = ZSTD_ldm_getRollingHash(ip, ldmParams.minMatchLength);\n        }\n        lastHashed = ip;\n\n        if (ZSTD_ldm_getTag(rollingHash, hBits, ldmParams.hashEveryLog) !=\n                ldmTagMask) {\n            /* Don't insert and don't look for a match */\n           ip++;\n           continue;\n        }\n\n        /* Get the best entry and compute the match lengths */\n        {\n            ldmEntry_t* const bucket =\n                ZSTD_ldm_getBucket(ldmState,\n                                   ZSTD_ldm_getSmallHash(rollingHash, hBits),\n                                   ldmParams);\n            ldmEntry_t* cur;\n            size_t bestMatchLength = 0;\n            U32 const checksum = ZSTD_ldm_getChecksum(rollingHash, hBits);\n\n            for (cur = bucket; cur < bucket + ldmBucketSize; ++cur) {\n                const BYTE* const curMatchBase =\n                    cur->offset < dictLimit ? dictBase : base;\n                const BYTE* const pMatch = curMatchBase + cur->offset;\n                const BYTE* const matchEnd =\n                    cur->offset < dictLimit ? dictEnd : iend;\n                const BYTE* const lowMatchPtr =\n                    cur->offset < dictLimit ? dictStart : lowPrefixPtr;\n                size_t curForwardMatchLength, curBackwardMatchLength,\n                       curTotalMatchLength;\n\n                if (cur->checksum != checksum || cur->offset <= lowestIndex) {\n                    continue;\n                }\n\n                curForwardMatchLength = ZSTD_count_2segments(\n                                            ip, pMatch, iend,\n                                            matchEnd, lowPrefixPtr);\n                if (curForwardMatchLength < ldmParams.minMatchLength) {\n                    continue;\n                }\n                curBackwardMatchLength = ZSTD_ldm_countBackwardsMatch(\n                                             ip, anchor, pMatch, lowMatchPtr);\n                curTotalMatchLength = curForwardMatchLength +\n                                      curBackwardMatchLength;\n\n                if (curTotalMatchLength > bestMatchLength) {\n                    bestMatchLength = curTotalMatchLength;\n                    forwardMatchLength = curForwardMatchLength;\n                    backwardMatchLength = curBackwardMatchLength;\n                    bestEntry = cur;\n                }\n            }\n        }\n\n        /* No match found -- continue searching */\n        if (bestEntry == NULL) {\n            ZSTD_ldm_makeEntryAndInsertByTag(ldmState, rollingHash, hBits,\n                                             (U32)(lastHashed - base),\n                                             ldmParams);\n            ip++;\n            continue;\n        }\n\n        /* Match found */\n        mLength = forwardMatchLength + backwardMatchLength;\n        ip -= backwardMatchLength;\n\n        /* Call the block compressor on the remaining literals */\n        {\n            /* ip = current - backwardMatchLength\n             * The match is at (bestEntry->offset - backwardMatchLength) */\n            U32 const matchIndex = bestEntry->offset;\n            U32 const offset = current - matchIndex;\n\n            /* Overwrite rep codes */\n            for (i = 0; i < ZSTD_REP_NUM; i++)\n                seqStorePtr->rep[i] = repToConfirm[i];\n\n            /* Fill the hash table for the block compressor */\n            ZSTD_ldm_limitTableUpdate(ctx, anchor);\n            ZSTD_ldm_fillFastTables(ctx, anchor);\n\n            /* Call block compressor and get remaining literals  */\n            lastLiterals = blockCompressor(ctx, anchor, ip - anchor);\n            ctx->nextToUpdate = (U32)(ip - base);\n\n            /* Update repToConfirm with the new offset */\n            for (i = ZSTD_REP_NUM - 1; i > 0; i--)\n                repToConfirm[i] = repToConfirm[i-1];\n            repToConfirm[0] = offset;\n\n            /* Store the sequence with the leftover literals */\n            ZSTD_storeSeq(seqStorePtr, lastLiterals, ip - lastLiterals,\n                          offset + ZSTD_REP_MOVE, mLength - MINMATCH);\n        }\n\n        /* Insert the current entry into the hash table */\n        ZSTD_ldm_makeEntryAndInsertByTag(ldmState, rollingHash, hBits,\n                                         (U32)(lastHashed - base),\n                                         ldmParams);\n\n        /* Fill the hash table from lastHashed+1 to ip+mLength */\n        assert(ip + backwardMatchLength == lastHashed);\n        if (ip + mLength < ilimit) {\n            rollingHash = ZSTD_ldm_fillLdmHashTable(\n                              ldmState, rollingHash, lastHashed,\n                              ip + mLength, base, hBits,\n                              ldmParams);\n            lastHashed = ip + mLength - 1;\n        }\n        ip += mLength;\n        anchor = ip;\n\n        /* check immediate repcode */\n        while (ip < ilimit) {\n            U32 const current2 = (U32)(ip-base);\n            U32 const repIndex2 = current2 - repToConfirm[1];\n            const BYTE* repMatch2 = repIndex2 < dictLimit ?\n                                    dictBase + repIndex2 : base + repIndex2;\n            if ( (((U32)((dictLimit-1) - repIndex2) >= 3) &\n                        (repIndex2 > lowestIndex))  /* intentional overflow */\n               && (MEM_read32(repMatch2) == MEM_read32(ip)) ) {\n                const BYTE* const repEnd2 = repIndex2 < dictLimit ?\n                                            dictEnd : iend;\n                size_t const repLength2 =\n                        ZSTD_count_2segments(ip+4, repMatch2+4, iend,\n                                             repEnd2, lowPrefixPtr) + 4;\n\n                U32 tmpOffset = repToConfirm[1];\n                repToConfirm[1] = repToConfirm[0];\n                repToConfirm[0] = tmpOffset;\n\n                ZSTD_storeSeq(seqStorePtr, 0, anchor, 0, repLength2-MINMATCH);\n\n                /* Fill the  hash table from lastHashed+1 to ip+repLength2*/\n                if (ip + repLength2 < ilimit) {\n                    rollingHash = ZSTD_ldm_fillLdmHashTable(\n                                      ldmState, rollingHash, lastHashed,\n                                      ip + repLength2, base, hBits,\n                                      ldmParams);\n                    lastHashed = ip + repLength2 - 1;\n                }\n                ip += repLength2;\n                anchor = ip;\n                continue;\n            }\n            break;\n        }\n    }\n\n    /* Overwrite rep */\n    for (i = 0; i < ZSTD_REP_NUM; i++)\n        seqStorePtr->rep[i] = repToConfirm[i];\n\n    ZSTD_ldm_limitTableUpdate(ctx, anchor);\n    ZSTD_ldm_fillFastTables(ctx, anchor);\n\n    /* Call the block compressor one last time on the last literals */\n    lastLiterals = blockCompressor(ctx, anchor, iend - anchor);\n    ctx->nextToUpdate = (U32)(iend - base);\n\n    /* Restore seqStorePtr->rep */\n    for (i = 0; i < ZSTD_REP_NUM; i++)\n        seqStorePtr->rep[i] = savedRep[i];\n\n    /* Return the last literals size */\n    return lastLiterals;\n}\n\nstatic size_t ZSTD_compressBlock_ldm_extDict(ZSTD_CCtx* ctx,\n                                             const void* src, size_t srcSize)\n{\n    return ZSTD_compressBlock_ldm_extDict_generic(ctx, src, srcSize);\n}\n",
        "res_region": "",
        "lookback": "                                   const BYTE* anchor, size_t lastLLSize)",
        "lookahead": "static void ZSTD_storeLastLiterals(seqStore_t* seqStorePtr,",
        "label": [
            "ours",
            "one_side_deletion"
        ],
        "start_line": 1515,
        "end_line": 2858,
        "merge_gen_region": null,
        "confidence": 0.6318163275718689,
        "hesitated": true
    }
]