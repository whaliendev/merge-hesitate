[
    {
        "a_contents": "#ifndef ROCKSDB_LITE\nnamespace {\n  void ValidateKeyExistence(DB* db,\n    const std::vector<Slice>& keysMustExist,\n    const std::vector<Slice>& keysMustNotExist) {\n    // Ensure that expected keys exist\n    std::vector<std::string> values;\n    if (keysMustExist.size() > 0) {\n      std::vector<Status> status_list = db->MultiGet(ReadOptions(),\n        keysMustExist,\n        &values);\n      for (size_t i = 0; i < keysMustExist.size(); i++) {\n        ASSERT_OK(status_list[i]);\n      }\n    }\n\n    // Ensure that given keys don't exist\n    if (keysMustNotExist.size() > 0) {\n      std::vector<Status> status_list = db->MultiGet(ReadOptions(),\n        keysMustNotExist,\n        &values);\n      for (size_t i = 0; i < keysMustNotExist.size(); i++) {\n        ASSERT_TRUE(status_list[i].IsNotFound());\n      }\n    }\n  }\n\n} //namespace\n\nTEST_F(DBTest, WalFilterTest) {\n  class TestWalFilter : public WalFilter {\n  private:\n    // Processing option that is requested to be applied at the given index\n    WalFilter::WalProcessingOption WalProcessingOption_;\n    // Index at which to apply WalProcessingOption_\n    // At other indexes default WalProcessingOption::kContinueProcessing is\n    // returned.\n    size_t applyOptionAtRecordIndex_;\n    // Current record index, incremented with each record encountered.\n    size_t currentRecordIndex_;\n  public:\n    TestWalFilter(WalFilter::WalProcessingOption WalProcessingOption,\n      size_t applyOptionForRecordIndex) :\n      WalProcessingOption_(WalProcessingOption),\n      applyOptionAtRecordIndex_(applyOptionForRecordIndex),\n      currentRecordIndex_(0) { }\n\n    virtual WalProcessingOption LogRecord(const WriteBatch & batch,\n      WriteBatch* new_batch, bool* batch_changed) const override {\n      WalFilter::WalProcessingOption optionToReturn;\n\n      if (currentRecordIndex_ == applyOptionAtRecordIndex_) {\n        optionToReturn = WalProcessingOption_;\n      }\n      else {\n        optionToReturn = WalProcessingOption::kContinueProcessing;\n      }\n\n      // Filter is passed as a const object for RocksDB to not modify the\n      // object, however we modify it for our own purpose here and hence\n      // cast the constness away.\n      (const_cast<TestWalFilter*>(this)->currentRecordIndex_)++;\n\n      return optionToReturn;\n    }\n\n    virtual const char* Name() const override {\n      return \"TestWalFilter\";\n    }\n  };\n\n  // Create 3 batches with two keys each\n  std::vector<std::vector<std::string>> batchKeys(3);\n\n  batchKeys[0].push_back(\"key1\");\n  batchKeys[0].push_back(\"key2\");\n  batchKeys[1].push_back(\"key3\");\n  batchKeys[1].push_back(\"key4\");\n  batchKeys[2].push_back(\"key5\");\n  batchKeys[2].push_back(\"key6\");\n\n  // Test with all WAL processing options\n  for (int option = 0; \n    option < static_cast<int>(WalFilter::WalProcessingOption::kWalProcessingOptionMax); \n    option++) {\n    Options options = OptionsForLogIterTest();\n    DestroyAndReopen(options);\n    CreateAndReopenWithCF({ \"pikachu\" }, options);\n\n    // Write given keys in given batches\n    for (size_t i = 0; i < batchKeys.size(); i++) {\n      WriteBatch batch;\n      for (size_t j = 0; j < batchKeys[i].size(); j++) {\n        batch.Put(handles_[0], batchKeys[i][j], DummyString(1024));\n      }\n      dbfull()->Write(WriteOptions(), &batch);\n    }\n\n    WalFilter::WalProcessingOption WalProcessingOption =\n      static_cast<WalFilter::WalProcessingOption>(option);\n\n    // Create a test filter that would apply WalProcessingOption at the first\n    // record\n    size_t applyOptionForRecordIndex = 1;\n    TestWalFilter testWalFilter(WalProcessingOption, \n      applyOptionForRecordIndex);\n\n    // Reopen database with option to use WAL filter\n    options = OptionsForLogIterTest();\n    options.wal_filter = &testWalFilter;\n    Status status = TryReopenWithColumnFamilies({ \"default\", \"pikachu\" }, \n      options);\n    if (WalProcessingOption ==\n      WalFilter::WalProcessingOption::kCorruptedRecord) {\n      assert(!status.ok());\n      // In case of corruption we can turn off paranoid_checks to reopen\n      // databse\n      options.paranoid_checks = false;\n      ReopenWithColumnFamilies({ \"default\", \"pikachu\" }, options);\n    } else {\n      assert(status.ok());\n    }\n\n    // Compute which keys we expect to be found\n    // and which we expect not to be found after recovery.\n    std::vector<Slice> keysMustExist;\n    std::vector<Slice> keysMustNotExist;\n    switch (WalProcessingOption) {\n      case  WalFilter::WalProcessingOption::kCorruptedRecord:\n      case  WalFilter::WalProcessingOption::kContinueProcessing: {\n        fprintf(stderr, \"Testing with complete WAL processing\\n\");\n        //we expect all records to be processed\n        for (size_t i = 0; i < batchKeys.size(); i++) {\n          for (size_t j = 0; j < batchKeys[i].size(); j++) {\n            keysMustExist.push_back(Slice(batchKeys[i][j]));\n          }\n        }\n        break;\n      }\n      case WalFilter::WalProcessingOption::kIgnoreCurrentRecord: {\n        fprintf(stderr, \"Testing with ignoring record %\" ROCKSDB_PRIszt \" only\\n\",\n          applyOptionForRecordIndex);\n        // We expect the record with applyOptionForRecordIndex to be not\n        // found.\n        for (size_t i = 0; i < batchKeys.size(); i++) {\n          for (size_t j = 0; j < batchKeys[i].size(); j++) {\n            if (i == applyOptionForRecordIndex) {\n              keysMustNotExist.push_back(Slice(batchKeys[i][j]));\n            }\n            else {\n              keysMustExist.push_back(Slice(batchKeys[i][j]));\n            }\n          }\n        }\n        break;\n      }\n      case WalFilter::WalProcessingOption::kStopReplay: {\n        fprintf(stderr, \"Testing with stopping replay from record %\" ROCKSDB_PRIszt \"\\n\",\n          applyOptionForRecordIndex);\n        // We expect records beyond applyOptionForRecordIndex to be not\n        // found.\n        for (size_t i = 0; i < batchKeys.size(); i++) {\n          for (size_t j = 0; j < batchKeys[i].size(); j++) {\n            if (i >= applyOptionForRecordIndex) {\n              keysMustNotExist.push_back(Slice(batchKeys[i][j]));\n            }\n            else {\n              keysMustExist.push_back(Slice(batchKeys[i][j]));\n            }\n          }\n        }\n        break;\n      }\n      default:\n        assert(false); //unhandled case\n    }\n\n    bool checkedAfterReopen = false;\n\n    while (true)\n    {\n      // Ensure that expected keys exists\n      // and not expected keys don't exist after recovery\n      ValidateKeyExistence(db_, keysMustExist, keysMustNotExist);\n\n      if (checkedAfterReopen) {\n        break;\n      }\n\n      //reopen database again to make sure previous log(s) are not used\n      //(even if they were skipped)\n      //reopn database with option to use WAL filter\n      options = OptionsForLogIterTest();\n      ReopenWithColumnFamilies({ \"default\", \"pikachu\" }, options);\n\n      checkedAfterReopen = true;\n    }\n  }\n}\n\nTEST_F(DBTest, WalFilterTestWithChangeBatch) {\n  class ChangeBatchHandler : public WriteBatch::Handler {\n  private:\n    // Whether we have already added a key to new batch\n    size_t m_numKeysAdded;\n    // Batch to insert keys in\n    WriteBatch* newWriteBatch_;\n    // Number of keys to add in the new batch\n    size_t m_numKeysToAddInNewBatch;\n  public:\n    ChangeBatchHandler(WriteBatch* newWriteBatch, \n      size_t numKeysToAddInNewBatch) :\n      newWriteBatch_(newWriteBatch),\n      m_numKeysToAddInNewBatch(numKeysToAddInNewBatch),\n      m_numKeysAdded(0){ }\n    virtual void Put(const Slice& key, const Slice& value) override {\n      if (m_numKeysAdded < m_numKeysToAddInNewBatch) {\n        newWriteBatch_->Put(key, value);\n        ++m_numKeysAdded;\n      }\n    }\n  };\n\n  class TestWalFilterWithChangeBatch : public WalFilter {\n  private:\n    // Index at which to start changing records\n    size_t m_changeRecordsFromIndex;\n    // Number of keys to add in the new batch\n    size_t m_numKeysToAddInNewBatch;\n    // Current record index, incremented with each record encountered.\n    size_t currentRecordIndex_;\n  public:\n    TestWalFilterWithChangeBatch(\n      size_t changeRecordsFromIndex,\n      size_t numKeysToAddInNewBatch) :\n      m_changeRecordsFromIndex(changeRecordsFromIndex),\n      m_numKeysToAddInNewBatch(numKeysToAddInNewBatch),\n      currentRecordIndex_(0) { }\n\n    virtual WalProcessingOption LogRecord(const WriteBatch & batch,\n      WriteBatch* new_batch, bool* batch_changed) const override {\n\n      if (currentRecordIndex_ >= m_changeRecordsFromIndex) {\n        ChangeBatchHandler handler(new_batch, m_numKeysToAddInNewBatch);\n        batch.Iterate(&handler);\n        *batch_changed = true;\n      }\n\n      // Filter is passed as a const object for RocksDB to not modify the\n      // object, however we modify it for our own purpose here and hence\n      // cast the constness away.\n      (const_cast<TestWalFilterWithChangeBatch*>(this)->currentRecordIndex_)++;\n\n      return WalProcessingOption::kContinueProcessing;\n    }\n\n    virtual const char* Name() const override {\n      return \"TestWalFilterWithChangeBatch\";\n    }\n  };\n\n  std::vector<std::vector<std::string>> batchKeys(3);\n\n  batchKeys[0].push_back(\"key1\");\n  batchKeys[0].push_back(\"key2\");\n  batchKeys[1].push_back(\"key3\");\n  batchKeys[1].push_back(\"key4\");\n  batchKeys[2].push_back(\"key5\");\n  batchKeys[2].push_back(\"key6\");\n\n  Options options = OptionsForLogIterTest();\n  DestroyAndReopen(options);\n  CreateAndReopenWithCF({ \"pikachu\" }, options);\n\n  // Write given keys in given batches\n  for (size_t i = 0; i < batchKeys.size(); i++) {\n    WriteBatch batch;\n    for (size_t j = 0; j < batchKeys[i].size(); j++) {\n      batch.Put(handles_[0], batchKeys[i][j], DummyString(1024));\n    }\n    dbfull()->Write(WriteOptions(), &batch);\n  }\n\n  // Create a test filter that would apply WalProcessingOption at the first\n  // record\n  size_t changeRecordsFromIndex = 1;\n  size_t numKeysToAddInNewBatch = 1;\n  TestWalFilterWithChangeBatch testWalFilterWithChangeBatch(\n    changeRecordsFromIndex, numKeysToAddInNewBatch);\n\n  // Reopen database with option to use WAL filter\n  options = OptionsForLogIterTest();\n  options.wal_filter = &testWalFilterWithChangeBatch;\n  ReopenWithColumnFamilies({ \"default\", \"pikachu\" }, options);\n\n  // Ensure that all keys exist before m_changeRecordsFromIndex\n  // And after that index only single key exists\n  // as our filter adds only single key for each batch\n  std::vector<Slice> keysMustExist;\n  std::vector<Slice> keysMustNotExist;\n\n  for (size_t i = 0; i < batchKeys.size(); i++) {\n    for (size_t j = 0; j < batchKeys[i].size(); j++) {\n      if (i >= changeRecordsFromIndex && j >= numKeysToAddInNewBatch) {\n        keysMustNotExist.push_back(Slice(batchKeys[i][j]));\n      }\n      else {\n        keysMustExist.push_back(Slice(batchKeys[i][j]));\n      }\n    }\n  }\n\n  bool checkedAfterReopen = false;\n\n  while (true)\n  {\n    // Ensure that expected keys exists\n    // and not expected keys don't exist after recovery\n    ValidateKeyExistence(db_, keysMustExist, keysMustNotExist);\n\n    if (checkedAfterReopen) {\n      break;\n    }\n\n    //reopen database again to make sure previous log(s) are not used\n    //(even if they were skipped)\n    //reopn database with option to use WAL filter\n    options = OptionsForLogIterTest();\n    ReopenWithColumnFamilies({ \"default\", \"pikachu\" }, options);\n\n    checkedAfterReopen = true;\n  }\n}\n#endif // ROCKSDB_LITE\n",
        "b_contents": "#ifndef ROCKSDB_LITE\nclass BloomStatsTestWithParam\n    : public DBTest,\n      public testing::WithParamInterface<std::tuple<bool, bool>> {\n public:\n  BloomStatsTestWithParam() {\n    use_block_table_ = std::get<0>(GetParam());\n    use_block_based_builder_ = std::get<1>(GetParam());\n\n    options_.create_if_missing = true;\n    options_.prefix_extractor.reset(rocksdb::NewFixedPrefixTransform(4));\n    options_.memtable_prefix_bloom_bits = 8 * 1024;\n    if (use_block_table_) {\n      BlockBasedTableOptions table_options;\n      table_options.hash_index_allow_collision = false;\n      table_options.filter_policy.reset(\n          NewBloomFilterPolicy(10, use_block_based_builder_));\n      options_.table_factory.reset(NewBlockBasedTableFactory(table_options));\n    } else {\n      PlainTableOptions table_options;\n      options_.table_factory.reset(NewPlainTableFactory(table_options));\n    }\n\n    perf_context.Reset();\n    DestroyAndReopen(options_);\n  }\n\n  ~BloomStatsTestWithParam() {\n    perf_context.Reset();\n    Destroy(options_);\n  }\n\n  // Required if inheriting from testing::WithParamInterface<>\n  static void SetUpTestCase() {}\n  static void TearDownTestCase() {}\n\n  bool use_block_table_;\n  bool use_block_based_builder_;\n  Options options_;\n};\n",
        "base_contents": "",
        "res_region": "#ifndef ROCKSDB_LITE\nnamespace {\n  void ValidateKeyExistence(DB* db,\n    const std::vector<Slice>& keysMustExist,\n    const std::vector<Slice>& keysMustNotExist) {\n    // Ensure that expected keys exist\n    std::vector<std::string> values;\n    if (keysMustExist.size() > 0) {\n      std::vector<Status> status_list = db->MultiGet(ReadOptions(),\n        keysMustExist,\n        &values);\n      for (size_t i = 0; i < keysMustExist.size(); i++) {\n        ASSERT_OK(status_list[i]);\n      }\n    }\n\n    // Ensure that given keys don't exist\n    if (keysMustNotExist.size() > 0) {\n      std::vector<Status> status_list = db->MultiGet(ReadOptions(),\n        keysMustNotExist,\n        &values);\n      for (size_t i = 0; i < keysMustNotExist.size(); i++) {\n        ASSERT_TRUE(status_list[i].IsNotFound());\n      }\n    }\n  }\n\n} //namespace\n\nTEST_F(DBTest, WalFilterTest) {\n  class TestWalFilter : public WalFilter {\n  private:\n    // Processing option that is requested to be applied at the given index\n    WalFilter::WalProcessingOption WalProcessingOption_;\n    // Index at which to apply WalProcessingOption_\n    // At other indexes default WalProcessingOption::kContinueProcessing is\n    // returned.\n    size_t applyOptionAtRecordIndex_;\n    // Current record index, incremented with each record encountered.\n    size_t currentRecordIndex_;\n  public:\n    TestWalFilter(WalFilter::WalProcessingOption WalProcessingOption,\n      size_t applyOptionForRecordIndex) :\n      WalProcessingOption_(WalProcessingOption),\n      applyOptionAtRecordIndex_(applyOptionForRecordIndex),\n      currentRecordIndex_(0) { }\n\n    virtual WalProcessingOption LogRecord(const WriteBatch & batch,\n      WriteBatch* new_batch, bool* batch_changed) const override {\n      WalFilter::WalProcessingOption optionToReturn;\n\n      if (currentRecordIndex_ == applyOptionAtRecordIndex_) {\n        optionToReturn = WalProcessingOption_;\n      }\n      else {\n        optionToReturn = WalProcessingOption::kContinueProcessing;\n      }\n\n      // Filter is passed as a const object for RocksDB to not modify the\n      // object, however we modify it for our own purpose here and hence\n      // cast the constness away.\n      (const_cast<TestWalFilter*>(this)->currentRecordIndex_)++;\n\n      return optionToReturn;\n    }\n\n    virtual const char* Name() const override {\n      return \"TestWalFilter\";\n    }\n  };\n\n  // Create 3 batches with two keys each\n  std::vector<std::vector<std::string>> batchKeys(3);\n\n  batchKeys[0].push_back(\"key1\");\n  batchKeys[0].push_back(\"key2\");\n  batchKeys[1].push_back(\"key3\");\n  batchKeys[1].push_back(\"key4\");\n  batchKeys[2].push_back(\"key5\");\n  batchKeys[2].push_back(\"key6\");\n\n  // Test with all WAL processing options\n  for (int option = 0; \n    option < static_cast<int>(WalFilter::WalProcessingOption::kWalProcessingOptionMax); \n    option++) {\n    Options options = OptionsForLogIterTest();\n    DestroyAndReopen(options);\n    CreateAndReopenWithCF({ \"pikachu\" }, options);\n\n    // Write given keys in given batches\n    for (size_t i = 0; i < batchKeys.size(); i++) {\n      WriteBatch batch;\n      for (size_t j = 0; j < batchKeys[i].size(); j++) {\n        batch.Put(handles_[0], batchKeys[i][j], DummyString(1024));\n      }\n      dbfull()->Write(WriteOptions(), &batch);\n    }\n\n    WalFilter::WalProcessingOption WalProcessingOption =\n      static_cast<WalFilter::WalProcessingOption>(option);\n\n    // Create a test filter that would apply WalProcessingOption at the first\n    // record\n    size_t applyOptionForRecordIndex = 1;\n    TestWalFilter testWalFilter(WalProcessingOption, \n      applyOptionForRecordIndex);\n\n    // Reopen database with option to use WAL filter\n    options = OptionsForLogIterTest();\n    options.wal_filter = &testWalFilter;\n    Status status = TryReopenWithColumnFamilies({ \"default\", \"pikachu\" }, \n      options);\n    if (WalProcessingOption ==\n      WalFilter::WalProcessingOption::kCorruptedRecord) {\n      assert(!status.ok());\n      // In case of corruption we can turn off paranoid_checks to reopen\n      // databse\n      options.paranoid_checks = false;\n      ReopenWithColumnFamilies({ \"default\", \"pikachu\" }, options);\n    } else {\n      assert(status.ok());\n    }\n\n    // Compute which keys we expect to be found\n    // and which we expect not to be found after recovery.\n    std::vector<Slice> keysMustExist;\n    std::vector<Slice> keysMustNotExist;\n    switch (WalProcessingOption) {\n      case  WalFilter::WalProcessingOption::kCorruptedRecord:\n      case  WalFilter::WalProcessingOption::kContinueProcessing: {\n        fprintf(stderr, \"Testing with complete WAL processing\\n\");\n        //we expect all records to be processed\n        for (size_t i = 0; i < batchKeys.size(); i++) {\n          for (size_t j = 0; j < batchKeys[i].size(); j++) {\n            keysMustExist.push_back(Slice(batchKeys[i][j]));\n          }\n        }\n        break;\n      }\n      case WalFilter::WalProcessingOption::kIgnoreCurrentRecord: {\n        fprintf(stderr, \"Testing with ignoring record %\" ROCKSDB_PRIszt \" only\\n\",\n          applyOptionForRecordIndex);\n        // We expect the record with applyOptionForRecordIndex to be not\n        // found.\n        for (size_t i = 0; i < batchKeys.size(); i++) {\n          for (size_t j = 0; j < batchKeys[i].size(); j++) {\n            if (i == applyOptionForRecordIndex) {\n              keysMustNotExist.push_back(Slice(batchKeys[i][j]));\n            }\n            else {\n              keysMustExist.push_back(Slice(batchKeys[i][j]));\n            }\n          }\n        }\n        break;\n      }\n      case WalFilter::WalProcessingOption::kStopReplay: {\n        fprintf(stderr, \"Testing with stopping replay from record %\" ROCKSDB_PRIszt \"\\n\",\n          applyOptionForRecordIndex);\n        // We expect records beyond applyOptionForRecordIndex to be not\n        // found.\n        for (size_t i = 0; i < batchKeys.size(); i++) {\n          for (size_t j = 0; j < batchKeys[i].size(); j++) {\n            if (i >= applyOptionForRecordIndex) {\n              keysMustNotExist.push_back(Slice(batchKeys[i][j]));\n            }\n            else {\n              keysMustExist.push_back(Slice(batchKeys[i][j]));\n            }\n          }\n        }\n        break;\n      }\n      default:\n        assert(false); //unhandled case\n    }\n\n    bool checkedAfterReopen = false;\n\n    while (true)\n    {\n      // Ensure that expected keys exists\n      // and not expected keys don't exist after recovery\n      ValidateKeyExistence(db_, keysMustExist, keysMustNotExist);\n\n      if (checkedAfterReopen) {\n        break;\n      }\n\n      //reopen database again to make sure previous log(s) are not used\n      //(even if they were skipped)\n      //reopn database with option to use WAL filter\n      options = OptionsForLogIterTest();\n      ReopenWithColumnFamilies({ \"default\", \"pikachu\" }, options);\n\n      checkedAfterReopen = true;\n    }\n  }\n}\n\nTEST_F(DBTest, WalFilterTestWithChangeBatch) {\n  class ChangeBatchHandler : public WriteBatch::Handler {\n  private:\n    // Whether we have already added a key to new batch\n    size_t m_numKeysAdded;\n    // Batch to insert keys in\n    WriteBatch* newWriteBatch_;\n    // Number of keys to add in the new batch\n    size_t m_numKeysToAddInNewBatch;\n  public:\n    ChangeBatchHandler(WriteBatch* newWriteBatch, \n      size_t numKeysToAddInNewBatch) :\n      newWriteBatch_(newWriteBatch),\n      m_numKeysToAddInNewBatch(numKeysToAddInNewBatch),\n      m_numKeysAdded(0){ }\n    virtual void Put(const Slice& key, const Slice& value) override {\n      if (m_numKeysAdded < m_numKeysToAddInNewBatch) {\n        newWriteBatch_->Put(key, value);\n        ++m_numKeysAdded;\n      }\n    }\n  };\n\n  class TestWalFilterWithChangeBatch : public WalFilter {\n  private:\n    // Index at which to start changing records\n    size_t m_changeRecordsFromIndex;\n    // Number of keys to add in the new batch\n    size_t m_numKeysToAddInNewBatch;\n    // Current record index, incremented with each record encountered.\n    size_t currentRecordIndex_;\n  public:\n    TestWalFilterWithChangeBatch(\n      size_t changeRecordsFromIndex,\n      size_t numKeysToAddInNewBatch) :\n      m_changeRecordsFromIndex(changeRecordsFromIndex),\n      m_numKeysToAddInNewBatch(numKeysToAddInNewBatch),\n      currentRecordIndex_(0) { }\n\n    virtual WalProcessingOption LogRecord(const WriteBatch & batch,\n      WriteBatch* new_batch, bool* batch_changed) const override {\n\n      if (currentRecordIndex_ >= m_changeRecordsFromIndex) {\n        ChangeBatchHandler handler(new_batch, m_numKeysToAddInNewBatch);\n        batch.Iterate(&handler);\n        *batch_changed = true;\n      }\n\n      // Filter is passed as a const object for RocksDB to not modify the\n      // object, however we modify it for our own purpose here and hence\n      // cast the constness away.\n      (const_cast<TestWalFilterWithChangeBatch*>(this)->currentRecordIndex_)++;\n\n      return WalProcessingOption::kContinueProcessing;\n    }\n\n    virtual const char* Name() const override {\n      return \"TestWalFilterWithChangeBatch\";\n    }\n  };\n\n  std::vector<std::vector<std::string>> batchKeys(3);\n\n  batchKeys[0].push_back(\"key1\");\n  batchKeys[0].push_back(\"key2\");\n  batchKeys[1].push_back(\"key3\");\n  batchKeys[1].push_back(\"key4\");\n  batchKeys[2].push_back(\"key5\");\n  batchKeys[2].push_back(\"key6\");\n\n  Options options = OptionsForLogIterTest();\n  DestroyAndReopen(options);\n  CreateAndReopenWithCF({ \"pikachu\" }, options);\n\n  // Write given keys in given batches\n  for (size_t i = 0; i < batchKeys.size(); i++) {\n    WriteBatch batch;\n    for (size_t j = 0; j < batchKeys[i].size(); j++) {\n      batch.Put(handles_[0], batchKeys[i][j], DummyString(1024));\n    }\n    dbfull()->Write(WriteOptions(), &batch);\n  }\n\n  // Create a test filter that would apply WalProcessingOption at the first\n  // record\n  size_t changeRecordsFromIndex = 1;\n  size_t numKeysToAddInNewBatch = 1;\n  TestWalFilterWithChangeBatch testWalFilterWithChangeBatch(\n    changeRecordsFromIndex, numKeysToAddInNewBatch);\n\n  // Reopen database with option to use WAL filter\n  options = OptionsForLogIterTest();\n  options.wal_filter = &testWalFilterWithChangeBatch;\n  ReopenWithColumnFamilies({ \"default\", \"pikachu\" }, options);\n\n  // Ensure that all keys exist before m_changeRecordsFromIndex\n  // And after that index only single key exists\n  // as our filter adds only single key for each batch\n  std::vector<Slice> keysMustExist;\n  std::vector<Slice> keysMustNotExist;\n\n  for (size_t i = 0; i < batchKeys.size(); i++) {\n    for (size_t j = 0; j < batchKeys[i].size(); j++) {\n      if (i >= changeRecordsFromIndex && j >= numKeysToAddInNewBatch) {\n        keysMustNotExist.push_back(Slice(batchKeys[i][j]));\n      }\n      else {\n        keysMustExist.push_back(Slice(batchKeys[i][j]));\n      }\n    }\n  }\n\n  bool checkedAfterReopen = false;\n\n  while (true)\n  {\n    // Ensure that expected keys exists\n    // and not expected keys don't exist after recovery\n    ValidateKeyExistence(db_, keysMustExist, keysMustNotExist);\n\n    if (checkedAfterReopen) {\n      break;\n    }\n\n    //reopen database again to make sure previous log(s) are not used\n    //(even if they were skipped)\n    //reopn database with option to use WAL filter\n    options = OptionsForLogIterTest();\n    ReopenWithColumnFamilies({ \"default\", \"pikachu\" }, options);\n\n    checkedAfterReopen = true;\n  }\n}\n#endif // ROCKSDB_LITE\n\n#ifndef ROCKSDB_LITE\nclass BloomStatsTestWithParam\n    : public DBTest,\n      public testing::WithParamInterface<std::tuple<bool, bool>> {\n public:\n  BloomStatsTestWithParam() {\n    use_block_table_ = std::get<0>(GetParam());\n    use_block_based_builder_ = std::get<1>(GetParam());\n\n    options_.create_if_missing = true;\n    options_.prefix_extractor.reset(rocksdb::NewFixedPrefixTransform(4));\n    options_.memtable_prefix_bloom_bits = 8 * 1024;\n    if (use_block_table_) {\n      BlockBasedTableOptions table_options;\n      table_options.hash_index_allow_collision = false;\n      table_options.filter_policy.reset(\n          NewBloomFilterPolicy(10, use_block_based_builder_));\n      options_.table_factory.reset(NewBlockBasedTableFactory(table_options));\n    } else {\n      PlainTableOptions table_options;\n      options_.table_factory.reset(NewPlainTableFactory(table_options));\n    }\n\n    perf_context.Reset();\n    DestroyAndReopen(options_);\n  }\n\n  ~BloomStatsTestWithParam() {\n    perf_context.Reset();\n    Destroy(options_);\n  }\n\n  // Required if inheriting from testing::WithParamInterface<>\n  static void SetUpTestCase() {}\n  static void TearDownTestCase() {}\n\n  bool use_block_table_;\n  bool use_block_based_builder_;\n  Options options_;\n};\n",
        "lookback": "namespace {",
        "lookahead": "// 1 Insert 2 K-V pairs into DB",
        "label": [
            "interleave",
            "one_side_deletion"
        ],
        "start_line": 9891,
        "end_line": 10270,
        "merge_gen_region": null,
        "confidence": 0.7664070725440979,
        "hesitated": true
    }
]